# 빅데이터를 지탱하는 기술
- 데이터 처리를 어떻게 시스템화하는가에 대한 문제를 다룸


### Hadoop
- 다수의 컴퓨터에서 대향의 데이터를 처리하기 위한 시스템
- 모여진 데이터를 나중에 집계하는 것이 목적
- 단일 소프트웨어가 아니라 분산 시스템을 구성하는 다수의 소프트웨어로 이루어진 집합체
- 구성요소
  - HDFS(분산파일시스템): 하둡에서 처리되는 데이터 대부분이 저장됨, 네트워크에 연결된 파일 서버와 같은 존재지만, 다수의 컴퓨터에 파일을 복사하여 중복성을 높임
  - YARN(리소스 관리자): CPU나 메모리 등의 계산 리소스를 관리, 애플리케이션이 사용하는 CPU 코어와 메모리를 컨테이너 단위로 관리, 하둡에서 분산 애플리케이션을 실행하면 YARN이 클러스터 전체의 부하를 보고 비어 있는 호스트부터 컨테이너를 할당
  - MapReduce(분산 데이터 처리)

### Hive
- SQL과 같은 쿼리 언어를 Hadoop에서 실행하기 위한 소프트웨어
- 배치형 쿼리엔진, 데이터베이스가 아닌 데이터 처리를 위한 배치 처리 구조
- 시간이 걸리는 배치 처리는 원칙적으로 Hive를 사용해야 함
  - ex. 비정규화 테이블이 수억 레코드나 되면, 그것을 데이터 마트로 내보내는 것만으로도 상당한 시간이 소요됨 -> 그러면 쿼리 엔진 자체의 성능은 최종적인 실행시간에 그다지 많은 영향을 끼지치 않음 -> 그렇다면 배치형 시스템을 사용하는 편이 리소스의 효용을 높일 수 있음
- 쿼리 개선 예
  - 서브 쿼리 안에서 레코드 수를 줄이는 방법 -> 초기에 팩트 테이블을 작게 하는 것
  - 데이터의 편향을 방지하는 방법
- 대량 출력을 수반하는 대규모 데이터 처리에 적합하지만, 작은 쿼리를 여러번 실행하는 대화형 처리에는 적합하지 않음

### Presto
- 대화형 쿼리 엔진 -> 쿼리 실행의 지연을 감소시키는 것을 목적으로 개발된 것
- 전용 스토리지를 갖고 있지 않으므로 Hive와 마찬가지로 다양한 데이터 소스에서 직접 데이터를 읽어 들임
- 성능을 최대한 발휘하려면 원래 스토리지가 열 지향 데이터 구조로 되어있어야 함
- ORC 형식의 로드에 최적화되어 있으며, 그것을 확장성이 높은 분산 스토리지에 배치하여 최대의 성능 발휘
- 데이터의 로딩 속도를 높이려면 Presto 클러스터를 분산 스토리지와 네트워크의 가까운 곳에 설치한 후에 그것들을 가능한 한 고속 네트워크에 연결하도록 해야 함
- SQL 실행에 특화된 시스템 -> 쿼리를 분석하여 최적의 실행 계획을 생성하고, 그것을 자바의 바이트 코드로 변환함
- Presto 쿼리는 일단 실행이 시작되면 중간에 끼어들 수 없기 때문에, 너무 큰 쿼리를 실행해서는 안됨
- 쿼리의 실행 과정에서 디스크에 쓰기를 하지 않음 -> 모든 데이터 처리를 메모리상에서 실시하고 메모리가 부족하면 여유가 생길 때까지 기다리거나 오류로 실패함
- 단시간 쿼리 실행에 사용하는 것이 효율적
- 기본적으로 분산 결합(distribute join) 실시 -> 갖은 키를 갖는 데이터는 동일한 노드에 모임
  - 분산 결합에서는 노드 간의 데이터 전송을 위한 네트워크 통신이 발생 -> 종종 쿼리 지연 초래
  - 한 쪽 테이블이 충분히 작은 경우에는 브로드캐스트 결합(broadcast join)을 사용하여 처리 속도를 크게 고속화할 수 있음
  - 브로드캐스트 결합을 유효로 하려면 분산 결합을 명시적으로 무효화해야 함 + 쿼리 안에 SELECT 문으로 먼저 팩트 테이블을 지정하여 그것에 디멘젼 테이블을 결합해야 함
- 열 지향 스토리지의 집계를 매우 빠르게 실행할 수 있음


### NoSQL
- 빈번한 읽기/쓰기 및 분산 처리가 강점
- 애플리케이션에서 온라인으로 접속하는 데이터베이스
- 전통적인 RDB의 제약을 제거하는 것이 목표

## 분산 스토리지
- 여러 컴퓨터와 디스크로부터 구성된 스토리지 시스템
- 데이터를 저장하는 방법
  - 객체 스토리지(object storage): 한 덩어리로 모인 데이터에 이름을 부여해서 파일로 저장 ex. Amazon S3

## 분산 데이터 처리
- 분산 스토리지에 저장된 데이터를 처리하는 데는 분산 데이터 처리 프레임워크가 필요
- 빅데이터를 SQL로 집계하는 방법
  - 쿼리엔진: 분산 스토리지 상의 데이터를 SQL로 집계하기 위함 ex. Hive
  - ETL 프로세스: 외부의 데이터 웨어하우스 제품을 이용하는 것,
                이를 위해 분산 스토리지에서 추출한 데이터를 웨어하우스에 적합한 형태로 변환
  
### 기간계 시스템 
- mission-critical system
- 비즈니스 근간에 관련된 중요한 시스템으로 이것이 정지되면 업무가 멈추기 때문에 완벽하게 테스트를 반복하고 신중하게 운용
- 실행과정을 로그파일이나 데이터베이스 등에 기록

### 정보계 시스템 
- information system
- 사내 커뮤니케이션과 의사 결정을 위해 이용하는 시스템으로 이것이 정지되어도 그 영향범위가 제한되어 있기 때문에 기간계 시스템만큼 엄격한 운영정책을 가지고 있지 않음

- 데이터를 효율적으로 분석하려면 정보계 시스템으로 분리해야 함
- 데이터 복사 없이는 정보계 시스템이 기간계 시스템에 연결되지 못함

### 크로스 테이블
- 사람들이 보기 편한 보고서
- 데이터베이스에서 다루기 어려움
  - 왜냐하며 디비에 새로운 행을 추가하는 것은 가난하지만, 열을 늘리는 것은 간단하지 않기 때문 

### 트랜잭션 테이블
- 보고서의 바탕이 되는 테이블
- 행 방향으로만 증가하고 열 방향으로는 데이터를 증가시키지 않도록 만든 것

### 크로스 집계
- 트랜잭션 테이블 -> 크로스 테이블로 변환하는 과정
- 소량의 데이터를 크로스 집계할 때 -> 스프레드시트의 피벗 테이블

### 룩업 테이블
- 트랜잭션 테이블에 새로운 항목을 추가하는 것이 아니라, 다른 테이블과 결합하고 싶을 때 사용되는 것

### RDB
- 5GB 정도면 일반적인 RDB가 데이터 마트에 적합
- 장점: 원래 지연이 적고, 많은 수의 클라이언트가 동시 접속해도 성능이 나빠지지 않아 많은 사용자가 사용하는 실제 운영 환경의 데이터 마트로 우수함
- 단점: 메모리가 부족하면 급격히 성능이 저하됨, 수억 레코드를 초과하는 데이터 집계에서는 항상 디바이스 I/O가 발생한다고 가정해야 함
    -> 어떻게 효율화할지가 중요한 열쇠!

### 대규모 병렬처리 MPP massive pararell processing
- 분산된 데이터를 읽어들여 멀티 코어를 활용하면서 디스크 I/O를 병렬적으로 처리하는 아키텍처
- 데이터를 가능한 작게 압축하고 그것을 여러 디스크에 분산함으로써 데이터 로드에 따른 지연을 줄임
- Amazon Redshift, Google BigQuery
- 데이터 집계에 최적화
- 데이터 웨어하우스와 데이터 분석용의 데이터베이스에서 특히 많이 사용됨
- MPP 아키텍처에 의한 데이터 처리 병렬화 -> 쿼리 지연을 줄일 수 있음

### 행 지향 데이터베이스 row-oriented database
- 일반적으로 업무 시스템에서 사용되는 데이터베이스는 레코드 단위의 읽고 쓰기에 최적화되어 있음
  -> 각 행이 디스크 상에 일련의 데이터로 기록됨
- 테이블의 각 행을 하나의 덩어리로 디스크에 저장 
- 새 레코드를 추가할 때 파일의 끝에 데이터를 쓸 뿐이므로 빠르게 추가 가능
  - 대량의 트랜잭션을 지연없이 처리하기 위해 데이터 추가를 효율적으로 할 수 있도록 함
- 인덱스: 데이터 검색을 고속화하기 위함
  - 인덱스가 없다면? 저장되는 모든 데이터를 로드해야 워하는 레코드를 찾을 수 있음 -> 많은 디스크 I/O 발생 -> 성능 저하
- 적절한 인덱스가 사용되도록 튜닝 중요
- 레코드 단위로 데이터가 저장되어 있어서 데이터분석에 필요 없는 열까지 로드됨
- Oracle, MySQL

### 열 지향 데이터베이스 column-oriented database
- 빅데이터는 대부분 디스크 상에 있기 때문에 쿼리에 필요한 최소한의 데이터만을 가져옴으로써 지연이 줄어듦 
  -> 컬럼을 압축해서 디스크 I/O 줄이기
- 데이터분석에 사용되는 데이터베이스는 칼럼 단위 집계에 최적화
- 데이터 분석에서는 어떤 칼럼이 사용되는지 미리 알 수 없기 때문에 인덱스를 작성했다고 해도 거의 도움 X
  - 인덱스에 의지하지 않는 고속화 기술 필요
- 데이터를 미리 칼럼 단위로 정리해 둠으로써 필요한 칼럼만을 로드하여 디스크 I/O를 줄임
- 데이터 압축 효율 우수 
  - 같은 칼럼에 유사한 데이터가 나열되는 경우: 같은 문자열의 반복은 매우 작게 압축할 수 있음
- 데이터 종류에 따라 다르지만, 열 지향 데이터베이스는 압축되지 않은 행 지향 데이터베이스와 비교하면 1/10이하로 압축 가능
- TeraData, Amazon Redshift

## 테이블 비정규화하기
- 트랜잭션: 시간과 함께 생성되는 데이터를 기록한 것, 한 번 기록하면 변화하지 않음
  - 데이터 웨어하우스에서 팩트테이블이라고 부름
  - 집계의 기반이 되는 숫자데이터 ex. 판매액
- 마스터: 트랜잭션에 참고되는 각종 정보, 상황에 따라 다시 쓰임
  - 데이터 웨어하우스에서 디멘젼 테이블이라고 부름
  - 데이터를 분류하기 위한 속성값

### 스타 스키마
- 데이터 마트를 만들 때는 팩트테이블 중심으로 여러 디멘젼 테이블을 결합하는 것이 좋은데, 그림으로 그리면 별모양이 되는 스키마
- 데이터 마트에서 사용되는 이유
  - 단순하기 때문에 이해하기 쉬움
  - 데이터 분석을 쉽게 할 수 있음
  - 성능상의 이유: 데이터 양이 증가함에 따라 팩트 테이블은 디멘젼 테이블보다 훨씬 커져 그 데이터 양이 집계 시간을 좌우함 -> 팩트 테이블을 될 수 있는 한 작게 만드는 것이 고속화에서 중요함, 팩트 테이블에는 ID와 같은 키만 남겨두고 나머지 외에는 디멘젼 테이블로 옮김
  
### 비정규화
- 디멘젼 테이블을 작성하려면 정규화에의해 분해된 테이블을 최대한 결합하여 하나의 테이블로 정리
- 그 결과가 중복이 되어도 괜찮음
- 정규화와는 반대의 작업
  - 비정규화 테이블: 스타스키마에서 좀 더 비정규화를 진행해 모든 테이블을 결합한 팩트 테이블 -> 열지향 스토리지는 컬럼 단위의 데이터 압축이 있어서 문자열을 그대로 저장해도 아주 작게 압축되므로 디스크 I/O의 증가가 억제되므로 데이터를 디멘젼으로 이동시킬 이유가 없어졌기 때문

### Hive
- 대량의 비구조화 데이터를 가공하는 무거운 배치처리
- 높은 처리량으로 리소스를 활용할 수 있음

### Impala, Presto
- 구조화 데이터를 대화식으로 집계하고자 할 때

### Spark 
- 다량의 메모리를 활용하여 고속화를 실현하는 것
- Hadoop을 대체하는 것이 아니라 MapReduce를 대체하는 존재
- HDFS나 YARN 등을 Spark에서 그대로 사용 할 수 있음
- Hadoop을 사용하지 않는 구성도 가능 -> S3를 이용하거나 카산드라에서 데이터를 읽어 들이는 것도 가능
- 실행은 자바의 런타임 필요
- Spark 상에서 실행되는 데이터 처리는 스크립트 언어를 사용 가능 ex. 자바, 스칼라, 파이썬, R

## 분산 시스템 성능 향상
- 데이터 편차 최대한 없애고, 모든 노드에 데이터가 균등하게 분산되도록 해야 함
- SELECT DISTINCT 로 중복을 제거함으로써 부하를 잘 분산하면서 데이터 양을 줄일 수 있음


## 데이터 분석의 프레임워크 선택하기
### MPP 데이터 베이스
- 스토리지 및 계산 노드가 일체화되어 있어 처음에 ETL 프로세스 등으로 데이터를 가져오는 절차가 필요함
- 시각화를 위한 데이터 마트로 생각하면 유력함
- 비정규화 테이블을 고속으로 집계하는 데에 최적

### Hive
- 대규모 배치 처리를 꾸준히 실행 가능
- 데이터양에 좌우되지 않는 쿼리 엔진으로 계속 이용될 것

### Presto
- Hive와 정 반대인 쿼리 엔진으로, 속도로 인해 다양한 것을 희생
- 쿼리 실행 중 장애가 발생하면 오류가 떠서 처음부터 다시 실행
- 메모리가 부족하면 쿼리를 실행할 수 없는 경우도 있음
- 그러나 원래 실행이 아주 빨라서 오류가 발생하면 다시 반복해서 사용 
- 대화식 쿼리에 특화되어 있기 때문에 텍스트 처리가 중심이 되는 ETL프로세스 및 데이터 구조화에는 적합하지 않음
  - 데이터 구조화에는 Hive, Spark가 좋다
- 단시간에 대량의 리소스를 소비하기 때문에 너무 무리하게 사용하면 다른 쿼리를 실행할 수 없음

### Spark
- SQL에 특화한 쿼리 엔진은 아님
- 인 메모리의 데이터 처리가 중심이며, Presto뿐만 아니라 대화형 쿼리 실행에 적합함
- 장점은 SQL이라기보단, ETL 프로세스에서 SQL에 이르기 까지의 일련의 흐름을 하나의 데이터 파이프라인으로 기술할 수 있다는 점
- Spark 하나로 Hive에 의한 데이터구조화와 Presto에 의한 SQL실행을 하나의 스크립트에서 실행할 수 있음
  - 텍스트 데이터를 읽어 열 지향 스토리지로 변환하고 SQL로 집계해서 결과를 내보내는 등 일련의 프로세스를 한 번의 데이터 처리로 기술 가능
- 메모리를 어떻게 관리하느냐가 중요함

## 데이터 전송 구조
## 벌크형
- 전통적인 데이터 웨어하우스에서 사용된 것
- 과거에 축적된 대량의 데이터가 이미 이는 경우나 기존의 데이터베이스에서 데이터를 추출하고 싶을 경우
- 데이터가 처음부터 분산 스토리지에 저장되어 있는 것이 아니라면 ETL 서버 설치 
- 데이터 전송의 신뢰성이 중요한 경우 -> 여러번 데이터 전송을 재실행할 수 있다는 점이 장점
  - cf.스트리밍 형의 데이터 전송은 나중에 재실행하기 쉽지 않기 때문
- 워크플로 관리 도구와 궁합이 뛰어남 -> 벌크형 데이터 전송은 워크플로 관리 도구와 조합시켜 도입
  - 정기적인 스케줄 실행 및 오류 통지 등은 워크플로 관리 도구에 맡기고 있음
  - 매일매일 마스터 데이터의 스냅샷과 신뢰성이 중시되는 과금 데이터 전송 등은 다른 배치 처리와 함께 워크플로 일부에 포함시키는 것이 좋음

## 스트리밍형
- 데이터가 처음부터 분산 스토리지에 저장되어 있는 것이 아니라면 