# 빅데이터를 지탱하는 기술
- 데이터 처리를 어떻게 시스템화하는가에 대한 문제를 다룸


### Hadoop
- 다수의 컴퓨터에서 대향의 데이터를 처리하기 위한 시스템
- 모여진 데이터를 나중에 집계하는 것이 목적
- 단일 소프트웨어가 아니라 분산 시스템을 구성하는 다수의 소프트웨어로 이루어진 집합체
- 구성요소
  - HDFS(분산파일시스템): 하둡에서 처리되는 데이터 대부분이 저장됨, 네트워크에 연결된 파일 서버와 같은 존재지만, 다수의 컴퓨터에 파일을 복사하여 중복성을 높임
  - YARN(리소스 관리자): CPU나 메모리 등의 계산 리소스를 관리, 애플리케이션이 사용하는 CPU 코어와 메모리를 컨테이너 단위로 관리, 하둡에서 분산 애플리케이션을 실행하면 YARN이 클러스터 전체의 부하를 보고 비어 있는 호스트부터 컨테이너를 할당
  - MapReduce(분산 데이터 처리)

### Hive
- SQL과 같은 쿼리 언어를 Hadoop에서 실행하기 위한 소프트웨어
- 배치형 쿼리엔진, 데이터베이스가 아닌 데이터 처리를 위한 배치 처리 구조
- 시간이 걸리는 배치 처리는 원칙적으로 Hive를 사용해야 함
  - ex. 비정규화 테이블이 수억 레코드나 되면, 그것을 데이터 마트로 내보내는 것만으로도 상당한 시간이 소요됨 -> 그러면 쿼리 엔진 자체의 성능은 최종적인 실행시간에 그다지 많은 영향을 끼지치 않음 -> 그렇다면 배치형 시스템을 사용하는 편이 리소스의 효용을 높일 수 있음
- 쿼리 개선 예
  - 서브 쿼리 안에서 레코드 수를 줄이는 방법 -> 초기에 팩트 테이블을 작게 하는 것
  - 데이터의 편향을 방지하는 방법
- 대량 출력을 수반하는 대규모 데이터 처리에 적합하지만, 작은 쿼리를 여러번 실행하는 대화형 처리에는 적합하지 않음

### Presto
- 대화형 쿼리 엔진 -> 쿼리 실행의 지연을 감소시키는 것을 목적으로 개발된 것
- 전용 스토리지를 갖고 있지 않으므로 Hive와 마찬가지로 다양한 데이터 소스에서 직접 데이터를 읽어 들임
- 성능을 최대한 발휘하려면 원래 스토리지가 열 지향 데이터 구조로 되어있어야 함
- ORC 형식의 로드에 최적화되어 있으며, 그것을 확장성이 높은 분산 스토리지에 배치하여 최대의 성능 발휘
- 데이터의 로딩 속도를 높이려면 Presto 클러스터를 분산 스토리지와 네트워크의 가까운 곳에 설치한 후에 그것들을 가능한 한 고속 네트워크에 연결하도록 해야 함
- SQL 실행에 특화된 시스템 -> 쿼리를 분석하여 최적의 실행 계획을 생성하고, 그것을 자바의 바이트 코드로 변환함
- Presto 쿼리는 일단 실행이 시작되면 중간에 끼어들 수 없기 때문에, 너무 큰 쿼리를 실행해서는 안됨
- 쿼리의 실행 과정에서 디스크에 쓰기를 하지 않음 -> 모든 데이터 처리를 메모리상에서 실시하고 메모리가 부족하면 여유가 생길 때까지 기다리거나 오류로 실패함
- 단시간 쿼리 실행에 사용하는 것이 효율적
- 기본적으로 분산 결합(distribute join) 실시 -> 갖은 키를 갖는 데이터는 동일한 노드에 모임
  - 분산 결합에서는 노드 간의 데이터 전송을 위한 네트워크 통신이 발생 -> 종종 쿼리 지연 초래
  - 한 쪽 테이블이 충분히 작은 경우에는 브로드캐스트 결합(broadcast join)을 사용하여 처리 속도를 크게 고속화할 수 있음
  - 브로드캐스트 결합을 유효로 하려면 분산 결합을 명시적으로 무효화해야 함 + 쿼리 안에 SELECT 문으로 먼저 팩트 테이블을 지정하여 그것에 디멘젼 테이블을 결합해야 함
- 열 지향 스토리지의 집계를 매우 빠르게 실행할 수 있음


### NoSQL
- 빈번한 읽기/쓰기 및 분산 처리가 강점
- 애플리케이션에서 온라인으로 접속하는 데이터베이스
- 전통적인 RDB의 제약을 제거하는 것이 목표

## 분산 스토리지
- 여러 컴퓨터와 디스크로부터 구성된 스토리지 시스템
- 데이터를 저장하는 방법
  - 객체 스토리지(object storage): 한 덩어리로 모인 데이터에 이름을 부여해서 파일로 저장 ex. Amazon S3

## 분산 데이터 처리
- 분산 스토리지에 저장된 데이터를 처리하는 데는 분산 데이터 처리 프레임워크가 필요
- 빅데이터를 SQL로 집계하는 방법
  - 쿼리엔진: 분산 스토리지 상의 데이터를 SQL로 집계하기 위함 ex. Hive
  - ETL 프로세스: 외부의 데이터 웨어하우스 제품을 이용하는 것,
                이를 위해 분산 스토리지에서 추출한 데이터를 웨어하우스에 적합한 형태로 변환
  
### 기간계 시스템 
- mission-critical system
- 비즈니스 근간에 관련된 중요한 시스템으로 이것이 정지되면 업무가 멈추기 때문에 완벽하게 테스트를 반복하고 신중하게 운용
- 실행과정을 로그파일이나 데이터베이스 등에 기록

### 정보계 시스템 
- information system
- 사내 커뮤니케이션과 의사 결정을 위해 이용하는 시스템으로 이것이 정지되어도 그 영향범위가 제한되어 있기 때문에 기간계 시스템만큼 엄격한 운영정책을 가지고 있지 않음

- 데이터를 효율적으로 분석하려면 정보계 시스템으로 분리해야 함
- 데이터 복사 없이는 정보계 시스템이 기간계 시스템에 연결되지 못함

### 크로스 테이블
- 사람들이 보기 편한 보고서
- 데이터베이스에서 다루기 어려움
  - 왜냐하며 디비에 새로운 행을 추가하는 것은 가난하지만, 열을 늘리는 것은 간단하지 않기 때문 

### 트랜잭션 테이블
- 보고서의 바탕이 되는 테이블
- 행 방향으로만 증가하고 열 방향으로는 데이터를 증가시키지 않도록 만든 것

### 크로스 집계
- 트랜잭션 테이블 -> 크로스 테이블로 변환하는 과정
- 소량의 데이터를 크로스 집계할 때 -> 스프레드시트의 피벗 테이블

### 룩업 테이블
- 트랜잭션 테이블에 새로운 항목을 추가하는 것이 아니라, 다른 테이블과 결합하고 싶을 때 사용되는 것

### RDB
- 5GB 정도면 일반적인 RDB가 데이터 마트에 적합
- 장점: 원래 지연이 적고, 많은 수의 클라이언트가 동시 접속해도 성능이 나빠지지 않아 많은 사용자가 사용하는 실제 운영 환경의 데이터 마트로 우수함
- 단점: 메모리가 부족하면 급격히 성능이 저하됨, 수억 레코드를 초과하는 데이터 집계에서는 항상 디바이스 I/O가 발생한다고 가정해야 함
    -> 어떻게 효율화할지가 중요한 열쇠!

### 대규모 병렬처리 MPP massive pararell processing
- 분산된 데이터를 읽어들여 멀티 코어를 활용하면서 디스크 I/O를 병렬적으로 처리하는 아키텍처
- 데이터를 가능한 작게 압축하고 그것을 여러 디스크에 분산함으로써 데이터 로드에 따른 지연을 줄임
- Amazon Redshift, Google BigQuery
- 데이터 집계에 최적화
- 데이터 웨어하우스와 데이터 분석용의 데이터베이스에서 특히 많이 사용됨
- MPP 아키텍처에 의한 데이터 처리 병렬화 -> 쿼리 지연을 줄일 수 있음

### 행 지향 데이터베이스 row-oriented database
- 일반적으로 업무 시스템에서 사용되는 데이터베이스는 레코드 단위의 읽고 쓰기에 최적화되어 있음
  -> 각 행이 디스크 상에 일련의 데이터로 기록됨
- 테이블의 각 행을 하나의 덩어리로 디스크에 저장 
- 새 레코드를 추가할 때 파일의 끝에 데이터를 쓸 뿐이므로 빠르게 추가 가능
  - 대량의 트랜잭션을 지연없이 처리하기 위해 데이터 추가를 효율적으로 할 수 있도록 함
- 인덱스: 데이터 검색을 고속화하기 위함
  - 인덱스가 없다면? 저장되는 모든 데이터를 로드해야 워하는 레코드를 찾을 수 있음 -> 많은 디스크 I/O 발생 -> 성능 저하
- 적절한 인덱스가 사용되도록 튜닝 중요
- 레코드 단위로 데이터가 저장되어 있어서 데이터분석에 필요 없는 열까지 로드됨
- Oracle, MySQL

### 열 지향 데이터베이스 column-oriented database
- 빅데이터는 대부분 디스크 상에 있기 때문에 쿼리에 필요한 최소한의 데이터만을 가져옴으로써 지연이 줄어듦 
  -> 컬럼을 압축해서 디스크 I/O 줄이기
- 데이터분석에 사용되는 데이터베이스는 칼럼 단위 집계에 최적화
- 데이터 분석에서는 어떤 칼럼이 사용되는지 미리 알 수 없기 때문에 인덱스를 작성했다고 해도 거의 도움 X
  - 인덱스에 의지하지 않는 고속화 기술 필요
- 데이터를 미리 칼럼 단위로 정리해 둠으로써 필요한 칼럼만을 로드하여 디스크 I/O를 줄임
- 데이터 압축 효율 우수 
  - 같은 칼럼에 유사한 데이터가 나열되는 경우: 같은 문자열의 반복은 매우 작게 압축할 수 있음
- 데이터 종류에 따라 다르지만, 열 지향 데이터베이스는 압축되지 않은 행 지향 데이터베이스와 비교하면 1/10이하로 압축 가능
- TeraData, Amazon Redshift

## 테이블 비정규화하기
- 트랜잭션: 시간과 함께 생성되는 데이터를 기록한 것, 한 번 기록하면 변화하지 않음
  - 데이터 웨어하우스에서 팩트테이블이라고 부름
  - 집계의 기반이 되는 숫자데이터 ex. 판매액
- 마스터: 트랜잭션에 참고되는 각종 정보, 상황에 따라 다시 쓰임
  - 데이터 웨어하우스에서 디멘젼 테이블이라고 부름
  - 데이터를 분류하기 위한 속성값

### 스타 스키마
- 데이터 마트를 만들 때는 팩트테이블 중심으로 여러 디멘젼 테이블을 결합하는 것이 좋은데, 그림으로 그리면 별모양이 되는 스키마
- 데이터 마트에서 사용되는 이유
  - 단순하기 때문에 이해하기 쉬움
  - 데이터 분석을 쉽게 할 수 있음
  - 성능상의 이유: 데이터 양이 증가함에 따라 팩트 테이블은 디멘젼 테이블보다 훨씬 커져 그 데이터 양이 집계 시간을 좌우함 -> 팩트 테이블을 될 수 있는 한 작게 만드는 것이 고속화에서 중요함, 팩트 테이블에는 ID와 같은 키만 남겨두고 나머지 외에는 디멘젼 테이블로 옮김
  
### 비정규화
- 디멘젼 테이블을 작성하려면 정규화에의해 분해된 테이블을 최대한 결합하여 하나의 테이블로 정리
- 그 결과가 중복이 되어도 괜찮음
- 정규화와는 반대의 작업
  - 비정규화 테이블: 스타스키마에서 좀 더 비정규화를 진행해 모든 테이블을 결합한 팩트 테이블 -> 열지향 스토리지는 컬럼 단위의 데이터 압축이 있어서 문자열을 그대로 저장해도 아주 작게 압축되므로 디스크 I/O의 증가가 억제되므로 데이터를 디멘젼으로 이동시킬 이유가 없어졌기 때문

### Hive
- 대량의 비구조화 데이터를 가공하는 무거운 배치처리
- 높은 처리량으로 리소스를 활용할 수 있음

### Impala, Presto
- 구조화 데이터를 대화식으로 집계하고자 할 때

### Spark 
- 다량의 메모리를 활용하여 고속화를 실현하는 것
- Hadoop을 대체하는 것이 아니라 MapReduce를 대체하는 존재
- HDFS나 YARN 등을 Spark에서 그대로 사용 할 수 있음
- Hadoop을 사용하지 않는 구성도 가능 -> S3를 이용하거나 카산드라에서 데이터를 읽어 들이는 것도 가능
- 실행은 자바의 런타임 필요
- Spark 상에서 실행되는 데이터 처리는 스크립트 언어를 사용 가능 ex. 자바, 스칼라, 파이썬, R

## 분산 시스템 성능 향상
- 데이터 편차 최대한 없애고, 모든 노드에 데이터가 균등하게 분산되도록 해야 함
- SELECT DISTINCT 로 중복을 제거함으로써 부하를 잘 분산하면서 데이터 양을 줄일 수 있음


## 데이터 분석의 프레임워크 선택하기
### MPP 데이터 베이스
- 스토리지 및 계산 노드가 일체화되어 있어 처음에 ETL 프로세스 등으로 데이터를 가져오는 절차가 필요함
- 시각화를 위한 데이터 마트로 생각하면 유력함
- 비정규화 테이블을 고속으로 집계하는 데에 최적

### Hive
- 대규모 배치 처리를 꾸준히 실행 가능
- 데이터양에 좌우되지 않는 쿼리 엔진으로 계속 이용될 것

### Presto
- Hive와 정 반대인 쿼리 엔진으로, 속도로 인해 다양한 것을 희생
- 쿼리 실행 중 장애가 발생하면 오류가 떠서 처음부터 다시 실행
- 메모리가 부족하면 쿼리를 실행할 수 없는 경우도 있음
- 그러나 원래 실행이 아주 빨라서 오류가 발생하면 다시 반복해서 사용 
- 대화식 쿼리에 특화되어 있기 때문에 텍스트 처리가 중심이 되는 ETL프로세스 및 데이터 구조화에는 적합하지 않음
  - 데이터 구조화에는 Hive, Spark가 좋다
- 단시간에 대량의 리소스를 소비하기 때문에 너무 무리하게 사용하면 다른 쿼리를 실행할 수 없음

### Spark
- SQL에 특화한 쿼리 엔진은 아님
- 인 메모리의 데이터 처리가 중심이며, Presto뿐만 아니라 대화형 쿼리 실행에 적합함
- 장점은 SQL이라기보단, ETL 프로세스에서 SQL에 이르기 까지의 일련의 흐름을 하나의 데이터 파이프라인으로 기술할 수 있다는 점
- Spark 하나로 Hive에 의한 데이터구조화와 Presto에 의한 SQL실행을 하나의 스크립트에서 실행할 수 있음
  - 텍스트 데이터를 읽어 열 지향 스토리지로 변환하고 SQL로 집계해서 결과를 내보내는 등 일련의 프로세스를 한 번의 데이터 처리로 기술 가능
- 메모리를 어떻게 관리하느냐가 중요함

## 데이터 전송 구조
## 벌크형
- 전통적인 데이터 웨어하우스에서 사용된 것
- 과거에 축적된 대량의 데이터가 이미 이는 경우나 기존의 데이터베이스에서 데이터를 추출하고 싶을 경우
- 데이터가 처음부터 분산 스토리지에 저장되어 있는 것이 아니라면 ETL 서버 설치 
- 데이터 전송의 신뢰성이 중요한 경우 -> 여러번 데이터 전송을 재실행할 수 있다는 점이 장점
  - cf.스트리밍 형의 데이터 전송은 나중에 재실행하기 쉽지 않기 때문
- 워크플로 관리 도구와 궁합이 뛰어남 -> 벌크형 데이터 전송은 워크플로 관리 도구와 조합시켜 도입
  - 정기적인 스케줄 실행 및 오류 통지 등은 워크플로 관리 도구에 맡기고 있음
  - 매일매일 마스터 데이터의 스냅샷과 신뢰성이 중시되는 과금 데이터 전송 등은 다른 배치 처리와 함께 워크플로 일부에 포함시키는 것이 좋음

## 이벤트 시간에 의한 집계의 효율화
## 시계열 인덱스
- Cassandra와 같은 시계열 인덱스에 대응하는 분산 데이터베이스를 이용하면 처음부터 이벤트 시간으로 인덱스 된 테이블을 만들 수 있음
- 시계열 인덱스를 사용하면 매우 짧은 범위의 특정 시간에 맞춘 데이터 집계를 빠르게 실행할 수 있음
- 장기간에 걸쳐서 대량의 데이터를 집계하는 경우에는 분산 데이터베이스가 그다지 효율적이지 않음

## 조건절 푸쉬다운
- 통계를 이용하여 필요 최소한의 데이터만 읽도록 하는 최적화
- 데이터를 정렬해둠으로써 조건절 푸시다운에 의한 최적화가 작동해 풀 스캔을 피할 수 있게 됨

### 분산 KVS distributed Key-Value Store
- 모든 데이터를 키값 쌍으로 저장하도록 설계된 데이터 저장소
- 모든 데이터에 고유의 키를 지정하고 그것을 부하 분산을 위해 이용
- 키가 정해지면 그 값을 클러스터 내의 어느 노드에 배치할 것인지 결정 -> 이 구조에 의해 노드 간에 부하를 균등하게 분산하고 노드를 증감하는 것만으로 클러스터의 성능을 변경할 수 있게 되어 있음

### Amazon DynamoDB
- 항상 안정된 읽기 쓰기 성능을 제공하도록 디자인된 분산형 NoSQL 데이터베이스
- 하나 또는 두 개의 키에 연결하는 형태로 임의의 스키마리스 데이터를 저장할 수 있음
- json과 같이 중첩된 데이터 구조도 취급할 수 있어 간단한 분산 KVS라기보다는 도큐먼트 스토어로 사용할 수 있음
- P2P형 문산 아키텍터를 갖고 있음
- 미리 설정한 초단위의 요청 수에 따라 노드가 증감되는 특징이 있음 -> 읽기 및 쓰기에 지연이 발생하면 곤란한 어플리케이션에 유용
- DynamoDB의 데이터를 분석하려면, 동일하게 AWS 서비스인 EMR 및 Redshift 등과 결합하여 Hive에 의한 배치 처리를 실행하거나 데이터 웨어하우스에 데이터를 전송하도록 함

### 와이드 칼럼 스토어 
- 분산 KVS를 발전시켜 2개 이상의 임의의 키에 데이터를 저장할 수 있도록 한 것
- 내부적으로 행 키와 칼럼 명의 조합에 대해 값을 저장
- 테이블에 새로운 행을 추가하는 것과 마찬가지로 칼럼도 얼마든지 추가할 수 있는 구조
- 수억의 칼럼을 만들 수 있음
- 하나의 테이블에 가로와 세로의 2차원에 데이터를 쓸 수 있도록 한 것
- 데이터를 집계하는 데는 적합하지 않음 -> 집계를 위해서는 분산된 모든 노드에서 데이터를 모아야 하기 때문

### Apache Cassandra
- 내부적인 데이터 저장소로 와이드 칼럼 스토어를 이용하면서도 'CQL'이라는 높은 수준의 쿼리 언어가 구현되어 있어 SQL과 동일한 감각으로 테이블 조작 가능
- 테이블의 스키마를 결정할 필요가 있기 때문에 구조화 데이터만을 취급할 수 있음
- 언뜻보면 RDB와 비슷하지만, 쿼리의 의미는 SQL과는 많은 점에서 다름
- P2P형 분산 아키텍처를 가짐
- 지정한 키에 의해 결정한 노드에 해당 키와 관련된 모든 값을 저장

### 도큐먼트 스토어
- NoSQL 데이터베이스를 대표하는 또 하나의 형태
- 데이터 처리의 유연성을 목적 -> JSON처럼 복잡하게 뒤얽힌 스키마리스 데이터를 그대로의 형태로 저장하고 쿼리를 실행할 수 있도록 함
  - 와이드 칼럼 스토어가 주로 성능 향상을 목표로 함
- 배열과 연상 배열(맵 형)과 같은 중첩된 데이터 구조에 대해 인덱스를 만들거나 도큐먼트 일부만을 치환하는 식의 쿼리를 쉽게 실행할 수 있음
- 스키마를 정하지 않고 데이터를 처리할 수 있음 -> 외부에서 들여온 데이터를 저장하는데 적합

### MongoDB
- 오픈소스의 분산형 도큐먼트 스토어
- 자바스크립트나 각종 프로그래밍언어를 사용하여 데이터를 읽고 쓸 수 있음
- 여러 노드에 데이터를 분산할 수 있지만, 그 자체는 대량의 데이터를 집계하는 데 적합하지 않음
- 데이터 분석이 목적인 경우, 역시 쿼리 엔진으로부터 접속하는 등 데이터를 추출할 필요 있음

### 검색 엔진
- 텍스트 데이터를 전문 검색하기 위해 '역 색인'을 만드는 부분
- 데이터를 기록하는 시스템 부하 및 디스크 소비량은 커지지만, 그 덕분에 키워드 검색이 훨씬 고속화됨
- 색인을 만듦으로써 데이터를 찾는 것에 특화 -> 데이터 집계에 적합
  - NoSQL 데이터베이스가 성능 향상을 위해 색인 작성 제한
- 장기적으로 데이터를 축적하기보다는 실시간 집계 시스템의 일부로 이용됨

### Elastic Search
- 오픈소스의 검색 엔진
- Logstash: 로그 수집 소프트웨어
- Kibana: 시각화 소프트웨어
- 임의의 JSON 데이터를 저장할 수 있기 때문에 도큐먼트 스토어와 비슷하지만, 아무것도 지정하지 않으면 모든 필드에 색인이 만들어짐
- 텍스트 데이터에서는 역 색인이 구축됨
- 간단한 도큐먼트 스토어와 비교하면 쓰기의 부하가 큼
- 필요에 따라 명시적으로 스키마를 결정함으로써 색인을 무효로 하는 식의 튜닝이 필요
- 자체 쿼리 언어에 의한 고급 집계 기능을 제공
- 열 지향 스토리지에도 대응하고 있어 그것만으로도 데이터를 집계하기 위한 기반이 됨

### Splunk
- 오픈 소스는 아니지만, 상용 검색 엔진으로 텍스트 데이터를 집계하기 위한 도구
- 주로 비정형 데이터, 웹서버나 네트워크 기기로부터 출력되는 로그 파일이나 JSON 파일을 다루어 텍스트 처리를 해야만 분석할 수 있는 데이터
- 검색을 실핼할 때 텍스트에서 필드가 추출됨
- 처음에 키워드 검색을 통해 로그를 찾으면 패턴 매치에 의해 키와 값이 추출됨
- 검색할때마다 데이터가 구조화되게 되어 있어 쿼리를 다시 작성함으로써 어떤 테이블이라도 유연하게 만들어낼 수 있음

## 워크플로 관리 도구의 종류
- 선언형 declarative: XML, YAML 등의 서식으로 워크플로를 기술하는 타입
  - 미리 제공된 기능만 이용할 수 있음
  - 누가 작성해도 동일한 워크플로가 되기 때문에 유지 보수성이 높아짐
  - 동일 쿼리를 파라미터만 바꾸어 여러번 실행하는 경우
  - 워크플로를 단순 반복적으로 자동 생성하는 경우
- 스크립트형 scripting: 스크립트 언어로 워크플로를 정의하는 유형
  - 일반적인 스크립트와 동일하게 변수 제어 구문을 사용할 수 있으므로, 태스크의 정의를 프로그래밍할 수 있음
  - 스크립트 언어에 의해 데이터 처리를 태스크 안에서 실행하는 것도 가능
  - 파일의 문자 코드를 변환하면서 서버에 업로드를 식 태스트에 유리함 

### 백필 backfil
- 실패한 플로우를 복구하는 방법 중 하나
- 플로우 전체를 처음부터 다시 실행하는 것


### DAG
- 새로운 프레임워크에 공통으로 들어가는 것 -> DAG
- DAG: 방향성 비순환 그래프 Directed acyclic graph
  - 노드와 노드가 화살표로 연결된다(방향성)
  - 화살표를 아무리 따라가도 동일 노드로는 되돌아오지 않는다(비순환)
  - DAG의 노드를 다시 나열하면, 화살표의 순서 관계를 유지하면서 하나의 순열로 할 수 있다(위상정렬)
- 데이터 플로우에서는 실행해야 할 일련읱 태스크를 DAG에 의한 데이터 구조로 표현함
- DAG를 구성하는 각 노드가 모두 동시 병행으로 실행됨
- DAG에 의한 프로그래밍 특징 -> 지연평가 lazy evaluation
  - 프로그램의 각 행은 실제로는 DAG의 데이터 구조를 조립하고 있을 뿐, 거기서 특별히 뭔가를 처리하지는 않음
  - 먼저 DAG를 구축하고 그 후에 명시적 혹은 암묵적으로 실행 결과를 요구함에 따라 데이터 처리가 시작됨
- 먼저 데이터 파이프라인 전체를 DAG로 조립하고나서 실행에 옮김으로써 내부 스케줄러가 분산 시스템에 효과적인 실행 계획을 세워주는 것이 장점

## 데이터 웨어하우스 구축
- 로드되는 데이터를 만드는 부분까지가 데이터 플로우의 역할
- 비구조화 데이터를 가공하여 CSV 파일 등을 만들어 분산 스토리지에 써넣음
- 그 이후의 태스크 실행이나 SQL에 의한 쿼리의 실행은 워크플로에 맡김

## 쿼리 엔진을 사용한 데이터 마트 구축
- 구조화 데이터를 만드는 부분까지가 데이터 플로우의 역할
- 분산 스토리지 상의 데이터를 매일 반복되는 배치로 가공하여 열 지향의 스토리지 형식으로 보관
- 쿼리 엔진을 사용한 SQL 실행이나 그 결과를 데이터 마트에 써서 내보내는 것은 워크플로에서 실행

### 배치처리
- 데이터가 분석할 수 있게 될 때 까지 시간이 걸림
- 집계 효율을 높이기 위해 열 지향 스토리지를 만들려고 하면, 데이터를 모아서 변환하는 데 일정 시간이 필요
- 받은 데이터를 분산 스토리지에 보관하는 부분부터 시작하는 것
- 대체로 1년 이상의 장기적인 데이터 분석을 예상한 스토리지를 구축하는 부분부터 시작
- 모아둔 데이터를 한번에 처리하지 않으면 효율이 떨어지므로, 1시간마다 비교적 큰 단위로 데이터 처리
- 배치 처리의 사이클이 올 때까지는 데이터를 볼 수 없어 실시간 집계에는 적합하지 않음
- 과거 데이터를 집계하고 싶을 때 적합
- 먼저 데이터가 있고, 그것을 작게 나눠서 DAG로 흘려 넣음

### 스트림처리
- 분산 스토리지를 거치지 않고 계속하는 것
- 실시간성이 우수하지만, 과거의 데이터를 취급하는 데에는 부적합
- 처리 내용을 변경하면 새롭게 도달한 데이터에는 적용되지만, 이미 처리가 끝난 과거 데이터까지는 변경되지 않음
- 앞으로 도달할 데이터에만 흥미가 있다면 스트림처리가 적합
- 끊임없이 데이터가 생성되며, 그것이 DAG 안에 흘러들어옴에 따라 처리가 진행됨

## Spark 스트리밍의 DAG
- Spark는 원래 배치 처리를 위한 분산 시스템
- Spark 스트리밍으로 불리는 기능이 통합됨으로써 현재는 스트림 처리까지 투명하게 취급하는 프레임워크가 되었음
- 하나의 프레임워크에서 통합적인 데이터 처리를 할 수 있는게 장점

### 람다 아키텍처
- 데이터 파이프라인을 3개의 레이어로 구분
- 배치 레이어: 반드시 모든 데이터를 처리
  - 과거의 데이터를 장기적인 스토리지에 축적하고, 여러번이고 다시 집계할 수 있도록
  - 대규모 배치처리를 실행할 수 있는 반면에, 1회 처리에는 긴 시간이 걸림
- 서빙 레이어: 배치처리의 결과를 접근
  - 여기에 응답이 빠른 데이터베이스를 설치하여 집계 결과를 바로 추출하도록
  - 배치 뷰: 서빙 레이어에서 얻어진 결과 -> 정기적으로 업데이트되지만, 실시간 정보를 얻을 수 없음
- 스피드 레이어: 스트림처리를 위함
  - 실시간 뷰: 스피드 레이어에서 얻은 결과 -> 배치 뷰가 업데이트될 때 까지만 이용되고, 오래된 데이터를 순서대로 삭제됨
- 배치뷰와 실시간뷰를 모두 조합시키는 형태로 쿼리 진행
- 배치 처리와 스트림 처리의 결점을 보완하고자 하는 아키텍처
- 장점
  - 실시간 뷰의 결과는 나중에 배치뷰로 치환된다는 것
  - 스트림 처리의 결과는 일시적으로만 사용되고, 잠시 기다리면 배치 처리에 의해 올바른 결과를 얻을 수 있음
  - 스트림 처리가 정확하지 않아도 길게 보면 문제가 없음
  - 배치처리만 안정되게 동작하고 있다면 스트림처리를 다시 실행할 필요가 없음
- 단점
  - 나쁜 개발 효율 -> 스피드 레이어와 배피 레이어는 모두 똑같은 처리를 구현하고 있어서 번거로움

### 카파 아키텍처
- 람다 아키텍처를 단순화한 것
- 람다 아키텍처로부터 배치 레이어나 서빙 레이어를 완전히 제거하고 스피드 레이어만 남김
- 대신 메시지 브로커의 데이터 보관 기간을 충분히 길게하여 문제가 일어났을 때 메시지 배송 시간을 과거로 다시 설정 -> 과거의 데이터가 다시 스트림 처리로 흘러 들어 실질적으로 재실행이 이루어짐
- 배치처리와 같은 과거 데이터의 일괄처리를 스트림 처리만으로 실행할 수 있음
- 단점
  - 부하가 높아진다는 것
  - 스트림 처리의 데이터 플로우에 대량의 과거 데이터를 흘려보내면, 평상시와 비교해 많은 자원을 일시적으로 소비하게 됨

### 아웃 오브 오더의 데이터 문제
- 늦게 도달하는 메시지, 즉 프로세스 시간과 이벤트 시간의 차이
- 이벤트 시간 윈도윙: 이벤트 시간에 의해 윈도우를 나누는 것
- 이벤트 시간으로 보면, 메시지가 배송된 데이터는 무작위 순으로 나열된, 즉 아웃 오브 오더 상태이므로, 적절히 순서를 바꿔 집계 결과를 업데이트해야 함


### Amazon Redshift
- 데이터 웨어하우스를 위한 MPP데이터베이스
- 스토리지와 계산 노드가 일체화되어 있어 보존할 데이터 양이 늘어나면 그것에 맞추어서 노드를 확정할 필요가 있음
- 전통적인 데이터 웨어하우스와 같은 구조여서 이용 빈도가 적은 데이터를 대량으로 보존해두는 데에는 그다지 적합하지 않음