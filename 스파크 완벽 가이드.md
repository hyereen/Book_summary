

# 하둡 완벽 가이드

# Part 1: 빅데이터와 스파크 간단히 살펴보기
## 1장 아파치 스파크란
- 아파치 스파크: 통합 컴퓨팅 엔진, 클러스터 환경에서 데이터를 병렬로 처리하는 라이브러리 집합

### 1.1 아파치 스파크의 철학
- 통합: 스파크는 간단한 데이터 읽기에서부터 SQL 처리, 머신러닝, 스트림 처리를 같은 연산 엔진과 일관성 있는 API로 수행할 수 있도록 설계
- 컴퓨팅 엔진
  - 저장소 시스템의 데이터를 연산하는 역할만 수행하고 영구 저장소 역할은 수행하지 않음
  - 스파크는 내부에 데이터를 오랜 시간 저장하지 않고 특정 저장소 시스템을 선호하지 않음

## 2장 스파크 간단히 살펴보기
### 2.1 스파크의 기본 아키텍처
#### 2.1.1 스파크 애플리케이샨
- 드라이버 프로세스
  - 클러스터 도느 중 하나에서 실행됨
  - main함수를 실행함
  - 스파크 애플리케이션 정보의 유지 관리, 사용자 프로그램이나 입력에 대한 응답, 전반적인 익스큐터 프로세스의 작업과 관련된 분석, 배포, 스케줄링 역할
  - 스타크 애플리케이션의 수명 주기 동안 관련 정보 모두 유지
  - 주어진 작업을 완료하기 위해 드라이버 프로그램의 명령을 익스큐터에서 실행할 책임이 있음
- 익스큐터 프로세스
  - 드라이버 프로세스가 할당한 작업을 수행
  - 드라이버가 할당한 코드를 실행하고 진행상황을 다시 드라이버 노드에 보고하는 역할 수행
  - 스파크 코드를 실행하는 역할
- 클러스터 매니저
  - 스파크 스탠드얼론 클러스터 매니저, 하둡 YARN, 메소스 중 하나 선택 가능
  - 하나의 클러스터에서 여러 개의 스파크 애플리케이션 실행 가능
  - 스파크는 사용가능한 자원을 파악하기 위해 클러스터 매니저를 사용

### 2.2 스파크의 다양한 언어 API
- 사용자는 스파크 코드를 실행하기 위해 SparkSession 객체를 진입점으로 사용할 수 있음
- 파이썬이나 R로 스파크를 사용할 때는 JVM 코드를 명시적으로 작성 X
- 스파크는 사용자를 대신해 파이썬이나 R로 작성한 코드를 익스큐터의 JVM에서 실행할 수 있는 코드로 변환함

### 2.3 스파크 API
- 다양한 언어로 스파크를 사용할 수 있는 이유는 스파크가 기본적으로 두가지 API를 제공하기 때문
  - 저수준 비구조적 API
  - 고수준 구조적 API

### 2.5 SparkSession
- 스파크 애플리케이션은 SparkSession이라고 불리는 드라이버 프로세스를 제어함
- SparkSession 인스턴스
  - 사용자가 정의한 처리 명령을 클러스터에서 실행
  - 하나의 SparkSession은 하나의 스파크 애플리케이션에 대응

### 2.6 DataFrame
- 가장 대표적인 구조적 API
- 스키마: 컬럼과 컬럼의 타입을 정의한 목록
- 스파크 DataFrame은 수천 대의 컴퓨터에 분산되어 있음
- Pandas나 R의 DataFrame에는 분산 컴퓨터가 아닌 단일 컴퓨터에 존재함 -> 데이터프레임으로 수행할 수 있는 작업이 해당 머신이 가진 자원에 따라 제한될 수 밖에 없음

### 2.6.1 파티션
- 스파크는 모든 익스큐터가 병렬로 작업을 수행할 수 있도록 파티션이라 불리는 청크 단위로 데이터를 분할함
- 파티션: 클러스터의 물리적 머신에 존재하는 로우의 집합을 의미
- 데이터프레임의 파티션은 실행 중에 데이터가 컴퓨터 클러스터에서 물리적으로 분산되는 방식을 나타냄
  - 만약 파티션이 하나라면 스파크의 수천 개의 익스큐터가 있더라도 병렬성은 1이 됨
  - 수백 개의 파티션이 있더라도 익스큐터가 하나 밖에 없다면 병렬성은 1이됨
- 데이터프레임을 사용하면 파티션을 수동 혹은 개별적으로 처리할 필요가 없음
- 물리적 파티션에 데이터 변환용 함수를 지정하면 스파크가 실제 처리 방법을 결정함

## 2.7 트랜스포메이션
- 스파크 핵심 데이터 구조는 불변성 -> 한번 생성하면 변경할 수 없음
- 데이터프레임을 변경하려면 원하는 변경 방법을 스파크에게 알려줘야 함 -> 이때 사용하는 명령을 트랜스포메이션이라고 함
- 변수에 값을 저장하는 코드를 실행해도 결과는 출력되지 않음 -> 추상적인 트랜스포메이션만 지정한 상태이기 때문에 액션을 호출하지 않으면 스파크는 실제 트랜스포메이션을 실행하지 않음
- 트랜스포메이션 유형
  - 좁은 의존성
    - 각 입력 파티션이 하나의 출력 파티션에만 영향을 미침
    - where 구문은 좁은 의존성을 가짐 
    - 하나의 파티션이 하나의 출력 파티션에만 영향을 미침
    - 스파크에서 파이프라이닝을 자동으로 수행 -> 데이터프레임에 여러 필터를 지정하는 경우 모든 작업이 메모리에서 일어남
  - 넓은 의존성
    - 하나의 입력 파티션이 여러 출력 파티션에 영향을 미침
    - 클러스터에서 파티션을 교환하는 셔플이 동작하여 셔플의 결과를 디스크에 저장함

### 2.7.1 지연 연산
- 지연 연산 lazy evaluation: 스파크가 연산 그래프를 처리하기 직전까지 기다리는 동작 방식을 의미
- 스파크는 특정 연산 명령이 내려진 즉시 데이터를 수정하지 않고 원시 데이터에 적용할 트랜스포메이션의 실행 계획을 생성함
- 스파크는 코드를 실행하는 마지막 순간까지 대기하다가 원형 데이터프레임 트랜스포메이션을 간결한 물리적 실행 계획으로 컴파일함
- 스파크는 이 대기 과정을 거치며 전체 데이터 흐름을 최적화하는 엄청난 강점을 가지고 있음
- 예시: 데이터 프레임의 조건절 푸시다운 predicate pushdown
- 아주 복잡한 스파크 잡이 원시 데이터에서 하나의 로우만 가져오는 필터를 가지고 있다면 필요한 레코드 하나만 읽는 것이 효율적 -> 스파크는 이 필터를 데이터소스로 위임하는 최적화 작업을 자동을 수행

## 2.8 액션
- 사용자는 트랜스포메이션을 사용해 논리적 실행 계획을 세울 수 있음
- 하지만 실제 연산을 수행하려면 액션 명령을 내려야 함
- 액션은 일련의 트랜스포메이션으로부터 결과를 계산하도록 지시하는 명령
- 액션 유형
  - 콘솔에서 데이터를 보내는 액션
  - 각 언어로 된 네이티브 객체에 데이터를 모으는 액션
  - 출력 데이터소스에 저장하는 액션
- 액션을 지정하면 스파크 잡이 시작됨
- 스파크 잡은 필터(좁은 트랜스포메이션)를 수행한 후 파티션별로 레코드 수를 카운트(넓은 트랜스포메이션)함
- 그리고 각 언어에 적합한 네이티브 객체를 모음
- 이때 스파크가 제공하는 스파크 UI로 클러스터에서 실행중인 스파크 잡을 모니터링할 수 있음

## 2.9 스파크UI
- 스파크 잡의 진행 상황을 모니터링할 때 사용
- 드라이버 노드의 4040 포트로 접속 가능
- 스파크 잡 상태, 환경 설정, 클러스터 상태 등 확인
- 스파크 잡을 튜닝하고 디버깅할 때 매우 유용
- 스파크 잡은 개별 액션에 의해 트리거되는 다수의 트랜스포메이션으로 이루어져 있으며 스파크 UI로 잡을 모니터링할 수 있음

### 2.10.1 Dataframe과 SQL
- 스파크는 언어 상관없이 같은 방식으로 트랜스포메이션을 실행할 수 있음
- 스파크는 SQL쿼리를 데이터프레임 코드와 같은 실행 계획으로 컴파일하므로 둘 사이의 성능의 차이가 없음
- 스파크는 해당 데이터프레임이나 자신의 원본 데이터프레임에 액션이 호출되기 전까지 데이터를 읽지 않음

# 3장 스파크 기능 둘러보기
## 3.1 운영용 애플리케이션 실행하기
- spark-submit 명령
  - 대화형 셸에서 개발한 프로그램을 운영용 애플리케이션으로 쉽게 전환 가능
  - 애플리케이션 코드를 클러스터에 전송해 실행시키는 역할
  - 애플리케이션 실행에 필요한 자원과 실행 방식, 옵션을 지정 가능
  - master 옵션의 인숫값을 변경하면 스파크가 지원하는 스파크 스탠드얼론, 메소스, YARN 클러스터 매니저에서 동일한 애플리케이션 실행 가능

## 3.2 Dataset: 타입 안정성을 제공하는 구조적 API
- Dataset
  - 자바와 스칼라의 정적 데이터 타입에 맞는 코드 -> 정적 타입 코드를 지원하기 위해 고안된 스파크의 구조적 API
  - 타입안정성을 지원하며 동적타입 언어인 파이썬과 R에서는 사용 X
  - 데이터프레임의 레코드를 사용자가 자바나 스칼라로 정의한 클래스에 할당하고 자바의 ArrayList 또는 스칼라의 Seq 객체 등의 고정 타입형 컬렉션으로 다룰 수 있는 기능 제공
  - 장점
    - 필요한 경우에 선택적으로 사용 가능
    - 스파크가 제공하는 여러 함수를 이용해 추가 처리 작업 가능
    - collect 메서드나 take 메서드를 호출하면 Dataset에 매개변수로 지정한 타입의 객체를 반환
    - 코드 변경 없이 타입 안정성을 보장, 로컬이나 분산 클러스터 환경에서 데이터를 안전하게 다룰 수 있음

## 3.3 구조적 스트리밍
- 구조적 스트리밍: 스파크 2.2 버전에서 안정화된 스트림 처리용 고수준 API
- ㄴ 사용하면 구조적 API로 개발된 배치 모드의 연산을 스트리밍 방식으로 실행 가능, 지연 시간을 줄이고 증분 처리 가능
- 배치 처리용 코드를 일부 수정하여 스트리밍 처리를 수행하고 값을 빠르게 얻을 수 있다는 장점