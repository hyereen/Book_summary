

# 하둡 완벽 가이드

# Part 1: 빅데이터와 스파크 간단히 살펴보기
## 1장 아파치 스파크란
- 아파치 스파크: 통합 컴퓨팅 엔진, 클러스터 환경에서 데이터를 병렬로 처리하는 라이브러리 집합

### 1.1 아파치 스파크의 철학
- 통합: 스파크는 간단한 데이터 읽기에서부터 SQL 처리, 머신러닝, 스트림 처리를 같은 연산 엔진과 일관성 있는 API로 수행할 수 있도록 설계
- 컴퓨팅 엔진
  - 저장소 시스템의 데이터를 연산하는 역할만 수행하고 영구 저장소 역할은 수행하지 않음
  - 스파크는 내부에 데이터를 오랜 시간 저장하지 않고 특정 저장소 시스템을 선호하지 않음

## 2장 스파크 간단히 살펴보기
### 2.1 스파크의 기본 아키텍처
#### 2.1.1 스파크 애플리케이샨
- 드라이버 프로세스
  - 클러스터 도느 중 하나에서 실행됨
  - main함수를 실행함
  - 스파크 애플리케이션 정보의 유지 관리, 사용자 프로그램이나 입력에 대한 응답, 전반적인 익스큐터 프로세스의 작업과 관련된 분석, 배포, 스케줄링 역할
  - 스타크 애플리케이션의 수명 주기 동안 관련 정보 모두 유지
  - 주어진 작업을 완료하기 위해 드라이버 프로그램의 명령을 익스큐터에서 실행할 책임이 있음
- 익스큐터 프로세스
  - 드라이버 프로세스가 할당한 작업을 수행
  - 드라이버가 할당한 코드를 실행하고 진행상황을 다시 드라이버 노드에 보고하는 역할 수행
  - 스파크 코드를 실행하는 역할
- 클러스터 매니저
  - 스파크 스탠드얼론 클러스터 매니저, 하둡 YARN, 메소스 중 하나 선택 가능
  - 하나의 클러스터에서 여러 개의 스파크 애플리케이션 실행 가능
  - 스파크는 사용가능한 자원을 파악하기 위해 클러스터 매니저를 사용

### 2.2 스파크의 다양한 언어 API
- 사용자는 스파크 코드를 실행하기 위해 SparkSession 객체를 진입점으로 사용할 수 있음
- 파이썬이나 R로 스파크를 사용할 때는 JVM 코드를 명시적으로 작성 X
- 스파크는 사용자를 대신해 파이썬이나 R로 작성한 코드를 익스큐터의 JVM에서 실행할 수 있는 코드로 변환함

### 2.3 스파크 API
- 다양한 언어로 스파크를 사용할 수 있는 이유는 스파크가 기본적으로 두가지 API를 제공하기 때문
  - 저수준 비구조적 API
  - 고수준 구조적 API

### 2.5 SparkSession
- 스파크 애플리케이션은 SparkSession이라고 불리는 드라이버 프로세스를 제어함
- SparkSession 인스턴스
  - 사용자가 정의한 처리 명령을 클러스터에서 실행
  - 하나의 SparkSession은 하나의 스파크 애플리케이션에 대응

### 2.6 DataFrame
- 가장 대표적인 구조적 API
- 스키마: 컬럼과 컬럼의 타입을 정의한 목록
- 스파크 DataFrame은 수천 대의 컴퓨터에 분산되어 있음
- Pandas나 R의 DataFrame에는 분산 컴퓨터가 아닌 단일 컴퓨터에 존재함 -> 데이터프레임으로 수행할 수 있는 작업이 해당 머신이 가진 자원에 따라 제한될 수 밖에 없음

### 2.6.1 파티션
- 스파크는 모든 익스큐터가 병렬로 작업을 수행할 수 있도록 파티션이라 불리는 청크 단위로 데이터를 분할함
- 파티션: 클러스터의 물리적 머신에 존재하는 로우의 집합을 의미