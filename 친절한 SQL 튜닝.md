# 친절한 SQL 튜닝
- 개발자를 위한 SQL 튜닝 입문서
- DB 프로그래밍에 어느정도 경험이 쌓였는데도 성능 문제를 스스로 해결하지 못해 늘 고민하는 사람을 위한 책

## 1. SQL 처리과정과 I/O
### 1.1 SQL 파싱과 최적화
- SQL은 기본적으로 구조적, 집합적, 선언적인 질의 언어
- 원하는 결과를 구조적, 집합적으로 선언하지만, 그 결과집합을 만드는 과정은 절차적 -> 프로시저 필요
- SQL 옵티마이저: 프로시저를 만들어내는 DBMS 내부 엔진
- SQL 최적화: DBMS 내부에서 프로시저를 작성하고 컴파일해서 실행 가능한 상태로 만드는 전 과정

#### 1.1.2 SQL 최적화
- SQL 실행하기 전 최적화 과정
  1. SQL 파싱
     - 사용자로부터 SQL을 전달받으면 가장 먼저 SQL 파서가 파싱을 진행
     - 파싱 트리 생성: SQL 문을 이루는 개별 구성 요소를 분석해서 파싱트리 생성
     - Syntax 체크: 문법적 오류가 없는지 확인
     - Semantic 체크: 의미상 오류가 없는지 확인
  2. SQL 최적화
     - 옵티마이저: 미리 수집한 시스템 및 오브젝트 통계정보를 바탕으로 다양한 실행 경로를 생성해서 비교한 후 가장 효율적인 하나를 선택
     - 데이터베이스 성능을 결정하는 가장 핵심적인 엔진
  3. 로우 소스 생성
     - 로우 소스 생성기: SQL 옵티마이저가 선택한 실행 경로를 실제 실행 가능한 코드 또는 프로시저 형태로 포맷팅하는 단계

#### 1.1.3 SQL 옵티마이저
- SQL 옵티마이저: 사용자가 원하는 작업을 가장 효율적으로 수행할 수 있는 최적의 데이터액세스 경로를 선택해주는 DBMS의 핵심 엔진
- 옵티마이저의 최적화 단계 
  1. 사용자로부터 전달받은 쿼리를 수행하는 데 후보군이 될만한 실행계획들을 찾아냄
  2. 데이터 딕셔너리에 미리 수집해 둔 오브젝트 통계 및 시스템 통계정보를 이용해 각 실행계획의 예상비용 산정
  3. 최저 비용을 나타내는 실행계획 선택

### 1.2 SQL 공유 및 재사용
#### 1.2.1 소프트 파싱 vs 하드 파싱
- 라이브러리 캐시
  - SQL 파싱, 최적화, 로우 소스 생성 과정을 거쳐 생성한 내부 프로시저를 반복 재사용할 수 있도록 캐싱해 두는 메모리 공간
  - SGA 구성요소 중 하나
  - ㄴ SGA(System Global Area): 서버 프로세스와 백그라운드 프로세스가 공통으로 액세스하는 데이터와 제어구조를 캐싱하는 메모리 공간
  - 필요한 이유
    - 데이터베이스에서 이루어지는 처리과정은 대부분 IO작업에 집중되지만, 하드 파싱은 CPU를 많이 소비하는 작업
    - 이렇게 생성한 내부 프로시저를 한 번만 사용하고 버린다면 비효율이므로 라이브러리 캐시가 필요
- 소프트 파싱 Soft parsing: 사용자가 SQL문을 전달하면 DBMS는 SQL을 파싱한 후 해당 SQL이 라이브러리 캐시에 존재해서 곧바로 실행 단계로 넘어가는 것
- 하드 파싱 Hard parsing: 사용자가 SQL문을 전달하면 DBMS는 SQL을 파싱한 후 해당 SQL이 라이브러리 캐시에 존재하지 않아 찾는 데 실패해 최적화 및 로우 소스 생성 단계까지 모두 거치는 것

#### 1.2.2 바인드 변수의 중요성
- 이름없는 SQL 문제
  - SQL은 따로 이름이 없음 
  - 전체 SQL 텍스트가 이름 역할을 함
  - 처음 실행할 때 최적화 과정을 거쳐 동적으로 생성한 내부 프로시저를 라이브러리 캐시에 적재함으로써 여러 사용자가 공유하면서 재사용함
  - 캐시 공간이 부족하면 버려졌다가 다음에 다시 실행할 때 똑같은 최적화 과정을 거쳐 캐시에 적재됨
  - SQL 자체가 이름이기 때문에 텍스트 중 작은 부분이라도 수정되면 그 순간 다른 객체가 새로 탄생하는 구조
  - DBMS에서 수행되는 SQL이 모두 완성된 것은 아니므로 모두 저장하면 많은 공간이 필요하고 SQL을 찾는 속도도 느려짐 -> 오라클 같은 DBMS가 SQL 영구 저장을 하지 않음
  - 공유가능 SQL
    - 프로시저를 여러 개 생성하는 것이 아니라 파라미터가 있는 프로시저 하나를 공유하면서 재사용 하는 것이 낫다
    - 파라미터 Driven 방식으로 SQL을 작성하는 방법이 제공됨 -> 바인드 변수
    - 하드파싱은 최초에 한번만 일어나고 캐싱된 SQL을 여러 사람이 공유하면서 재사용하게 됨

### 1.3 데이터 저장 구조 및 I/O 메커니즘
#### 1.3.1 SQL이 느린 이유
- SQL이 느린 이유는 디스크 I/O 때문

#### 1.3.2 데이터베이스 저장 구조
- 데이터를 저장하려면 먼저 테이블스페이스를 생성해야 함
- 테이블스페이스
  - 세그먼트를 담는 콘테이너
  - 여러 개의 데이터파일(디스크 상의 물리적인 OS파일)로 구성됨
- 테이블 스페이스 > 세그먼트 > 익스텐트 > 블록 > 로우 
- 세그먼트: 데이터 저장공간이 필요한 오트벡트(테이블, 인덱스, 파티션, LOB 등)
  - 테이블, 인덱스처럼 데이터 저장공간이 필요한 오브젝트, 여러 익스텐트로 구성됨
- 테이블, 인덱스를 생성할 때 데이터를 어떤 테이블 스페이스에 저장할 지를 지정
- 파티션 구조가 아니라면 테이블도, 인덱스도 각각 하나의 세그먼트가 됨
- 테이블 또는 인덱스가 파티션 구조라면, 각 파티션이 하나의 세그먼트가 된다.
- LOB 컬럼은 그 자체가 하나의 세그먼트를 구성하므로 자신이 속한 테이블과 다른 별도의 공간에 값을 저장 
  - ㄴ LOB (Large Object): 그래픽이미지나 음성, 바이너리 데이터, 사이즈가 큰 텍스트 데이터를 다루는 데이터 타입
- 익스텐트: 공간을 확장하는 단위, 연속된 블록 집합
  - 공간을 확장하는 단위
  - 테이블이나 인덱스에 데이터를 입력하다가 공간이 부족해지면 해당 오브젝트가 속한 테이블 스페이스로부터 익스텐트를 추가로 할당받음
  - 연속된 블록들의 집합이기도 함
  - 한 익스텐트도 하나의 테이블이 독점 -> 한 익스텐트에 담긴 블록은 모두 같은 테이블 블록
- 블록: 데이터를 읽고 쓰는 단위
  - 익스텐트 단위로 공간을 확장하지만, 사용자가 입력한 레코드를 실제로 저장하는 공간은 데이터 블록
  - 한 블록은 하나의 테이블이 독점
  - 한 블록에 저장된 레코드는 모두 같은 테이블 레코드
- 데이터 파일: 디스크 상의 물리적인 OS 파일

#### 1.3.4 시퀀셜 액세스 vs 랜덤 액세스
- 테이블 또는 인덱스를 액세스하는(=읽는) 방식
- 시퀀셜 액세스 sequential access
  - 논리적 또는 물리적으로 연결된 순서에 따라 차례대로 블록을 읽는 방식
  - 인덱스 리프 블록은 앞 뒤를 가리키는 주소값을 통해 논리적으로 서로 연결돼 있음
  - 이 주소 값에 따라 앞 또는 뒤로 순차적으로 스캔하는 방식
  - 테이블 블록 간에는 서로 논리적인 연결고리를 갖고 있지 않으므로 대신 익스텐트 맵을 이용한다
  - 익스텐트 맵은 각 익스텐트의 첫번째 블록 주소 값을 갖는다
  - 읽어야 할 익스텐트 목록을 익스텐트 맵에서 얻고, 각 익스텐트의 첫 번째 블록 뒤에 연속해서 저장된 블록을 순서대로 읽으면 그것이 곧 Full Table Scan
- 랜덤 액세스 Random accsess
  - 논리적, 물리적인 순서를 따르지 않고 레코드 하나를 읽기 위해 한 블록씩 접근하는 방식

#### 1.3.5 논리적 I/O vs 물리적 I/O
- DB 버퍼 캐시
  - 디스크 I/O가 SQL 성능을 결정
  - SQL을 수행하는 과정에 계속해서 데이터 블록을 읽는데, 자주 읽는 블록을 매번 디스크에서 읽는 것은 매우 비효율적
  - 모든 DBMS에 데이터 캐싱 메커니즘이 필수인 이유
  - 공유 메모리 SGA 구성요소
    - 라이브러리 캐시: SQL과 실행계획, DB 저장형 함수/프로시저 등을 캐싱하는 코드캐시
    - DB 버퍼캐시: 데이터를 캐싱, 디스크에서 어렵게 읽은 데이터 블록을 캐싱해 둠으로써 같은 블록에대한 반복적인 I/O call을 줄이는 데 목적이 있음
      - 서버 프로세스와 데이터 파일 사이에 DB 버퍼 캐시가 있음
      - 데이터 블록을 읽을 땐 항상 DB 버퍼 캐시부터 탐색
      - 캐시에서 블록을 찾는다면 프로세스가 I/O call을 하지 않아도 됨
      - 같은 블록을 두 번 읽을때부터는 I/O call을 하지 않아도 됨
      - 버퍼캐시는 공유메모리 영역이므로 같은 블록을 읽는 다른 프로세스도 득을 봄

- 논리적 블록 I/O
  - SQL을 처리하는 과정에서 발생한 총 블록 I/O를 의미
  - SQL을 수행하면서 읽은 총 블록 I/O
  - 논리적 I/O를 줄이는 방법
    - SQL을 튜닝해서 읽는 총 블록 개수를 줄이면 됨
    - 논리적 I/O는 항상 일정하게 발생하지만, SQL 튜닝을 통해 줄일 수 있는 통제 가능한 내생변수
    - SQl을 튜닝해서 논리적 I/O를 줄이면 물리적 I/O도 줄고, 그만큼 성능도 향상됨
- 
- 물리적 블록 I/O
  - 디스크에서 발생한 총 블록 I/O
  - SQL 처리 도중 읽어야 할 블록을 버퍼 캐시에서 찾지 못할 때만 디스크를 액세스 하므로 논리적 블록 I/O 중 일부를 물리적으로 I/O함
  - 요약하면, bchr공식을 이루는 물리적 I/O는 통제 불가능한 외생변수
  - 메모리를 증설해서 DB 버퍼캐시 크기를 늘리는 방법 외에 이것을 직접 줄이는 방법은 없음

#### 1.3.6 Single Block I/O vs Multiple I/O
- Single Block I/O
  - 한 번에 한 블록씩 요청해서 메모리에 적재하는 방식
  - 인덱스를 이용할 때 기본적으로 인덱스와 테이블 모두 Single Block I/O 방식 사용
  - 인덱스는 소량 데이터를 읽을 때 주로 사용하므로 이 방식이 효율적
- Multiblock I/O
  - 많은 벽돌을 실어 나를 때 손수레를 이용하는 것처럼 한 번에 여러 블록씩 요청해서 메모리에 적재하는 방식
  - 많은 데이터 블록을 읽을 때 효율적
  - 인덱스를 이용하지 않고 테이블 전체를 스캔할 때 사용
  - 테이블이 클수록 Single Block I/O 단위도 크면 좋음 -> 프로세스가 잠자는 횟수를 줄여줌
    - 읽고자하는 블록을 db 버퍼캐시에서 찾지 못하면 해당 블록을 디스크에서 읽기 위해 I/O call을 함
    - 그동안 프로세스는 대기 큐에서 잠을 잠
    - 대용량 테이블이면 수 많은 블록을 디스크에서 읽는 동안 여러 차례 잠을 잘텐데, 기왕에 잠을 자려면 한꺼번에 많은 양을 요청해야 잠자는 횟수를 줄이고 성능을 높일 수 있음
    - 대용량 테이블을 Full Scan할 때 Multiblock I/O 단위를 크게 설정하면 성능이 좋아지는 이유
  - 캐시에서 찾지 못한 특정 블록을 읽으려고 I/O call할 때 시스크 상에 그 블록과 인접한 블록들을 한꺼번에 읽어 캐시에 미리 적재하는 기능
    - 인접한 블록: 같은 익스텐트에 속한 블록을 의미
      - Single Block I/O 방식으로 읽더라도 익스텐트 경계를 넘지 못한다는 뜻
  - DBMS 블록 사이즈가 얼마건 간에 OS 단에서는 보통 1MB 단위로 I/O를 수행(OS마다 다름0)

#### 1.3.7 Table Full Sacn vs. Index Range Scan
- 테이블에 저장된 데이터를 읽는 방식
  - 테이블 전체를 스캔해서 읽는 방식 = Table Full Scan
    - 테이블에 속한 블록 전체를 읽어서 사용자가 원하는 데이터를 찾는 방식
    - 시퀀셜 액세스와 Multiblock I/O 방식으로 디스크 블록을 읽음
      - 수십~수백건의 소량 데이터를 찾을 때 수백만~수천만건의 데이터를 스캔하는 것 -> 비효율적 =>큰 테이블에서 소량 데이털르 검색할때는 반드시 인덱스 이용
    - 한 블록에 속한 모든 레코드를 한 번에 읽어 들이고, 캐시에서 못찾으면 I/O Call을 통해 인접한 수십~수백개의 블록을 한꺼번에 I/O하는 메커니즘
    - 스토리지 스캔 성능이 좋아지는 만큼 성능도 좋아짐
  - 인덱스를 이용해서 읽는 방식 = Index Range Scan = 인덱스를 이용한 테이블 액세스
    - 인덱스에서 일정량을 스캔하면서 얻은 ROWID로 테이블 레코드를 찾아가는 방식
      - ROWID: 테이블 레코드가 시크으 상에 어디 저장됐는지를 가리키는 위치 정보
    - 앤덤 액세스와 Single Block I/O 방식으로 디스크 블록을 읽음
    - 캐시에서 블록을 못찾으면 레코드 하나를읽기 위해 매번 I/O Call하는 메커니즘
    - 따라서 많은 데이터를 읽을 때는 Table Full Scan보다 불리함
    - 스토리지 스캔 성능이 수십배 좋아져도 성능이 조금밖에 좋아지지 않음
    - 읽었던 블록을 반복해서 읽는 비효율이 있음
    - 많은 데이터를 일긍ㄹ때 물리적인 블록 I/O뿐만 아니라 논리적인 블록 I/O 측면에서도 불리함 -> 각 블록을 단 한번 읽는 Table Full Scan보다 훨씬 불리함
    - 인덱스는 큰 테이블에서 아주 적은 일부 데이터를 빨리 찾기 위한 도구일 뿐
    - 모든 성능 문제를 인덱스로 해결하려 해선 안됨
    - 읽을 때 데이터가 일정량을 넘으면 인덱스보다 Table Full Scan이 유리
  
#### 1.3.8 캐시 탐색 메커니즘
- Direct Path I/O 제외한 모든 블록 I/O는 메모리 버퍼 캐시를 경유함
- 메모리 공유자원에 대한 액세스 직렬화
  - 버퍼캐시: SGA 구성요소이므로 버퍼캐시에 캐싱된 버퍼블록은 모두 공유자원
  - 공유자원: 모두에게 권한이 있기 때문에 누구나 접근 가능
  - ㄴ 문제는 하나의 버퍼블록을 두 개 이상 프로세스가 동시에 접그하려고 할때마다 발생 -> 동시에 접근하면 블록 정합성에 문제가 생길 수 있음
  - 자원을 공유하는 것처럼 보여도 내부에선 한 프로세스씩 순차적으로 접근하도록 구형해야 함 -> 직렬화 메커니즘 필요
  - 래치 Latch: 줄서기가 가능하도록 지원하는 메커니즘
    - SGA를 구성하는 서브 캐시마다 별도의 래치가 존재
    - 버퍼캐시에는 캐시버퍼 체인 래치, 캐시버퍼 LRU체인 래치 등이 작동
    - 빠른 데이터베이스를 구현하려면 버퍼캐시 히트율을 높여야 하지만, 캐시 I/O도 생각만큼 빠르지 않을 수 있음 -> 이들 래치에 의한 경합이 생길 수 있기 때문
  - 버퍼블록 자체에도 직렬화 메커니즘 존재 -> 버퍼 Lock
  - 이런 직렬화 메커니즘에 의한 캐시 경합을 줄이려면, SQL 튜닝을 통해 쿼리 일량(논리적I/O) 자체를 줄여야 함

## 2. 인덱스 기본
### 2.1 인덱스 구조 및 탐색
- 인덱스 큐닝의 두 가지 핵심요소
  - 인덱스: 큰 테이블에서 소량 데이터를 검색할 때 사용
  - 온라인 트랜잭션 처리(OLTP) 시스템에서는 소량 데이터를 주로 검색하므로 인덱스 튜닝이 중요
  1. 인덱스 스캔 효율화 튜닝: 인덱스 스캔 과정에서 비효율을 줄이는 것
  2. 랜덤 액세스 최소화 튜닝: 테이블 액세스 횟수를 줄이는 것: 인덱스 스캔 후 테이블 레코드를 액세스할 때 랜덤 I/O 방식을 사용, 성능에 미치는 영향이 더 큼

- SQL 튜닝은 랜덤I/O와의 전쟁
  - 데이터베이스 성능이 느린 이유 = 다스크 I/O 때문
  - 읽어야 할 데이터량이 많고, 그 과정에 디스크 I/O가 많이 발생할 때 느림
  - 인덱스를 많이 사용하는 OLTP 시스템이라면 디스크 I/O 중에서도 랜덤 I/O가 특히 중요함
  - 조인 메소드 중 NL 조인이 대량 데이터 조인할 때 느린이유도 랜덤 I/O 때문
    - 소트머지 조인과 해시 조인도 결국 느린 랜덤I/O를 극복하기 위해서 개발된 기능
  
#### 2.1.2 인덱스 구조
- 인덱스: 대용량 테이블에서 필요한 데이터만 빠르게 효율적으로 액세스하기 위해 사용하는 오브젝트
- 데이터베이스에서도 인덱스 없이 데이터를 검색하려면, 테이블을 처음부터 끝까지 모두 읽어야 함
- 인덱스를 이용하면 일부만 읽고 멈출 수 있음 -> 범위 스캔 Range Scan이 가능함 -> 인덱스가 정렬되어 있기 때문에!
- DBMS는 일반적오르 B*Tree 인덱스를 사용
- LMC(Leftmost Child): 가장 왼쪽 끝에 위치한 블록, 가장 왼쪽 첫 번째 레코드
  - 키값을 갖지 안는 특별한 레코드
  - LMC가 가리키는 주소로 찾아간 블록에는 키값을 가진 첫 번째 레코드보다 작거나 같은 레코드가 저장돼 있음
- 리프블록에 저장된 각 레코드는 키값 순으로 정렬돼 있음 + 테이블 레코드를 가리키는 주소값, 즉 ROWID를 가짐
  - 인덱스 키값이 같으면 ROWID 순으로 정렬됨
  - 인덱스를 스캔하는 이유는, 검색 조건을 만족하는 소량의 데이터를 빨리 찾고, 거기서 ROWID를 얻기 위해서
  - ROWID는 데이터블록주소(Data Block Address)와 로우 번호로 구성되므로 이 값을 알면 테이블 레코드를 찾아갈 수 있음

#### 2.1.3 인덱스 수직적 탐색
- 정렬된 인덱스 레코드 중 조건을 만족하는 첫 번째 레코를 찾는 과정 = 인덱스 스캔 시작지점을 찾는 과정
- 인덱스 수직적 탐색은 루트 블록에서부터 시작
- 루트를 포함해 브랜치 블록에 저장된 각 인덱스 레코드는 하위 블록에 대한 주소값을 갖음 -> 루트에서 시작해 리프 블록까지 수직적 탐색이 가능한 이유
- 인덱스를 수직적으로 탐색할 때, 루트를 포함한 브랜치 블록은 등산 푯말과 같은 역할 -> 조건을 만족하는 첫 번째 레코드가 목표 지점

#### 2.1.4 인덱스 수평적 탐색
- 수직적 탐색을 통해 스캔 시작점을 찾았으면, 찾고자 하는 데이터가 더 안나타날 때 까지 인덱스 리프 블록을 수평적으로 스캔
- 인덱스에서 본격적으로 데이터를 찾는 과정
- 인덱스 리프 블록끼리는 서로 앞뒤 블록에 대한 주소값을 갖음 -> 양방향 연결 리스트 구조 -> 과우로 수평적 탐색이 가능한 이유
- 인덱스를 수평적으로 탐색하는 이유
  - 조건절을 만족하는 데이터를 모두 찾기 위해
  - ROWID를 얻기 위해
    - 필요한 컬럼을 인덱스가 모두 갖고 있어 인덱스만 스캔하고 끝나는 경우도 있지만, 일반적으로 인덱스를 스캔하고서 테이블도 액세스하므로 ROWID 필요
    
#### 결합 인덱스 구조와 탐색
- 두 개 이상 컬럼을 결합해 인덱스를 만들 수도 있음
- DBMS기 사용하는 B*Tree 인덱스는 엑셀처럼 평면 구조가 아님

### 2.2 인덱스 기본 사용법
- 인덱스 기본 사용법 = 인덱스를 Range Scan하는 방법 

#### 2.2.2 인덱스를 Range Scan할 수 없는 이유
- 인덱스 컬럼을 가공하면 인덱스를 정상적으로 사용할 수 없음 -> 인덱스 스캔 시작점을 찾을 수 없기 때문
- Index Range Scan 에서 Range는 범위를 의미 -> Index Range Scan은 인덱스에서 일정 범위를 스캔한다는 뜻
- 인덱스를 정상적으로 사용한다 = 리프 블록에서 스캔 시작점을 찾아 거기서부터 스캔하다가 중간에 멈추는 것을 의미

#### 2.2.3 더 중요한 인덱스 사용 조건
- 조건절에서 인덱스 컬럼을 가공하면 인덱스를 정상적으로 사용할 수 없음
- 인덱스를 Range Scan하기 위한 가장 첫번째 조건은 인덱스 선두 컬럼이 조건절에 있어야 함 -> 인덱스를 Range Scan하려면 인덱스 선두 컬럼이 가공되지 않은 상태로 조건절에 있어야 함
- 반대로 말해, 인덱스 선두 커럼이 가공되지 않은 상태로 조건절에 있으면 인덱스 Range Scan은 무조건 가능
- 문제는 인덱스를 Range Scan 한다고 해서 항상 성능이 좋은 건 아니라는 사실

#### 2.2.4 인덱스를 이용한 소트 연산 생략
- 인덱스를 Range Scan 할 수 있는 이유는 데이터가 정렬돼 있기 때문
- 찾고자 하는 데이터가 정렬된 상태로 서로 모여있기 때문에 전체가 아닌 일정 부분만 읽다가 멈출 수 있음
- 인덱스 컬럼을 가공해도 인덱스를 사용할 수는 있지만, 찾고자 하는 데이터가 전체 구간에 흩어져 있기 때문에 Range Scan이 불가능하거나 비효율이 발생 
- 테이블과 달리 인덱스는 정렬되어 있음 -> 우리가 인덱스를 사용하는 이유
  - 인덱스가 정렬되어 있기 때문에 우리가 사용하고, Range Scan이 가능하고, 소트 연산 생량 효과도 부수적으로 얻게 됨

#### 2.2.7 자동 형변환
- 각 조건절에서 양쪽값의 데이터 타입이 서로 다르면 값을 비교할 수 없음
- 그럴 때 타입 체크를 엄격히 함으로써 컴파일 시점에 에러를 내는 DBMS가 있고 자동으로 형변환 해주는 DBMS도 있음(오라클은 후자)
- 오라클에서 숫자형과 문자형이 만나면 숫자형이 이김 -> 숫자형 컬럼 기준으로 문자형 컬럼을 변환한다는 뜻
  - 연산자 LIKE일 때는 다름 -> LIKE 자체가 문자열 비교 연산자이므로 이때는 문자형 기준으로 숫자형 컬럼이 변환됨
- 날짜형 문자형이 만나면 날짜형이 이김
- 숫자형 컬럼을 LIKE 조건으로 검색하면 자동 형변환이 발생해 계좌번호가 아예 인덱스 액세스 조건으로 사용되지 못함
- SQL 성능은 블록 I/O를 줄일 수 있느냐 없느냐에서 결정됨
- 형변환 함수를 생략한다고 해서 연산 횟수가 주는 것도 아님 -> 형변환 함수 생략해도 옵티마이저가 자동으로 생성하기 때문

### 2.3 인덱스 확장기능 사용법
- 인덱스 스캔 방식: Index Range Scan, Index Full Scan, Index Unique Scan, Index Skip Scan, Index Fast Full Scan 

#### 2.3.1 Index Range Scan
- 인덱스의 가장 일반적이고 정상적인 형태의 액세스 방식
- 인덱스 루트에서 리프블록까지 수직적으로 탐색한 후에 필요 범위(Range)만 스캔
- 인덱스를 Range Scan하려면 선두 컬럼을 가공하지 않은 상태로 조건절에 사용해야 함
- 반대로, 선두 컬럼을 가공하지 않은 상태로 조건절에 사용하면 Index Range Scan은 무조건 가능
- 실행 계획을 보고 인덱스 잘 타니까 성능도 OK라고 생각하면 안 되는 이유 -> 성능은 인덱스 스캔 범위, 테이블 액세스 횟수를 얼마나 줄일 수 있느냐로 결정

#### 2.3.2 Index Full Scan
- 수직적 탐색 없이 인덱스 리프 블록을 처음부터 끝까지 수평적으로 탐색하는 방식
- 대개 데이터 검색을 위한 최적의 인덱스가 없을 때 차선으로 선택됨
- Index Full Scan의 효용성
  - 인덱스 선두 컬럼이 조건절에 없으면 옵티마이저는 먼저 Table Full Scan을 고려함
  - 그런데 대용량 테이블이어서 Table Full Scan에 따른 부담이 크다면 옵타이마이저는 인덱스 활용을 다시 고려하지 않을 수 없음
  - 데이터 저장 공간은 컬럼길이 X 레코드수에 의해 결정됨 -> 인덱스가 차지하는 면적은 테이블보다 훨씬 적음
  - 인덱스를 Range Scan할 수 없을 때, 면적이 큰 테이블보다 인덱스를 스캔하는 쪽이 훨씬 유리함

#### 2.3.3 Index Unique Scan
- 수직적 탐색만으로 데이터를 찾는 스캔 방식
- Unique 인덱스를 '=' 조건으로 탐색하는 경우에 작동
- Unique 인덱스가 존재하는 컬럼은 중복 값이 입력되지 않게 DBMS가 데이터 정합성을 관리해줌 -> 해당 인덱스 키 컬럼을 모두 '=' 조건으로 검색할 때는 데이터를 한 건 찾는 순간 더 이상 탐색할 필요가 없음
- Unique 인덱스가 해도 범위 조건(between, 부등호 like)로 검색할 때는 Index Range Scan으로 처리됨
- Unique 결합 인덱스에 대해 일부 컬럼만으로 검색할 때도 Index Range Scan이 skxkska

#### 2.3.4 Index Skip Scan 
- 인덱스 선두 컬럼을 조건절에 사용하지 않으면 옵티마이저는 기본적으로 Table Full Scan을 선택
- Table Full Scan보다 I/O를 줄일 수 있거나 정렬된 결과를 쉽게 얻을 수 있다면, Index Full Scan을 사용하기도 함
- 오라클이 선보인 인덱스 선두 컬럼이 조건절에 없어도 인덱스를 활용하는 스캔 방식
- 이 스캔 방법은 조건절에 따빈 인덱스 선두 컬럼의 Distinct Value 개수가 적고 후행 컬럼의 Distinct Value 개수가 많을 때 유용
- Index Skip Scan이 작동하기 위한 조건
  - Distinct Value 개수가 적은 선두 컬럼이 조건절에 없고 후행 컬럼의 Distinct Value 개수가 많을 때 효과적
  - 하지만 인덱스 선두 컬럼이 없을 때만 Index Skip Scan이 작동하는 것은 아님
  - Index Range Scan이 불가하거나 효율적이지 못한 상황에서 Index Skip Scan이 효율적인 경우가 있음
  - 부분범위 처리가 가능하다면 Index Full Scan이 도움이 되기도 함
  - 하지만 이 스캔 방식이 최선책일 수는 없음 -> 인덱스는 기본적으로 최적의 Index Range Scan을 목표로 설계해야 함
  - 수행 횟수가 적은 SQL을 위해 인덱스를 추가하는 것이 비효율적일 때, 이들 스캔 방식을 차선책으로 활용하는 전략이 바람직함

#### 2.3.5 Index Fast Full Scan 
- 말 그래도 Index Full Scan보다 빠름 -> 논리적인 인덱스 트리 구조를 무시하고 인덱스 세그먼트 전체를 Multiblock I/O 방식으로 스캔하기 때문
- 물리적으로 디스크에 저장된 순서대로 인덱스 리프블록을 읽음
- Multiblock I/O 방식을 사용하므로 디스크로부터 대량의 인덱스 블록을 읽어야 할 때 큰 효과를 발휘함
- 속도는 빠르지만, 인덱스 리프 노드가 갖는 연결 리스트 구조를 무시한 채 데이터를 읽기 때문에 결과 집합이 인덱스 키 순서대로 정렬되지 않음
- 쿼리에 사용한 컬럼이 모두 인덱스에 포함되어 있을 때만 사용 가능
- Index Range Scan 또는 Index Full Scan과 달리, 인덱스가 파티션 돼 있지 않더라도 병렬 쿼리가 가능 -> 병렬 쿼리 시, Direct path I/O 방식을 사용하기 때문에 I/O 속도가 더 빠름

#### 2.3.6 Index Range Scan Descending
- Index Range Scan과 기본적으로 동일한 스캔 방식
- 인덱스를 뒤에서 앞으로 스캔하기때문에 내림차순으로 정렬된 결과 집합을 얻는다는 점만 다름


## 3. 인덱스 튜닝
### 3.1 테이블 액세스 최소화
- SQL 튜닝은 랜덤 I/O와의 전쟁
- SQL 성능 향상을 위해 DBMS가 제공하는 많은 기능은 느린 랜덤 I/O 극복을 위해 개발됨
- 조인 메소드의 발전, 많은 튜닝 기법도 랜덤 I/O 최소화에 맞춰져 있음

#### 3.1.1 테이블 랜덤 액세스
- 아무리 데이터가 많아도 인덱스를 사용하니까 데이터가 금방 조회됨
- 대량 데이터를 조회할 때 인덱스를 사용하니까 테이블 전체를 스캔할 때 보다 훨씬 느림
- 인덱스를 스캔하는 이유는 검색 조건을 만족하는 소량의 데이터를 인덱스에서 빨리 찾고 거기서 테이블 레코드를 찾아가기 위한 주소값, 즉 ROWID를 얻으려는 것
- ROWID는 논리적 주소 -> 물리적으로 직접 연결되지 않고, 테이블 레코드를 찾아가기 위한 논리적 주소 정보를 담고 있기 때문
  - 포인터가 아니며, 테이블 레코드와 물리적으로 직접 연결된 구조는 더더욱 아님
- I/O 메커니즘 복습
  - DBA(=데이터 파일번호 + 블록번호)는 디스크 상에서 블록을 찾기 위한 주소 정보
  - 그렇다고 매번 디스크에서 블록을 읽을 수는 없으므로 I/O 성능을 높이려면 버퍼캐시를 이용해야 함 

#### 3.1.2 인덱스 클러스터링 팩터
- 클러스터링 팩터(Clustering Factor, CF): 군집성 계수 -> 특정 컬럼을 기준으로 같은 값을 갖는 데이터가 서로 모여있는 정도를 의미
- CF가 좋은 컬럼에 생성한 인덱스는 검색 효율이 매우 좋음
- 인덱스 클러스터링 팩터가 가장 좋은 상태면 인덱스 레코드 정렬 순서와 테이블 레코드 정렬 순서가 100% 일치함
- 반대로 인덱스 클러스터링 팩터가 가장 안 좋은 상태면 인덱스 레코드 정렬 순서와 레코드 정렬 순서가 전혀 일치하지 않음

#### 3.1.3. 인덱스 손익분기점
- 인덱스 손익분기점: Index Range Scan에 의한 테이블 액세스가 Table Full Scan보다 느려지는 지점
- Table Full Scan은 성능이 일정해서 1000만 건 중 1개를 조회하든, 10만개를 조회하든, 1000만건을 다 조회하든 차이가 거의 없음
- 인덱스를 이용해 테이블을 액세스할 때는 전체 1000만건 중 몇 건을 추출하느냐에 따라 성능이 크게 달라짐 -> 테이블 랜덤 액세스 때문
- 인덱스를 이용한 테이블 액세스가 Table Full Scan보다더 느려지게 만드는 이유
  - Table Full Scan은 시퀀셜 액세스인 반면, 인덱스 ROWID를 이용한 테이블 액세스는 랜덤 액세스 방식
  - Table Full Scan은 Multiblock I/O인 반면, 인덱스 ROWID를 이용한 테이블 액세스는 Single Block I/O 방식
- 위 요인으로 인해 인덱스 손익분기점은 보통 5~20% 낮은 수준에서 결정됨
- CF에 따라 크게 달라짐 -> 인덱스 CF가 나쁘면 같은 테이블 블록을 여러번 반복 액세스하면서 논리적 I/O 횟수가 늘고, 물리적 I/O 횟수도 늘기 때문
- 테이블 스캔이 항상 나쁜 것이 아니며, 반대로 인덱스 스캔도 항상 좋은 것도 아님
- 온라인 프로그램 튜닝
  - 보통 소량 데이터를 읽고 갱신하므로 인덱스를 효과적으로 활용하는 것이 중요
  - 조인도 대부분 NL 방식 사용 -> NL 조인은 인덱스를 이용하는 조인 방식
  - 인덱스를 이용해 소트 연산을 생략함으로써 부분 범위 처리 방식으로 구현할 수 있다면, 온라인 환경에서 대량 데이터를 조회할 때도 아주 빠른 응답 속도를 낼 수 있음
- 배치 프로그램 튜닝
  - 대량 데이터를 일고 갱신하는 배치 프로그램은 항상 전체 범위 처리 기준으로 튜닝해야 함 -> 처리대상 집합 중 일부를 빠르게 처리하는 것이 아니라 전체를 빠르게 처리하는 것을 목표로 삼아야 함
  - 인덱스와 NL조인보다 Full Scan과 해시 조인이 유리함
  - 대량 배치 프로그램에선 인덱스보다 Full Scan이 효과적이지만, 초대용량 테이블을 Full Scan하면 상당히 오래 기다려야 하고 시스템에 주는 부담도 적지 않음
  - 따라서 파티션 활용 전략이 매우 중요한 튜닝 요소, 병렬처리까지 더할 수 있으면 좋음
  - 테이블을 파티셔닝하는 이유는 결국 Full Scan을 빠르게 처리하기 위함
- 인덱스는 다양한 튜닝 도구 중 하나일 뿐이며, 큰 테이블에서 아주 적은 일부 데이터를 빨리 찾고자 할 때 주로 사용

#### 3.1.4 인덱스 컬럼 추가
- 테이블 액세스를 최소화하기 위해 가장 일반적으로 사용하는 튜닝 기법은 인덱스에 컬럼을 추가하는 것
- 테이블 액세스 단계 필터 조건에 의해 버려지는 레코드가 많을 때, 인덱스에 컬럼을 추가하여 성능 효과를 얻음

#### 3.1.5 인덱스만 읽고 처리
- 테이블 랜덤 액세스가 아무리 많아도 필터 조건에 의해 버려지는 레코드가 거의 없다면 비효율은 없음
- ㄴ 이때 반드시 성능을 개선해야 한다면, 쿼리에 사용된 컬럼을 모두 인덱스에 추가해서 테이블 액세스가 아예 발생하지 않게 하는 방법을 고려할 수 있음
- Covered쿼리: 인덱스만 읽어서 처리하는 쿼리 -> 그 쿼리에 사용한 인덱스는 Covered 인덱스
- 이 방법이 효과는 매우 좋지만, 추가해야 할 컬럼이 많아 실제 적용하기 곤란한 경우도 많음
- Include 인덱스
  - 인덱스 킹 ㅚ에 미리 지정한 컬럼을 리프 레벨에 함께 저장하는 기능
  - 순전히 테이블 랜덤 액세스를 줄이는 요도로 개발됨

#### 3.1.6 인덱스 구조 테이블
- IOT(Index-Organized Table): 랜덤 액세스가 아예 발생하지 않도록 테이블을 인덱스 구조로 생성한 것 -> 오라클에서 부르는 명칭, MS-SQL에서는 클러스터형 인덱스라고 부름
  - 테이블을 찾아가기 위한 ROWID를 갖는 일반 인덱스와 달리 IOT는 그 자리에 테이블 데이터를 갖음
  - 테이블 블록에 있어야 할 데이터를 인덱스 리프블록에 모두 저장하고 있음
  - IOT에서는 인덱스 리프 블록이 곧 데이터 블록
  - 인덱스 구조 테이블이므로 정렬 상태를 유지하며 데이터를 입력
  - 인위적으로 클러스터링 팩터를 좋게 만드는 방법 중 하나
  - 같은 값을 가진 레코드들이 100% 정렬된 상태로 모여 있으므로 랜덤 액세스가 아닌 시퀀셜 방식으로 데이터를 액세스함
  - 이 때문에 BETWEEN이나 부등호 조건으로 넓은 범위를 읽을 때 유리함
  - 데이터 입력과 조회 패턴이 서로 다른 테이블에도 유용함
- 일반 힙 구조 테이블
  - 데이터를 입력할 때 랜덤 방식 -> Freelist로부터 할당 받은 블록에 정해진 순서 없이 데이터를 입력

#### 3.1.7 클러스터 테이블
- 인덱스 클러스터 테이블
  - 클러스터 키 값이 같은 레코드를 한 블록에 모아서 저장하는 구조
  - 한 블록에 모두 담을 수 없을 때는 새로운 블록을 할당해서 클러스터 체인으로 연결
  - 다중 테이블 클러스터: 여러 테이블 레코드를 같은 블록에 저장하는 것
  - ㄴ cf. 일반 테이블은 하나의 데이터 블록을 여러 테이블이 공유할 수 없음
  - 키 값이 같은 데이터를 같은 공간에 저장해둘 뿐, IOT나 SQL Server의 클러스터형 인덱스처럼 정렬하지는 않음
  - 구성: 클러스터 생성 -> 클러스터에 테이블을 담기 전, 반드시 클러스터 인덱스 정의 먼저 -> 클러스터 인덱스는 데이터 검색 용도로 사용할 뿐만 아니라 데이터가 저장될 위치를 찾을 때도 사용하기 때문
  - 일반 B*Tree 인덱스 구조를 사용하지만, 테이블 레코드를 일일이 가리키지 않고해당 키 값을 저장하는 첫 번째 데이터 블록을 가리킨다는 점이 다름 -> 일반 테이블에 생성한 인덱스 레코드는 테이블 레코드와 1:1 대응관계를 갖지만, 클러스터 인덱스는 테이블 레코드와 1:M 관계를 갖음 -> 클러스터 인덱스의 키 값은 항상 unique함
  - 클러스터 인덱스를 스캔하면서 값을 찾을 때는 랜덤 액세스가 값 하나당 한 번씩 밖에 발생하지 않음
  - 클러스터에 도달해서는 시퀀셜 방식으로 스캔하기 때문에 넓은 범위를 읽더라도 비효율이 없다는게 핵심 원리
- 해시 클러스터 테이블
  - 인덱스를 사용하지 않고 해시 알고리즘을 사용해 클러스터를 찾아간다는 점만 다름

### 3.2 부분범위 처리 활용
- 테이블 랜덤 액세스로 인한 인덱스 손익분기점의 한계를 극복할 또 다른 방법 소개 -> 부분범위 처리 원리
- 부분범위 처리 원리: 이를 활용하면 인덱스로 액세스할 대상 레코드가 아무리 많아도 아주 빠른 응답속도를 낼 수 있음

#### 3.2.1 부분범위 처리
- DBMS가 클라이언트에게 데이터를 전송할 때도 일정량씩 나누어 전송
- 전체 결과집합 중 아직 전송하지 않은 분량이 많이 남아있어도 서버 프로세스는 클라이언트로부터 추가 Fetch Call을 받기 전까지 그대로 멈춰 서서 기다림
- 1억 건짜리 테이블을 빨리 출력할 수 있는 이유는, DBMS가 데이터를 모두 읽어 한 번에 전송하지 않고 먼저 읽는 데이터부터 일정량을 전송하고 멈추기 때문
- 데이터를 전송하고 나면 서버 프로세스는 CPU를 OS에 반환하고 대기 큐에서 잠을 잠 -> 다음 Fetch Call을 받으면 대기 큐에서 나와 그다음 데이터부터 일정량을 읽어서 전송하고 또다시 잠을 잠
- 부분범위 처리: 전체 쿼리 결과집합을 쉼없이 연속적으로 전송하지 않고 사용자로부터 Fetch Call이 있을 때마다 일정량씩 나누어 전송하는 것 

#### 3.2.3 OLTP환경에서 부분범위 처리에 의한 성능개선 원리
- OLTP(Online Transaction Processing) 시스템: 온라인 트랜잭션을 처리하는 시스템 
- ㄴ 온라인 트랜잭션: 일반적으로 소량 데이터를 읽고 갱신
- 그런데 항상 소령 데이터만 조회하는 것은 아니고 수천수만 건을 조회하는 경우도 있음
- 인덱스를 이용해 수천수만 건을 조회하려면 많은 테이블 랜덤 액세스가 발생하기 때문에 만족할만한 성능을 내기 어려움
- 다행히 OLTP성 업무에서 쿼리 결과 집합이 아주 많을 때 사용자가 모든 데이터를 일일이 다 확인하지 않고 특정한 정렬 순서로 상위 일부 데이터만 확인 -> 항상 정렬 상태를 유지하는 인덱스를 활용하면 정렬 작업을 생략하고 앞쪽 일부 데이터만 아주 빠르게 보여줄 수 있음

### 3.3 인덱스 스캔 효율화
- IOT, 클러스터, 파티션은 테이블 랜덤 액세스를 최소화하는 데 매우 효과적인 저장구조이지만, 운영시스템 환경에서 이를 적용하려면 성능 검증을 위해 많은 테스트를 진행해야 하므로 어려움이 따름 -> 시스템 개발 단계에서 물리 설계가 중요한 이유
- 운영환경에서 가능한 일반적인 튜닝 기법은 인덱스 컬럼 추가
- 인덱스 스캔 효율화는 튜닝요소가 매우 다양함

#### 3.3.3 액세스 조건과 필터 조건
- 인덱스를 스캔하는 단계에 처리하는 조건절은 액세스 조건과 필터 조건으로 나뉨
- 인덱스 액세스 조건
  - 인덱스 스캔 범위를 결정하는 조건절
  - 인덱스 수직적 탐색을 통해 스캔 시작점을 결정하는 데 영향을 미치고, 인덱스 리프블록을 스캔하다가 어디서 멈출지를 결정하는 데 영향을 미치는 조건절
- 인덱스 필터 조건
  - 테이블로 액세스할지를 결정하는 조건절
- 인덱스를 이용하든, 테이블을 Full Scan 하든, 테이블 액세스 단계에서 처리되는 조건절은 모투 필터 조건
- 테이블 필터 조건
  - 쿼리 수행 다음 단계로 전달하거나 최종 결과집합에 포함할지를 결정

#### 3.3.5 인덱스 선행컬럼이 등치(=) 조건이 아닐 때 생기는 비효율
- 인덱스 스캔 효율성은 인덱스 컬럼을 조건절에 모두 등치(=) 조건으로 사용할 때 가장 좋음
- 리프 블록을 스캔하면서 읽은 레코드는 하나도 걸러지지 않고 모두 테이블 액세스로 이어지므로 인덱스 스캔 단계에서의 비효율은 전혀 없음
- 인덱스 컬럼 중 일부가 조건절에 없거나 등치 조건이 아니더라도, 그것이 뒤쪽 컬럼일 때는 비효율이 없음
- 반면 인덱스 선행 컬럼이 조건절에 없거나 부등호, BETWEEN, LIKE 같은 범위 검색 조건이면, 인덱스 스캔하는 단계에서 비효율이 생김
- 인덱스 선행 컬럼이 모두 '=' 조건일 때 필요한 범위만 스캔하고 멈출 수 있는 것은, 조건을 만족하는 레코드가 모두 한 데 모여있기 때문

#### 3.3.6 BETWEEN을 IN-List로 전환
- 범위검색 컬럼이 맨 뒤로 가도록 인덱스를변경하면 좋겠지만 운영시스템에서 인덱스 구성을 바꾸기는 쉽지 않음
- 이럴때 BETWEEN 조건을 IN-List로 바꿔주면 큰 효과를 얻는 경우가 있음
- IN-List 개수만큼 UNION ALL 브랜치가 생성되고 각 브랜치마다 모든 컬럼을 '='조건으로 검색하므로 앞서 선두 컬럼에 BETWEEN을 사용할 때와 같은 비효율이 사라짐
- IN-List 항목 개수가 늘어날 수 있다면 BETWEEN을 IN-List로 전환하는 방식은 사용하기 곤란함
- 그럴 때는 NL방식의 조인문이나 서브쿼리로 구현하면 됨 -> IN-List 값들을 코드 테이블로 관리하고 있을 때 가능한 방식
- BETWEEN을 IN-List로 전환할 때 주의 사항
  - IN-List의 개수가 많지 않아야 함
    - IN-List의 개수가 많으면 수직적 탐색이 많이 발생함
    - 그러면 BETWEEN 조건 때문에 리프블록을 많이 스캔하는 비효율보다 더 커질 수 있음
    - 루트에서 브랜치 블록까지 Depth가 깊을 때 특히 그럼
  - 인덱스 스캔 과정에 선택되는 레코드들이 서로 멀리 떨어져 있을 때만 유용함
    - 서로 멀리떨어져 있지 않으면 효과가 전혀 없거나 수직적 탐색 때문에 오히려 I/O가 더 많이 발생

#### 3.3.7 Index Skip Scan 활용
- BETWEEN을 IN-List로 변환하면 도움이 되는 상황에서 같은 효과를 내는 다른 방법 -> Index Skip Scan
- 선두컬럼이 BETWEEN이어서 나머지 검색 조건을 만족하는 데이터들이 서로 멀리 떨어져 있을 때 Index Skip Scan 위력이 나타남

#### 3.3.8 IN 조건은 '='인가
- IN조건은 '='가 아님
- IN조건이 '='이 되려면 IN-List Iterator 방식으로 풀어야 함, 그렇지 않으면 IN조건은 필터 조건
- IN조건을 '='조건으로 만들기 위해 즉, 액세스 조건으로 만들기 위해 IN-List Iterator 방식으로 푸는것이 항상 효과적인 것은 아님

#### 3.3.9 BETWEEN과 LIKE 스캔 범위 비교
- LIKE와 BETWEEN 둘다 범위 검색 조건 -> 범위 검색 조건을 사용할 때 비효율 원리 똑같이 적용 하지만 데이터 분포와 조건절 값에 따라 인덱스 스캔량이 서로 다를 수 있음
- LIKE보다 BETWEEN 사용하는게 나음

#### 3.3.10 범위검색 조건을 남용할 때 생기는 비효율
- 인덱스 스캔 범위가 늘어날 수 있기 때문

#### 3.3.11 다양한 옵션 조건 처리 방식의 장단점 비교
- 인덱스 선두 컬럼에 대한 옵션 조건에 OR조건을 사용해선 안 됨
- OR 조건을 이용한 옵션 조건 처리는 가급적 사용하지 않아야 함

### 3.4 인덱스 설계
#### 3.4.1 인덱스 설계가 어려운 이유
- 인덱스가 많으면 생기는 문제
  -  DML 성능 저하 -> TPS 저하
  -  데이터베이스 사이즈 증가 -> 디스크 공간 낭비
  -  데이터베이스 관리 및 운영 비용 상승
- 테이블과 달리 인덱스는 정렬 상태를 유지해야 하므로 수직적 탐색을 통해 입력할 블록부터 찾음 -> 찾은 블록에 여유 공간이 없으면 인덱스 분할 발생
  - 인덱스 분할 Index Split: 인덱스는 정렬 상태를 유지해야 하므로 아무 블록에나 값을 입력할 수 없음, 값을 입력한 위치에 공간이 없으면, 인덱스 분할을 통해 공간을 확보
  - 인덱스는 양방향 연결리스트 구조
- 개발 단계에서 인덱스 설계의 중요성
  - 운영 단계에서 인덱스 추가는 시스템에 부하를 주고, 인덱스 변경은 운영 리스크가 큼

#### 3.4.2 가장 중요한 두 가지 선택 기준
- Index Range Scan: 가장 정상적이고 일반적인 방식, 이를 위해서 인덱스 선두 컬럼을 조건절에 반드시 사용해야 함
- 결합 인덱스 구성 기준
   - 조건절에 항상 사용하거나 자주 사용하는 컬럼을 선정하는 것
   - 그렇게 선정한 컬럼 중 '=' 조건을 자주 조회하는 컬럼을 앞쪽에 두어야 한다는 것
- 이 기준은 인덱스 스캔 효율성 기준

#### 3.4.3 스캔 효율성 이외의 판단 기준
- 수행 빈도
  - NL조인할 때 어느 쪽에서 자주 액세스 되는지도 중요한 판단 기준이 됨
  - NL조인 Inner 쪽 인덱스는 '='조건 컬럼을 선두에 두는 것이 중요
  - 될 수 있으면 테이블 액세스 없이 인덱스에서 필터링 마치도록 구성해야 함
- 업무상 중요도
- 클러스터링 팩터
- 데이터량
  - 데이터량이 적다면 굳이 인덱스를 많이 만들 필요가 없음 -> Full Scan으로 충분히 빠르기 때문
  - 초대용량 테이블일 때는 영향이 크므로 인덱스 설계가 중요함
- DML 부하(=기존 인덱스 개수, 초당 DML 발생량, 자주 갱신하는 컬럼 포함 여부 등)
- 저장 공간
- 인덱스 관리 비용

#### 3.4.5 소트 연산을 생략하기 위한 컬럼 추가
- I/O를 최소화하면서도 소트 연산을 생략하기 위한 인덱스 구성 방법
  - '=' 연산자로 사용한 조건절 컬럼 선정
  - ORDER BY 절에 기술한 컬럼 추가
  - '=' 연산자가 아닌 조건절 컬럼은 데이터 분포를 고려해 추가 여부 결정
- IN 조건은 '=' 아님
  - 소트 연산을 생략하려면 IN 조건이 IN-List Iterator 방식으로 풀려선 안 됨 -> IN 조건절을 인덱스 액세스 조건으로 사용하면 안 되고 필터조건을 사용해야 함

#### 3.4.6 결합 인덱스 선택도
- 인덱스 생성 여부를 결정할 때는 선택도가 충분히 낮은지가 중요한 판단 기준
- 선택도 Selectivity: 전체 레코드 중에서 조건절에 의해 선택되는 레코드 비율, 선택도에 총 레코드 수를 곱해서 '카디널리티'를 구함
- 인덱스 선택도: 인덱스 컬럼을 모두 '='로 조회할 때 평균적으로 선택되는 비율을 의미
- 선택도가 높은(카디널리티가 높은) 인덱스는 생성해봐야 효용가치가 별로 없음
- 인덱스 생성 여부를 결정할 때는 선택도가 매우 중요하지만, 컬럼 간 순서를 결정할 때는 각 컬럼의 선택도보다 필수 조건 여부, 연산자 형태가 더 중요한 판단 기준

## 4. 조인 튜닝
### 4.1 NL조인
#### 4.1.1 기본 메커니즘
- NL 조인은 인덱스를 이용한 조인 방식

#### 4.1.5 NL 조인 특징 요약
- 랜덤 액세스 위주의 조인 방식 -> 인덱스 구성이 아무리 완벽해도 대량 데이터에 조인할때 NL 조인이 불리한 이유
- 조인을 한 레코드씩 순차적으로 진행 -> 부분범위 처리가 가능한 상황이라면, 매우 빠른 응답 속도를 낼 수 있음
- 인덱스 구성 전략이 특히 중요함 -> 인덱스에 따라 조인 효율이 크게 달라짐
- NL 조인은 소량 데이터를 주로 처리하거나 부분 범위 처리가 가능한 온라인 트랜잭션 처리 시스템에 적합한 조인 방식

### 4.2 소트 머지 조인
- 옵타이마이저가 NL조인 대신 소트 머지 조인이나 해시 조인을 선택할 경우
  - 조인 컬럼에 인덱스가 없을 때
  - 대량 데이터 조인이어서 인덱스가 효과적이지 않을 때
- 해시조인을 사용할 수 없는 상황에서 대량 데이터를 조인하고자 할 때

#### 4.2.1 SGA vs PGA
- SGA
  - 공유메모리 영역
  - SGA에 캐시된 데이터는 여러 프로세스가 공유할 수 있음 그러나 동시에 액세스할 수는 없음
  - 동시에 액세스하려는 프로세스 간 액세스를 직렬화하기 위한 Lock 메커니즘으로서 래치(Latch) 존재
  - 데이터 블록과 인덱스 블록을 캐싱하려는 DB 버퍼캐시는 SGA의 핵심 구성 요소 -> DB 버퍼캐시에서 블록을 읽으려면 버퍼 Lock도 얻어야 함
- PGA
  - 오라클 서버 프로세는 SGA에 공유된 데이터를 읽고 쓰면서, 동시에 자신만의 고유 메모리 영역을 갖음, 각 오라클 서버 프로세스에 할당된 메모리 영역을 PGA라 부름
  - 프로세스에 종속적인 고유 데이터를 저장하는 용도로 사용
  - 할당받은 PGA 공간이 작아 데이터를 모두저장할 수 없을 때는 Temp 테이블 스페이스 이용
  - PGA는 다른 프로세스와 공유하지 않는 독립적인 메모리 공간 -> 래치 메커니즘이 불필요
  - 같은 양의 데이터를 읽더라도 SGA 버퍼 캐시에서 읽을 때보다 훨씬 빠름
 
#### 4.2.2 기본 메커니즘
- 1. 소트 단계: 양쪽 집합을 조인 컬럼 기준으로 정렬
- 2. 머지 단계: 정렬한 양쪽 집합을 서로 머지
- Sort Area에 저장한 데이터 자체가 인덱스 역할을 하므로 소트 머지 조인은 조인 컬럼에 인덱스가 없어도 사용할 수 있는 조인 방식
- 조인 컬럼에 인덱스가 있어도 NL 조인은 대량 데이터 조인할 때 불리하므로 소트 머지 조인을 사용할 수 있음
 
#### 4.2.3 소트 머지 조인이 빠른 이유
- NL 조인
  - 모든 DBMS가 곹옹으로 제공하는 가장 전통적인 조인 방식
  - 대량 데이터 조인할 때 성능이 매우 느림 -> 소트 머지 조인, 해시 조인이 개발된 이유
  - Sort Area에 미리 정렬해 둔 자료구조를 이용한다는 점만 다를 뿐 조인 프로세싱 자체는 Nl조인과 같음
  - 대량 데이터 조인할 때 소트 머지 조인이 빠른 이유
    - NL 조인
      - NL 조인은 단적으로 말해 인덱스를 이용한 조인 방식, 조인 과정에서 액세스하는 모든 블록을 랜덤 액세스 방식으로 건건이 DB 버퍼 캐시를 경유해서 읽음 -> 인덱스든 테이블이든 읽는 모든 블록에 래치 획득 및 캐시버퍼 체인 스캔 과정을 거침
      - 인덱스를 이용하기 때문에 인덱스 손익분기점 한계가 그대로 드러남
    - 소트 머지 조인
      - 양쪽 데이블로부터 조인 대상 집합을 일괄적으로 읽어 PGA에 저장한 후 조인
      - PGA는 프로세스만을 위한 독립적인 메모리 공간이므로 데이터를 읽을 때 래치 획득 과정이 없음 -> 소프트 머지 조인이 대량 데이터 조인에 유리한 이유
      - 조인 전에 양쪽 집합에 대한 소트 연산을 추가로 수행한 것이 핵심 요인

#### 4.2.4 소트 머지 조인의 주용도
- 조인 조건식이 등치(=)조건이 아닌 대량 데이터 조인 -> 해시 조인은 조인 조건식이 등치(=) 조건이 아닐 때 사용할 수 없음
- 조인 조건식이 아예 없는 조인(Cross Join, 카테시안 곱)

#### 4.2.6 소트 머지 조인 특징 요약
- 조인을 위해 실시간으로 인덱스를 생성하는 것과 같음
- 양쪽 집합을 정렬한 다음에는 NL 조인과 같은 방식으로 진행, PGA 영역에 저장한 데이터를 이용하기 때문에 빠름 -> 소트 부하만 감수한다면 건건이 버퍼캐시를 경유하는 NL 조인보다 빠름
- 소트머지 조인은 조인 컬럼에 대한 인덱스 유무에 크게 영향 받지 않음 -> 조인 컬럼에 인덱스가 없는 상황에서 두 테이블을 각각 읽어 조인 대상 집합을 줄일 수 있을 때 아주 유리
- 스캔 위주의 액세스 방식 사용

### 4.3 해시 조인
- 해시 조인은 소트 머지 조인처럼 항상 양쪽 테이블을 정렬해야 하는 부담도 없음

#### 4.3.1 기본 메커니즘
- 1. Build 단계: 작은 쪽 테이블(Build Input)을 읽어 해시 테이블(해시 맵)을 생성 
- 2. Probe 단계: 큰 쪽 테이블(Probe Input)을 읽어 해시 테이블을 탐색하면서 조인

#### 4.3.2 해시 조인이 빠른 이유
- 해시 테이블을 PGA 영역에 할당하기 때문 -> NL 조인은 Outer 테이블 레코드마다 Inner 쪽 테이블 레코드를 읽기 위해 래치 획득 및 캐시버퍼 체인스캔 과정을 반복하지만, 해시 조인은 그 과정없이 PGA에서 빠르게 데이터 탐색하고 조인함
- 해시 조인에서 사전 준비작업은 양쪽 집합 중 어느 '한쪽'을 읽어 해시 맵을 만든느 작업 -> 소트 머지 조인의 사전 준비 작업은 '양쪽' 집합을 모두 정렬해서 PGA에 담는 작업
- 해시 조인은 둘 중 작은 집합을 해시 맵 Build Input으로 선택하므로 두 집합 모두 Hash Area에 담을 수 없을 정도로 큰 경우가 아니면 디스크에 쓰는 작업은 일어나지 않음
- 정리
  - NL 조인처럼 조인 과정에서 발생하는 랜덤 액세스 부하 없음
  - 소프트 머지 조인처럼 양쪽 집합을 미리 정렬하는 부하 없음

#### 4.3.5 조인 메소드 선택 기준
- 일반 적인 경우
  - 소량 데이터 조인할 때 -> NL 조인
  - 대량 데이터 조인할 때 -> 해시 조인
  - 대량 데이터 조인인데 해시 조인으로 처리할 수 없을 때, 즉 조인 조건식이 등치(=) 조건이 아닐 때 -> 소트 머지 조인
- 해시 조인은 아래 세 가지 조건을 만족하는 SQL문에 주로 사용
  - 수행 빈도가 낮고
  - 쿼리 수행 시간이 오래 걸리는
  - 대량 데이터 조인할 때

### 4.3 서브쿼리 조인
#### 4.4.1 서브쿼리 변환이 필요한 이유
- 쿼리 변환: 옵티마이저가 SQL 분석해 의미적으로 동일하면서도 더 나은 성능이 기대되는 형태로 재작성하는 것
- 서브 쿼리: 하나의 SQL문 안에 괄호로 묶은 별도의 쿼리 블록, 쿼리에 내장된 또 다른 쿼리
- 서브 쿼리 종류
  - 인라인 뷰: FROM 절에 사용된 서브쿼리
  - 중첩된 서브쿼리: 결과 집합을 한정하기 위해 WHERE 절에 사용한 서브쿼리, 특히 서브쿼리가 메인쿼리 컬럼을 참조하는 형태를 상관관계 있는 서브쿼리라고 함
  - 스칼라 서브쿼리: 한 레코드당 정확히 하나의 값을 반환하는 서브쿼리
- 옵티마이저는 쿼리 블록 단위로 최적화를 수행

#### 4.4.2 서브쿼리와 조인
- 필터 오퍼레이션
  - NL조인과의 공통점: 기본적으로 NL 조인과 처리 루틴이 같음, NL 조인처럼 부분 범위 처리도 가능
  - NL조인과의 차이점
    - 필터는 메인쿼리의 한 로우가 서브쿼리의 한 로우와 조인에 성공하는 순간 진행을 멈추고, 메인쿼리의 다음 로우를 계속 처리함
    - 필터는 캐싱기능을 갖음 -> 서브쿼리 입력 값에 따른 반환 값을 캐싱하는 기능 -> 이 기능이 작동하므로 서브쿼리를 수행하기 전 항상 캐시부터 확인하여 성능을 높이는데 큰 도움
    - 필터 서브쿼리는 일반 NL조인과 달리 메인 쿼리에 종속되므로 조인순서가 고정됨, 항상 메인쿼리가 드라이빙 집합

## 5. 소트 튜닝
### 5.1 소트 연산에 대한 이해
#### 5.1.1 소트 수행 과정
- 소트는 기본적으로 PGA에 할당한 Sort Area에서 이루어짐
- 메모리 공간인 Sort Area가 다 차면, 디스크 Temp 테이블스페이스를 활용
- Sort Area에서 작업을 완료할 수 있는지에 따라 소트 유형
  - 메모리 소트 In-Memory Sort: 전체 데이터의 정렬 작업을 메모리 내에서 완료하는 것, Internal Sort
  - 디스크 소트 To-Disk Sort: 할당 받은 Sort Area 내에서 정렬을 완료하지 못해 디스크 공간까지 사용하는 경우, External Sort 라고도 함
- 소트할 대상 집합을 SGA 버퍼캐시를 통해 읽어들이고, 일차적으로 Sort Area에서 정렬을 시도함
- Sort Area가 찰 때마다 Temp 영역에 저장해둔 중간 단계의 집합을 Sort Run이라고 함
- 정렬된 최종 집합을 얻으려면 이를 다시 머지해야 함
- PGA로부터 읽어들여 PGA가 찰때마다 쿼리 수행 다음 단계로 전달하거나 클라이언트에게 전송하면 됨
- 소트연산은 메모리 집약적일 뿐만 아니라 CPU 집약적

#### 5.1.2 소트 오퍼레이션
- 소트를 발생시키는 오퍼레이션
  - Sort Aggregate
    - 전체 로우를 대상으로 집계를 수행할 때
    - Sort 라는 표현을 사용하지만 실제로 데이터를 정렬하진 않음 -> Sort Area를 사용한다는 의미
  - Sort Order By: 데이터 정렬
  - Sort Group By: 소팅 알고리즘을 사용해 그룹별 집계를 수행할 때
  - Sort Unique
    - 옵티마이저가 서브쿼리를 풀어 일반 조인문으로 변환하는 것을 서브쿼리 Unnesting이라고 함
    - Unnesting된 서브쿼리가 M쪽 집합이면, 메인 쿼리와 조인하기 전에 중복 레코드부터 제거해야 함 -> 이 때 Sort Unique 오퍼레이션이 나타남
  - Sort Join: 소트 머지 조인을 수행할 때
  - Window Sort: 윈도우 함수(=분석 함수)를 수행할 때 

### 5.2 소트가 발생하지 않도록 SQL 작성
- SQL 작성할 때 불필요한 소트가 발생하지 않도록 주의해야 함
- Union, Minus, Distinct 연산자는 중복 레코드를 제거하기 위한 소트 연산을 발생시키므로 꼭 필요한 경우에만 사용하고 성능이 느리다면 소트 연산을 피할 방법이 있는지 찾아봐야 함

#### 5.2.1 Union vs. Union All
- SQL에 Union을 사용하면 옵티마이저는 상단과 하단 두 집합 간 중복을 제거하려고 소트 작업을 수행함
- Union All은 중복을 확인하지 않고 두 집합을 단순히 결합하므로 소트 작업을 수행하지 않음 -> 될 수 있으면 Union All 사용해야 함
- 그런데 Union을 Union All로 변경하려다가 결과 집합이 달라질 수 있음 -> 데이터 모델에 대한 이해와 집합적 사고가 필요함
  - 그런 능력이 부족하면 데이터 중복을 우려해 중복 제거용 연산자를 불필요하게 자주 사용하게 됨

#### 5.2.2 Exists 활용
- 중복 레코드를 제거할 목적으로 Distinct 연산자를 종종사용하는데 이 연산자를 사용하면 조건에 해당하는 데이터를 모두 읽어서 중복을 제거해야 함
- 부분범위 처리는 당연히 불가능하고, 모든 데이터를 읽는 과정에 많은 I/O가 발생함
- Exists 서브쿼리는 데이터 존재여부만 확인하면 되기 때문에 조건절을 만족하는 데이터를 모두 읽지 않음
- Distinct, Minus 연산자를 사용한 쿼리는 대부분 Exists 서브쿼리로 변환 가능함

#### 5.2.3 조인 방식 변경
- 조인문일때는 조인 방식도 잘 선택해줘야 함
- 정렬 기준이 조인 키 컬럼이면 소트 머지 조인도 Sort Order By 연산을 생략할 수 있음

### 5.3 인덱스를 이용한 소트 연산 생략
- 인덱스는 항상 키 컬럼 순으로 정렬된 상태를 유지함
- ㄴ 이를 활용하면 SQL에 Order By 또는 Group By 절이 있어도 소트 연산을 생략할 수 있음

#### 5.3.2 Top N 쿼리
- Top N 쿼리: 전체 결과집합 중 상위 N개 레코드만 선택하는 쿼리
  - 오라클에서는 인라인 뷰로 한 번 감싸줘야 함
- COUNT(STOPKEY): 조건절에 부합하는 레코드가 아무리 많아도 그 중 ROWNUM으로 지정한 건수만큼 결과 레코드를 얻으면 거기서 바로 멈춘다는 뜻 -> Top N Stopkey 알고리즘
- 페이징 처리
  - 3-Tier 환경에서는 대량의 결과집합을 조회할 때 페이징 처리 기법을 활용
  - 부분범위 처리 가능하도록 SQL을 작성한다는 의미
    - 인덱스 사용 가능하도록 조건절을 주사하고
    - 조인은 NL조인 위주로 처리
    - Order by 절이 있어도 소트 연산을 생략할 수 있도록 인덱스를 구성해주는 것

#### 5.3.3 최소값/최대값 구하기
- 인덱스를 이용해 최소/최대값 구하기
  - 전체 데이터를 읽지 않고 인덱스를 이용해 최소/최대값을 구하려면 조건절 컬럼과 MIN/MAX함수 인자 컬럼이 모두 인덱스에 포함돼 있어야 함 -> 테이블 액세스가 발생하지 않아야 함
  - 조건절 컬럼과 MAX 컬럼이 모두 인덱스에 포함되어 있어야 함
  - FIRST ROW: 조건을 만족하는 레코드 하나를 찾았을 때 바로 멈춘다는 것을 의미 -> FIRST ROW STOPKEY 알고리즘
- TOP N 쿼리 이용해 최소/최대값 구하기
  - TOP N 쿼리를 통해서도 최소 또는 최대값을 쉽게 구할 수 있음
  - ROWNUM <=1 조건을 이용해 TOP 1 레코드를 찾으면 됨
  - TOP N쿼리에 작동하는 TOP STOPKEY 알고리즘은 모든 컬럼이 인덱스에 포함돼 있지 않아도 잘 작동함

#### 5.3.5 Sort Group By 생략
- 인덱스를 이용해 Nosort 방식으로 Group By를 처리하면 부분범위 처리가 가능해짐

### 5.4 Sort Area를 적게 사용하도록 SQL 작성
- 소트 연산이 불가피하다면 메모리 내에서 처리를 완료할 수 있도록 노력해야 함

#### 5.4.4 분석함수에서의 Top N 소트
- 윈도우 함수 중 rank나 row_number 함수는 max 함수보다 소트 부하가 적음 -> Top N 소트 알고리즘이 작동하기 때문

## 6. DML 튜닝
### 6.1 기본 DML 튜닝
#### 6.1.1 DML 성능에 영향을 미치는 요소
- 인덱스
  - 테이블은 Freelist를 통해 입력블록을 할당받지만, 인덱스는 정렬된 자료구조이므로 수직적 탐색을 통해 입력할 블록을 찾아야 함 
  - 인덱스에 입력하는 과정이 더 복잡하므로 DML 성능이 미치는 영향도 더 큼
  - 테이블에서 레코드를 하나 삭제하면, 인덱스 레코드를 모두 찾아서 삭제해줘야 함
  - UPDATE 할 때는 변경된 컬럼을 참조하는 인덱스만 찾아서 변경해 주면 됨
  - 핵심 트랜잭션 테이블에서 인덱스 하나라조 줄이면 TPS(Transaction per second)는 그만큼 향상됨
- 무결성 제약
  - 데이터베이스에 논리적으로 의미 있는 자료만 저장되게 하는 데이터 무결성 규칙
    - 개체 무결성
    - 참조 무결성
    - 도메인 무결성
    - 사용자 정의 무결성(또는 업무 제약 조건)
  - 위 규칙을 애플리케이션으로 구현할 수도 있지만, DBMS에서 PK, FK, Check, Not Null 같은 제약을 설정하면 더 완벽하게 데이터 무결성을 지켜낼 수 있음
  - PK, FK 제약은 실제 데이터를 조회해봐야 하기 때문에 나머지 제약들보다 성능에 더 큰 영향을 미침
- 조건절
- 서브쿼리
- Redo 로깅
  - 오라클은 데이터파일과 컨트롤파일에 가해지는 모든 변경사항을 Redo 로그에 기록
  - Redo로그는 트랜잭션 데이터가 어떤 이유에서건 유실됐을 때, 트랜잭션을 재현함으로써 유실 이전 상태로 복구하는 데 사용됨
  - DML을 수행할 때마다 Redo 로그를 생성해야 하므로 Redo 로깅은 DML 성능에 영향을 미침 -> INSERT 작업에 대해 Redo 로깅 생략 기능을 제공하는 이유
  - 트랜잭션을 재현함으로써 과거를 현재 상태로 돌리는 데 사용
  - 트랜잭션을 재현하는 데 필요한 정보를 로깅
- Undo 로깅
  - 트랜잭션을 롤백함으로써 현재를 과거 상태로 돌리는데 사용
  - 변경된 블록을 이전 상태로 되돌리는 데 필요한 정보를 로깅
  - DML을 수행할 때 마다 Undo를 생성해야 하므로 Undo 로깅은 DML 성능에 영향을 미침
- Lock
  - DML 성능에 매우 크고 직접적인 영향을 미침
  - Lock을 필요 이상으로 자주, 길게 사용하거나 레벨을 높일수록 DML 성능은 느려짐
  - 그렇다고 Lock을 너무 적게, 짧게 사용하거나 필요한 레벨 이하로 낮추면 데이터 품질이 나빠짐
  - 성능과 데이터 품질을 모두 잡으려면 매우 세심한 동시성 제어가 필요
- 커밋
  - 커밋은 DML과 별개로 실행하지만, DML을 끝내려면 커밋까지 완료해야 하므로 서로 밀접한 관계가 있음
  - DML이 Lock에 의해 블로킹된 경우, 커밋은 DML 성능과 직결됨 -> DML을 완료할 수 있게 Lock을 푸는 열쇠가 커밋이기 때문

#### 6.1.2 데이터베이스 Call과 성능
- SQL 세 단계
  - Parse Call: SQL 파싱과 최적화를 수행하는 단계
  - Execute Call: SQL을 실행하는 단계
  - Fetch Call: 데이터를 읽어서 사용자에게 결과집합을 전송하는 과정으로 SELECT문에서만 나타남, 전송할 데이터가 많을 때는 Fetch Call이 여러번 발생함
- SQL은 Call이 어디서 발생하냐에 따라 두 개로 나눌 수 있음 -> 둘 다 SQL을 실행할 때 마다 Parse, Execute, Fetch Call 단계를 거침 
  - User Call: 네트워크를 경유해 DBMS 외부로부터 인입되는 Call
  - Recursive Call: DBMS 내부에서 발생하는 Call

### 6.2 Direct Path I/O 활용
- 온라인 트랜잭션은 기준성 데이터, 특정 고객, 특정 상품, 최근 거래 등을 반복적으로 읽기 때문에 버퍼 캐시가 성능 향상에 도움을 줌
- 정보계 시스템이나 배치프로그램에 사용하는 SQL은 주로 대량 데이터를 처리하기 때문에 버퍼캐시를 경유하는 I/O메커니즘이 오히려 성능을 떨어뜨릴 수 있음
- 오라클은 버퍼캐시를 경유하지 않고 곧바로 데이터 블록을 읽고 쓸 수 있는 Direct I/O 기능 제공

#### 6.2.1 Direct Path I/O
- 일반적인 블록 I/O는 DB버퍼캐시를 경유함 -> 읽고자 하는 블록을 먼저 버퍼캐시에서 찾아보고, 찾지 못할 때만 디스크에서 읽음
- 자주 읽는 블록에 대한 반복적인 I/O call을 줄임으로써 시스템 전반적인 성능을 높이려고 버퍼캐시를 이용
- 대량 데이터를 읽고 쓸 때 건건이 버퍼캐시를 탐색한다면 개별 프로그램 성능에는 오히려 안좋음 -> 버퍼 캐시에서 블록을 찾을 가능성이 거의 없기 때문
- 오라클은 버퍼캐시를 경유하지 않고 곧바로 데이터 블록을 읽고 쓸 수 있는 Direct Path I/O 기능 제공
  - 병렬 쿼리로 Full Scan을 수행할 때
  - 병령 DML을 수행할 때
  - DIRECT PATH INSERT를 수행할 때
  - TEMP 세그먼트 블록들을 읽고 쓸 때
  - DIRECT 옵션을 지정하고 EXPORT을 수행할 때
  - NOCACHE 옵션을 지정한 LOB 컬럼을 읽을 때

#### 6.2.2 Direct Path Insert
- 일반적인 INSERT가 느린 이유
  1. 데이터를 입력할 수 있는 블록을 Freelist에서 찾음
    - Freelist: 테이블 High-WaterMart 아래 쪽에 있는 블록 중 데이터 입력이 가능한 블록 목록
  2. Freelist에서 할당받은 블록을 버퍼캐시에서 찾음
  3. 버퍼캐시에 없으면, 데이터파일에서 읽어 버퍼캐시에 적재
  4. INSERT 내용을 Undo 세그먼트에 기록
  5. INSERT 내용을 Redo 로그에 기록
- Direct Path Insert 방식을 사용하면 대량 데이터를 일반적인 INSERT보다 훨씬 더 빠르게 입력할 수 있음
- Direct Path Insert가 빠른 이유
  1. Freelist를 참조하지 않고 HWM 바깥 영역에 데이터를 순차적으로 입력
  2. 블록을 버퍼캐시에서 탐색하지 않음
  3. 버퍼캐시에 적재하지 않고, 데이터파일에 직접 기록
  4. Undo 로깅을 안함
  5. Redo 로깅을 안하게 할 수 있음. 
- Direct Path Insert 사용 시 주의할 점
  - 성능은 빨라지지만 Exclusive 모드 TM Lock이 걸림
  - Freelist를 조회하지 않고 HWM 바깥 영역에 입력하므로 테이블에 여유공간이 있어도 재활용하지 않음

#### 6.2.3 병렬DML
- INSERT는 append 힌틀르 이용해 Direct Path Write 방식으로 유도할 수 있음
- UPDATE, DELETE는 기본적으로 Direct Path Write가 불가능함 -> 병렬 DML로 처리해야 함
- 병렬 처리는 대용량 데이터가 전제이므로 오라클은 병렬 DML에 항상 Direct Path Write 방식을 사용함
- DML 작업을 각 병렬 프로세스가 잘 처리하는지, 아니면 QC가 처리하는지를 실행 계획에서 확인할 수 있음

### 6.3 파티션을 활용한 DML 튜닝
- 파티션을 이용하면 대령 추가/변경/삭제 작업을 빠르게 처리할 수 있음

#### 6.3.1 테이블 파티션
- 파티셔닝: 테이블 또는 인덱스 데이터를 특정 컬럼(파티션 키) 값에 따라 별도 세그먼트에 나눠서 저장하는 것
- 일반적으로 시계열에 따라 Range 방식으로 분할하지만, 그 외 다른 기준(리스트 또는 해시 방식)으로 분할할 수도 있음
- 파티션이 필요한 이유
  - 관리적 측면: 파티션 단위 백업, 추가, 삭제, 변경 -> 가용성 향상
  - 성능적 측면: 파티션 단위 조회 및 DML, 경합 또는 부하 분산
- 파티션 종류
  - Range: 오라클 8버전부터 제공된 가장 기초적인 방식으로 주로 날짜 컬럼을 기준으로 파티셔닝
  - 해시
  - 리스트