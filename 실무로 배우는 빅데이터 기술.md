# 실무로 배우는 빅데이터 기술


## HDFS
- 대용량 파일 적재
- 실시간 및 대량으로 발생하는 작은 메시지 데이터를 저장할 경우 파일의 수가 기하급수적으로 늘어남 -> 관리노드와 병렬 처리의 효율성이 크게 떨어짐
- 보안하기 위해 NoSQL, 인메모리 캐시, MoM 등을 선택적으로 사용할 수 있는 아키텍처링 필요

## 접근제어 보안
### 아파치 녹스 Apache Knox
- 네크워크상의 DMZ에 위치시킴으로써 외부 클라이언트가 하둡 에코시스템에 직접 접근하는 것을 막음
  - DMZ: 클라이언트와 하둡에코시스템의 사이, 각 영역 사이에는 방화벽이 있음
- 항상 녹스를 거쳐 통신하게 하는 중간 게이트웨이 역할
- 이때 들어온 요청에 대한 접근 인증을 LDAP로 제공받을 수 있음

### 아파치 센트리 Apache Sentry
- 하둡파일 시스템에 상세한 접근제어(하둡 파일/디렉터리, 하이브 테이블 등)가 필요할 때 사용
- 하둡 데이터에 접근하려는 클라이언트는 센트리 에이전트를 반드시 설치해야 함
- 센트리 에이전트가 서버와 통신하면서 접근 권한을 획득하게 됨
- 접근 이력을 관리하는 기능이 있어 향후 감사 로그를 편리하게 조회 가능

### 아파치 레인저 Apache Ranger
- 레인저가 지원하는 에코시스템이 많아 아파치 센트리에 비해 범용성이 좀 더 높은 편
- 레인저를 사용할 경우 플러그인을 통해 레인저 서버와 통신하게 됨
- 접근 이력을 관리하는 감사 로그 기능 제공

### 커베로스 Kerberos
- 빅데이터 외에도 이미 다양한 곳에서 활용되고 있는 범용화된 시스템
- AS(Authentication Service): 인증서버
- TGS(Ticket Granting Service): 티켓 발행 서버
- 하둡 파일 시스템에 접근하려는 클라이언트 에코시스템은 AS 인증서버를 통해 최초 인증을 수행
- TGS 티켓 발행 서버로부터 하둡 파일시스템에 접근을 허용하는 티켓을 발행받음
- 이후부터는 유효한 티켓만 있으면 하둡 파일시스템에 인증없이 접근할 수 있음

## 빅데이터 수집 기술
### 플럼 Flume
- 빅데이터를 수집할 때 다양한 수집 요구사항들을 해결하기 위한 기능으로 구성된 소프트웨어
- 플럼 아키텍처: Source, Channel, Sink
  - Source: 데이터 로드
  - Channel: 데이터 임시 저장
  - Sink: 목적지에 데이터 최종 적재
- 활용 방안: 스마트카에서 발생하는 로그를 직접 수집하는 역할 담당

### 카프카 Kafka
- MOM 소프트웨어 중 하나
- 대규모로 발생하는 메시지성 데이터를 비동기 방식으로 중계하는 역할
- 원천 시스템으롭터 대규모 트랜잭션 데이터가 발생했을 때 중간에 데이터를 버퍼링하면서 타깃 시스템에 안정적으로 전송해주는 역할
- 카프카 아키텍처: 주키퍼를 반드시 이용해야 함
- 활용 방안
  - 플럼이 실시간 데이터를 수집해 카프카 토픽에 전송하면 카프카는 전송받은 데이터를 토픽에 임시 저장하고 있다가 컨슈머 프로그램이 작동해 토픽에서 데이터를 가져감
  - 플럼이 아주 빠르게 발생하는 데이터를 실시간으로 수집하게되면 이를 최종 목적지에 전달하기 전 중간에서 안정적인 버퍼링 처리가 필요해서
  - 카프카와 같은 대규모 중간 저장소가 완충역할 -> 안정적인 수집 아키텍처 구성 가능

## 빅데이터 적재 기술
### 하둡 Hadoop
- 대용량 데이터 분산 저장
- 분산 저장된 데이터 가공/분석 처리 기능: 분산 병렬 처리 기술 사용
  - 맵리듀스 MapReduce: 아래 두가지를 쉽고 편리하게 지원하는 프레임워크
  - 분산 병렬 처리에서의 핵심은 여러 컴퓨터에 분산 저장돼 있는 데이터로부터 어떻게 효율적으로 일을 나눠서(map) 실행시킬 수 있느냐
  - 다음으로 여러 컴퓨터가 나눠서 실행한 결과들을 어떻게 하나로 모으냐(reduce)
- 활용 방안
  - HDFS의 특정 디렉터리에 일자 단위로 파티션하여 저장하기 위해 하이브를 사용하는데, 대규모 하이브 작업을 위해 맵리듀스 프로세스가 내부적으로 작동

### 주키퍼 Zookeeper
- 빅데이터 분산 환경을 더욱 효율적으로 관리하기 위해 서버 간의 정보를 쉽고 안전하게 공유해야 함
- 공유된 정보를 이용해 서버 간의 중요한 이벤트를 관리하면서 상호작용을 조율해주는 코디네이터 시스템 필요 -> 분산 코디네이터인 주키퍼
- 주키퍼는 하둡, HBase, 카프카, 스톰 등의 분산 노드 관리에 사용 중
- 주키퍼 아키텍처
  - 3대 이상의 홀수 개의 서버로 구성돼야 함
  - 리더 서버: 반드시 1개 서버 -> 다른 모든 팔로워 서버에 요청받은 ZNode 정보를 브로드캐스트함
  - 팔로워 서버: 나머지 서버 -> 팔로워 서버 1에 저장된 ZNode 정보는 리더서버에 전달됨
- 활용 방안: 하둡, HBase, 카프카, 스톰의 내부에서 주키퍼에 의존해 클러스터 멤버십 기능 및 환경설정의 동기화 등을 사용하고 있음

## 빅데이터 실시간 적재 기술
### HBase
- NoSQL 데이터베이스
  - 데이터를 키/값 구조로 단순화
  - 칼럼 또는 도큐먼트 형식의 제약사항이 적은 스키마 모델로 만들어 고성능 쓰기/읽기가 가능
- HBase: 하둡 기반의 컬럼 지향 NoSQL 데이터베이스
  - 스키마 변경이 자유로움 
  - 리전이라는 수십~수백 대의 분산 서버로 샤딩과 복제 등의 기능을 지원 -> 성능과 안정성 보장
  - 하둡의 확장성과 내고장성을 그대로 이용할 수 있음 -> 대규모 실시간 데이터 처리를 위한 스피드 레이어 저장소에서 주로 사용됨
- HBase 아키텍처
  - 하둡의 HDFS를 기반으로 설치 및 구성됨
  - 분산 데이터베이스 아키텍처를 채택하고 있음
  - HDFS의 가용성과 확장성을 그대로 물려받고 있음
- 활용 방안
  - 카프카에 저장돼 있는 데이터를 스톰이 받아서 HBase의 테이블에 모두 적재
  - HBase에 저장된 스마트카 운전자의 운행 정보를 특정 조건에 따라 필터링해서 신속하게 조회
  - 하이브 핸들러를 이용해 HBase에 저장된 데이터와 하이브 데이터를 동시에 활용

### 레디스 Redis
- 분산 캐시 시스템이면서 NoSQL 데이터베이스처럼 대규모 데이터 관리 능력도 갖춘 IMDG(In-Memory Data Grid) 소프트웨어
- 키/값 형식의 데이터 구조를 분산 서버상의 메모리에 저장하면서 고성능의 응답 속도를 보장
- 다양한 데이터 타입을 지원하기 때문에 데이터를 구조화해서 저장할 수 있음
- 단순 키/값 이상의 데이터 복잡성도 처리할 수 있음
- 인메모리 데이터를 영구정으로 저장할 수 있는 스냅샷 기능 제공
- 데이터 유실에 대비해 AOF(Append Only File) 기능으로 정합성 보장
- NoSQL 데이터베이스의 주요 특징인 데이터의 샤딩(Shading)과 복제(Replication) 지원 -> 높은 성능이 필요한 서비스에서 많이 사용됨
- 활용 방안
  - 분석한 결과를 빠르게 저장하면서 주변 시스템과 공유하기 위한 저장소로 사용

### 스톰 Storm
- 스피드 데이터를 인메모리 상에서 병렬처리하기 위한 소프트웨어
- 스피터 데이터를 실시간으로 다루기 위해 모든 데이터를 인메모리 상에서 분산 병렬 처리
- 분산 데이터를 통제하기 위한 강력한 기능(분리, 정제, 통합, 집계)과 아키텍처도 제공
- 데이터 발생과 동시에 처리하는 완전 실시간 방식 -> 조금의 레이턴시도 허용되지 않는 아키텍처에 적용함
- 아키텍처
  - 매우 견고한 장애 복구 기능 제공
  - 롤백 시점으로부터 데이터의 정합성 보장
- 활용 방안
  - 스마트카 운전자의 실시간 운행 정보를 대상으로 데이터 라우팅과 스트리밍 처리에 활용

### 에스퍼 Esper
- 실시간 스트리밍 데이터의 복잡한 이벤트 처리가 필요할 때 사용하는 룰 엔진
- 스톰이 대규모의 실시간 데이터를 단순 가공 및 추출 처리하는 데는 문제 없지만, 실시간으로 발생하는 데이터로부터 복잡한 패턴을 찾고, 그 패턴에 따른 이벤트를 처리하는 것은 쉽지 않음
- CEP: 실시간으로 발생하는 데이터 간의 관계를 복합적으로 판단 및 처리하는 것 -> 에스퍼 제공
- 에스퍼를 이용하면 CEP 처리를 위한 다양한 조건과 복합 이벤트를 하나의 룰로 쉽게 정의할 수 있어 CEP 처리 및 관리가 수월
- 아키텍처
  - CEP 엔진 -> 여기서 엔진은 단순 자바 라이브러리 프로그램으로, 설치와 사용은 매우 간단함
  - 애플리케이션 서버(톰캣, 제이보스, OSGI, 스톰 등) 또는 애플리케이션의 컨텍스트에 에스퍼 라이브러리 설치, 해당 라이브러리를 이용해 CEP 프로그래밍하는 단순 아기텍처
  - 에스퍼의 EPL(Event Processing Language)을 이용해 대규모 분산 아키텍처를 구성할 때는 룰 통합 관리, 분산 노드에 일관되게 적용하기 위해 다소 복잡한 구성 필요
  - ㄴ 분산된 응용 서버에 에스퍼 엔진을 설치, 에스퍼 엔진들이 동일한 EPL 룰을 동적으로 일괄 로딩하기 위해 EPL 공유 저장소가 이용됨
- 활용 방안
  - 운전자의 운행 데이터를 실시간으로 분석하기 위해 에스퍼 EPL 사용
  - 운전자 이벤트 정보를 실시간으로 감지할 수 있도록 룰 정의
  - 해당 이벤트 데이터를 감지 즉시 레디스에 적재되어 과속한 차량 정보만 관리할 수 있게 됨

## 빅데이터 탐색 기술
### 하이브 Hive
- 하둡 초창기에는 적재된 데이터를 탐색/분석하기 위한 도구로 맵리듀스를 주로 이용
- 그러나 맵리듀스는 복잡도가 높은 프로그래밍 기술을 필요로 했음 -> 분석가들에게 빅데이터 접근을 어렵게 만듦
- 하이브: 페이스북에서 SQL과 매우 유사한 방식으로 하둡 데이터 접근성을 높이도록 개발
- 아키텍처
  - 하이브 클라이언트에서 작성한 QL(Query Language)이 맵리듀스 프로그램으로 변환되어 실행된다는 것
  - 하이브 QL이 작동하면 항상 MetaStore를 참고해 하이브의 런타임 환경이 만들어짐
  - 쓰리프트 API 제공 -> 클라이언트 프로그램이 API를 호출해 다양한 하이브 액션을 외부에서도 실행
- 활용 방안
  - 데이터 웨어하우스 구축
  - 주제 영역별 데이터 마트 구성
- 장점
  - 복잡한 맵리듀스를 하이브QL로 래핑해 접근성을 높임
- 단점
  - 맵리듀스 코어를 그대로 사용함으로써 성능면에서는 만족스럽지 못했음 -> 반복적인 대화형 연산 작업에서는 하이브가 적합하지 않음

### 스파크 Spark
- 하이브 단점을 극복하기 위해 개발
- 고성능 인메모리 분석 -> 데이터 가공 처리를 인메모리에서 빠르게 처리
  - 기존 맵리듀스 기반의 하이브 또는 피그의 경우 하둡의 로컬 디스트에 의존해 대량의 데이터를 로드하고 생성함으로써 높은 IO발생과 그로인한 레이턴시를 피할 수 없었음
- 스파크SQL, 스파크 스트리밍, 스파크 머신러닝 등의 기능을 제공하고 있어 활용성이 높고 다양한 클라이언트 언어를 제공해 범용성이 뛰어남
- 스파크 코어의 주요 기능(스케줄링, 자원관리, 장애복구, RDD 관리)에 API로 접근 가능 
- 스파크 엔진은 대규모 분산 노드에서 최적의 성능을 낼 수 있음
- 활용 방안
  - 다양한 클라이언트 언어 지원
  - SQL을 이용해 데이터 액세스 가능

### 우지 Woozie
- 복잡한 데이터 파이프라인 작업을 위해 방향성 있는 비순환 그래프(DAG)로 잡의 시작, 처리, 분기, 종점 등의 액션을 정의하는 워크플로
- 아키텍처
  - 우지 클라이언트에서 작성한 워크플로는 우지 서버로 전송되어 메타화되고 RDBMS에 저장됨
  - 우지 서버에 있는 coordinator는 우지에 등록된 워크플로를 스케줄링 해줌
  - 워크플로 엔진이 Action 노드와 Control노드의 정보를 해석하면서 관련 태스크를 하둡의 클러스터에서 실해이킴
  - 주요 Action Task로는 하이브, 피그, 스쿱(sqoop)등이 있음
  - 관련 Action은 최종적으로 하둡의 맵리듀스 프로그램을 기반으로 작동
  - 실행 중인 태스크의 라이프 사이클을 우지 서버가 시작부터 종료까지 추적하면서 모니터링 정보 제공
- 활용 방안
  - 후처리 작업을 정의하고 프로세스화
  - 적재된 데이터를 External -> Managed -> Mart로 이동시키기 위해 다양한 하이브QL들이 이용되고, 이를 약속된 시간에 따라 스케줄링해서 실행하는데 이때 우지 워크플로 사용

### 휴 Hue
- 다양한 하둡 에코시스템들의 기능들을 웹 UI로ㅗ 통합 제공
- 아키텍처
  - 하둡 에코시스템들을 통합하기 위해 자체 플러그인을 설치하거나 API를 연동해서 에코시스템들의 주요 기능들을 웹 UI로 제공
  - 휴 데이터베이스에서는 휴에 로그인하는 사용자의 계정 관리와 휴에서 사용할 컴포넌트(잡, 하이브, 피그, 우지 등)의 메타정보 등을 관리
- 활용 방안
  - HDFS, HBase, 하이브, 임팔라를 편리하게 사용하기 위한 웹 에디터 제공
  - 데이터를 직관적으로 탐색 가능
  - 데이터 임포트 작업 진행
  - 주제 영역별 데이터웨어하우스 작업을 위해 휴의 Job Designer를 이용해 우지의 워크플로 5개를 주제영역별로 작성하고 실행

## 빅데이터 분석
- 기술 분석: 분석 초기 데이터의 특징을 파악하기 위해 선택, 집계, 요약 등 양적 기술 분석 진행
- 탐색 분석: 업무 도메인 지식을 기반으로 대규모 데이터셋의 상관관계나 연관성 파악
- 추론 분석: 전통적인 통계분석 기법으로 문제에 대한 가설을 세우고 샘플링을 통해 가설 검증
- 인과 분석: 문제 해결을 위한 원인과 결과 변수를 도출하고 변수의 영향도 분석
- 예측 분석: 대규모 과거 데이터를 학습해 예측 모형을 만들고, 최근의 데이터로 미래 예측

## 빅데이터 분석 활용 기술
### 임팔라 Impala
- 실시간 빅데이터 분석 질의 가능
- 빅데이터 분석을 인메모리 기반의 실시간 온라인 분석으로
- 아키텍처
  - 하둡의 분산 노드에서 대규모 실시간 분석을 위해 Impalad, Statestored, Catalogd라는 컴포넌트 설치
  - Impalad: HDFS의 분산 노드 상에서 실행 계획과 질의 작업을 수행하는 데몬
  - Statestored: Impalad의 기본 메타 정보부터 각 분산 노드에 설치돼 있는 Impalad를 관리하는 역할
  - Catalogd: Impalad와 Statestored와 통신하면서 임팔라 SQL의 실행과 변경 이력을 관리
- 활용 방안
  - 하이브 쿼리를 임팔라 쿼리로 바꾸고 실시간 탐색 가능
  - 하이브 쿼리는 대부분 임팔라 쿼리와 호환 가능,
  - 임팔라가 하이브 대비 빠른 응답 속도 보장

### 제플린 zeppelin
- 스파크 기반
- 대용량 데이터를 효과적으로 탐색 및 분석하기 위해 대용량 데이터셋을 빠르게 파악하고 이해하기 위한 분석 및 시각화 툴
- R의 경우, 하둡의 분산 파일을 직접 참조할 수 없고 분산 병렬처리가 어려움
- ㄴ RHive, RHadoop, RHipe 같은 도구로 HDFS와 직접 연결해 병렬처리가 가능하도록 구성할 수 있지만 복잡도가 낲아지고 안정적인 사용을 위해서 추가 비용 발생
- 아키텍처
  - 웹UI의 노트북에서 스파크 또는 스파크SQL을 작성해 하둡 클러스터에 작업을 요청하고, 처리 결과를 다시 웹UI에서 시각화해서 볼 수 있음
  - 제플린의 클라이언트와 서버 사이에는 REST 또는 웹소켓 통신을 요청하게 됨
  - 요청된 결과에 해당하는 인터프리터가 작동해서 타깃 시스템에 작업을 요청하게 됨
  - 스파크 뿐만 아니라 다양한 확장 인터프리터(스파크, 하이브, 플링크, R, 카산드라 등) 제공
- 활용 방안
  - 주제 영역별 마트에 접근해 데이터를 추출, 처리, 분석하고 그 결과를 제플린의 시각화 기능을 이용해 다양하게 분석

### 머하웃 Mahout
- 하둡 생태계에서 머신러닝 기법을 이용해 데이터 마이닝을 수행하는 툴
- 그동안의 머신러닝 툴은 대규모의 데이터셋을 분석할 수 있게 설계되지 않았고 분산 환경에서 실행 어려움 -> 머하웃은 하둡에서 분산 머신러닝
- 아키텍처
  - 하둡의 분산 환경 위에 맵리듀스를 기반으로 고급 분석을 지원하는 라이브러리 패키지
  - 하둡 클러스터 관점에서 보면 머하웃의 머신러닝 알고리즘이 맵리듀스에서 작동하도록 구현됐기 때문에 선형 확장으로 대규모(테라급 이상) 머신러닝 작업이 가능한 아키텍처를 가지고 있음
  - 주요 라이브러리: 추천, 분류, 군집
- 활용 방안
  - 상품 추천
  - 군집 분석을 통한 고객군 적정 개수 파악

### 스쿱 Sqoop
- RDBMS와 HDFS 사이에서 데이터를 편리하게 임포트하거나 익스포트해주는 소프트웨어
- ㄴ RDBMS에 있는 데이터를 특별한 전처리 없이 곧바로 HDFS에 적재하거나 반대로 HDFS에 저장된 데이터를 RDBMS로 제공해야 하는 경우
- 아키텍처
  - 아키텍처1: 스쿱의 CLI로, 임포트, 익스포트 명령을 하둡에 전달하면 맵 태스크가 병렬로 실행되어 외부 데이터베이스와 HDFS 사이에서 대향의 데이터를 임포트 및 익스포트
  - 아키텍처2: 아키텍처1 확장해서 스쿱 서버 추가, 스쿱1에서 클라이언트마다 설치됐던 커넥터와 라이브러리를 스쿱 서버에 배치하고 스쿱의 임포트, 익스포트 기능을 REST API로 제공해서 클라이언트 경량화, 접근 통제 가능
- 활용 방안
  - 분석된 결과를 RDBMS 시스템에 편리하게 제공하기 위한 도구로 활용 
- 원래 스쿱은 하둡 생태계에서는 수집 기술로 분류됨!