# 실무로 배우는 빅데이터 기술


## HDFS
- 대용량 파일 적재
- 실시간 및 대량으로 발생하는 작은 메시지 데이터를 저장할 경우 파일의 수가 기하급수적으로 늘어남 -> 관리노드와 병렬 처리의 효율성이 크게 떨어짐
- 보안하기 위해 NoSQL, 인메모리 캐시, MoM 등을 선택적으로 사용할 수 있는 아키텍처링 필요

## 접근제어 보안
### 아파치 녹스 Apache Knox
- 네크워크상의 DMZ에 위치시킴으로써 외부 클라이언트가 하둡 에코시스템에 직접 접근하는 것을 막음
  - DMZ: 클라이언트와 하둡에코시스템의 사이, 각 영역 사이에는 방화벽이 있음
- 항상 녹스를 거쳐 통신하게 하는 중간 게이트웨이 역할
- 이때 들어온 요청에 대한 접근 인증을 LDAP로 제공받을 수 있음

### 아파치 센트리 Apache Sentry
- 하둡파일 시스템에 상세한 접근제어(하둡 파일/디렉터리, 하이브 테이블 등)가 필요할 때 사용
- 하둡 데이터에 접근하려는 클라이언트는 센트리 에이전트를 반드시 설치해야 함
- 센트리 에이전트가 서버와 통신하면서 접근 권한을 획득하게 됨
- 접근 이력을 관리하는 기능이 있어 향후 감사 로그를 편리하게 조회 가능

### 아파치 레인저 Apache Ranger
- 레인저가 지원하는 에코시스템이 많아 아파치 센트리에 비해 범용성이 좀 더 높은 편
- 레인저를 사용할 경우 플러그인을 통해 레인저 서버와 통신하게 됨
- 접근 이력을 관리하는 감사 로그 기능 제공

### 커베로스 Kerberos
- 빅데이터 외에도 이미 다양한 곳에서 활용되고 있는 범용화된 시스템
- AS(Authentication Service): 인증서버
- TGS(Ticket Granting Service): 티켓 발행 서버
- 하둡 파일 시스템에 접근하려는 클라이언트 에코시스템은 AS 인증서버를 통해 최초 인증을 수행
- TGS 티켓 발행 서버로부터 하둡 파일시스템에 접근을 허용하는 티켓을 발행받음
- 이후부터는 유효한 티켓만 있으면 하둡 파일시스템에 인증없이 접근할 수 있음

## 빅데이터 수집 기술
### 플럼 Flume
- 빅데이터를 수집할 때 다양한 수집 요구사항들을 해결하기 위한 기능으로 구성된 소프트웨어
- 플럼 아키텍처: Source, Channel, Sink
  - Source: 데이터 로드
  - Channel: 데이터 임시 저장
  - Sink: 목적지에 데이터 최종 적재
- 활용 방안: 스마트카에서 발생하는 로그를 직접 수집하는 역할 담당

### 카프카 Kafka
- MOM 소프트웨어 중 하나
- 대규모로 발생하는 메시지성 데이터를 비동기 방식으로 중계하는 역할
- 원천 시스템으롭터 대규모 트랜잭션 데이터가 발생했을 때 중간에 데이터를 버퍼링하면서 타깃 시스템에 안정적으로 전송해주는 역할
- 카프카 아키텍처: 주키퍼를 반드시 이용해야 함
- 활용 방안
  - 플럼이 실시간 데이터를 수집해 카프카 토픽에 전송하면 카프카는 전송받은 데이터를 토픽에 임시 저장하고 있다가 컨슈머 프로그램이 작동해 토픽에서 데이터를 가져감
  - 플럼이 아주 빠르게 발생하는 데이터를 실시간으로 수집하게되면 이를 최종 목적지에 전달하기 전 중간에서 안정적인 버퍼링 처리가 필요해서
  - 카프카와 같은 대규모 중간 저장소가 완충역할 -> 안정적인 수집 아키텍처 구성 가능

## 빅데이터 적재 기술
### 하둡 Hadoop
- 대용량 데이터 분산 저장
- 분산 저장된 데이터 가공/분석 처리 기능: 분산 병렬 처리 기술 사용
  - 맵리듀스 MapReduce: 아래 두가지를 쉽고 편리하게 지원하는 프레임워크
  - 분산 병렬 처리에서의 핵심은 여러 컴퓨터에 분산 저장돼 있는 데이터로부터 어떻게 효율적으로 일을 나눠서(map) 실행시킬 수 있느냐
  - 다음으로 여러 컴퓨터가 나눠서 실행한 결과들을 어떻게 하나로 모으냐(reduce)
- 활용 방안
  - HDFS의 특정 디렉터리에 일자 단위로 파티션하여 저장하기 위해 하이브를 사용하는데, 대규모 하이브 작업을 위해 맵리듀스 프로세스가 내부적으로 작동

### 주키퍼 Zookeeper
- 빅데이터 분산 환경을 더욱 효율적으로 관리하기 위해 서버 간의 정보를 쉽고 안전하게 공유해야 함
- 공유된 정보를 이용해 서버 간의 중요한 이벤트를 관리하면서 상호작용을 조율해주는 코디네이터 시스템 필요 -> 분산 코디네이터인 주키퍼
- 주키퍼는 하둡, HBase, 카프카, 스톰 등의 분산 노드 관리에 사용 중
- 주키퍼 아키텍처
  - 3대 이상의 홀수 개의 서버로 구성돼야 함
  - 리더 서버: 반드시 1개 서버 -> 다른 모든 팔로워 서버에 요청받은 ZNode 정보를 브로드캐스트함
  - 팔로워 서버: 나머지 서버 -> 팔로워 서버 1에 저장된 ZNode 정보는 리더서버에 전달됨
- 활용 방안: 하둡, HBase, 카프카, 스톰의 내부에서 주키퍼에 의존해 클러스터 멤버십 기능 및 환경설정의 동기화 등을 사용하고 있음