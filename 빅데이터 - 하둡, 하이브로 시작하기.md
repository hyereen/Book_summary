# 빅데이터 - 하둡, 하이브로 시작하기
- https://wikidocs.net/book/2203

## 2-빅데이터 처리단계
### 정제
- Identification: 알려진 다양한 데이터 포맷이나 비정형 데이터에 할당된 기본 포맷을 식별
- Filtration: 수집된 정보에서 정확하지 않은 데이터는 제외
- Validation: 데이터 유효성을 검증
- Noise Reduction: 오류 데이터를 제거, 분석 불가능한 데이터는 제외
- Transformation: 데이터를 분석 가능한 형태로 변환
- Compression: 저장장치 효율성을 위해 변환한 데이터를 압축
- Integration: 처리 완료한 데이터를 적재

## 3-빅데이터 에코시스템
### 데이터 직렬화
- 빅데이터 에코시스템이 다양한 기술과 언어로 구현되기 때문에 각 언어간에 내부 객체를 공유해야 하는 경우가 있음
- 이를 효율적으로 처리하기 위해 데이터 직렬화 기술 이용

### 에이브로 Avro
- 아파치 하둡 프로젝트에서 개발된 원격 프로시저 호출(RPC) 및 데이터 직렬화 프레임워크
  - 원격 프로시저 호출(영어: remote procedure call, 리모트 프로시저 콜, RPC)은 별도의 원격 제어를 위한 코딩 없이 다른 주소 공간에서 함수나 프로시저를 실행할 수 있게하는 프로세스 간 통신 기술
- 자료형과 프로토콜 정의를 위해 JSON을 사용
- 콤팩트 바이너리 포맷으로 데이터 직렬화

### 스리프트 Thrift
- 페이스북에서 개발한 서로 다른 언어로 개발된 모듈의 통합을 지원하는 RPC 프레임워크
- 데이터 타입과 서비스 인터페이스를 선언하면, RPC 형태의 클라이언트와 서버 코드를 자동으로 생성해줌
- 자바, C++, C#, Perl, PHP, 파이썬 등 다양한 언어 지원

### 프로토콜 버터 Protocol Buffers
- 구글에서 개발한 RPC 프레임워크 
- 구조화된 데이터를 직렬화하는 방식을 제공
- 직렬화 속도가 빠르고 직렬화된 파일의 크기도 작아서 Apache Avro 파일 포맷과 함께 많이 사용됨

### 저장
### 하둡 분산 파일 시스템 HDFS, Hadoop distributed file system
- 하둡 프레임워크를 위해 자바 언어로 작성된 분산 확장 파일 시스템
- 범용 컴퓨터를 클러스터로 구성
- 대용량의 파일을 블록단위로 분할하여 여러서버에 복제하여 저장

### HBase
- DFS 기반의 칼럼 기반 NoSQL 데이터베이스
- 실시간 랜덤 조회 및 업데이트가 가능
- 각 프로세스는 개인의 데이터를 비동기적으로 업데이트 가능
- 기본 동작단위 - 칼럼
- H마스터가 H리전을 관리하하는 구조
- 주키퍼거 H마스터를 관리하여 SPOF를 회피
  - SPOF: 단일 장애 지점, 동작하지 않으면 전체 시스템이 중단되는 요소