# 빅데이터 - 하둡, 하이브로 시작하기
- https://wikidocs.net/book/2203

## 2-빅데이터 처리단계
### 정제
- Identification: 알려진 다양한 데이터 포맷이나 비정형 데이터에 할당된 기본 포맷을 식별
- Filtration: 수집된 정보에서 정확하지 않은 데이터는 제외
- Validation: 데이터 유효성을 검증
- Noise Reduction: 오류 데이터를 제거, 분석 불가능한 데이터는 제외
- Transformation: 데이터를 분석 가능한 형태로 변환
- Compression: 저장장치 효율성을 위해 변환한 데이터를 압축
- Integration: 처리 완료한 데이터를 적재

## 3-빅데이터 에코시스템
### 데이터 직렬화
- 빅데이터 에코시스템이 다양한 기술과 언어로 구현되기 때문에 각 언어간에 내부 객체를 공유해야 하는 경우가 있음
- 이를 효율적으로 처리하기 위해 데이터 직렬화 기술 이용

### 에이브로 Avro
- 아파치 하둡 프로젝트에서 개발된 원격 프로시저 호출(RPC) 및 데이터 직렬화 프레임워크
  - 원격 프로시저 호출(영어: remote procedure call, 리모트 프로시저 콜, RPC)은 별도의 원격 제어를 위한 코딩 없이 다른 주소 공간에서 함수나 프로시저를 실행할 수 있게하는 프로세스 간 통신 기술
- 자료형과 프로토콜 정의를 위해 JSON을 사용
- 콤팩트 바이너리 포맷으로 데이터 직렬화

### 스리프트 Thrift
- 페이스북에서 개발한 서로 다른 언어로 개발된 모듈의 통합을 지원하는 RPC 프레임워크
- 데이터 타입과 서비스 인터페이스를 선언하면, RPC 형태의 클라이언트와 서버 코드를 자동으로 생성해줌
- 자바, C++, C#, Perl, PHP, 파이썬 등 다양한 언어 지원

### 프로토콜 버터 Protocol Buffers
- 구글에서 개발한 RPC 프레임워크 
- 구조화된 데이터를 직렬화하는 방식을 제공
- 직렬화 속도가 빠르고 직렬화된 파일의 크기도 작아서 Apache Avro 파일 포맷과 함께 많이 사용됨

### 저장
### 하둡 분산 파일 시스템 HDFS, Hadoop distributed file system
- 하둡 프레임워크를 위해 자바 언어로 작성된 분산 확장 파일 시스템
- 범용 컴퓨터를 클러스터로 구성
- 대용량의 파일을 블록단위로 분할하여 여러서버에 복제하여 저장

### HBase
- DFS 기반의 칼럼 기반 NoSQL 데이터베이스
- 실시간 랜덤 조회 및 업데이트가 가능
- 각 프로세스는 개인의 데이터를 비동기적으로 업데이트 가능
- 기본 동작단위 - 칼럼
- H마스터가 H리전을 관리하하는 구조
- 주키퍼거 H마스터를 관리하여 SPOF를 회피
  - SPOF: 단일 장애 지점, 동작하지 않으면 전체 시스템이 중단되는 요소

### 데이터 처리 
### 맵리듀스 MapReduce
- HDFS 상에서 동작하는 가장 기본적인 분석 기술
- 간단한 단위 작업을 반복할 때 효율적인 맵리듀스 모델을 사용히여 데이터 분석

### 스파크 Spark
- 인메모리 기반의 범용 데이터 처리 플랫폼
- ㄴ 인메모리: 인-메모리 컴퓨팅은 메모리 내에서 데이터의 저장 뿐 아니라 데이터의 연산까지 수행하는 최첨단 칩 기술,메모리 내 대량의 정보를 이동 없이 메모리 내에서 병렬 연산하기 때문에 전력 소모가 낮음

### 임팔라 Impala
- 하둡 기반 분산 쿼리 엔진
- 맵리듀스를 사용하지 않고, C++로 개발한 인메모리 엔진을 사용해 빠른 성능을 보여줌
- 데이터 조회를 위한 인터페이스로 HiveQL 사용

### 프레스토 Presto
- 대화형 질의를 처리하기 위한 분산 쿼리 엔진
- 메모리 기반으로 데이터 처리
- 다양한 데이터 저장소에 저장된 데이터를 SQL로 처리 가능

### 하이브 Hive
- 하둡 기반의 데이터웨어하우징용 솔루션
- SQL과 애무 유사한 HiveQL 사용
- ㄴ HiveQL은 내부적으로 맵리듀스 잡으로 변환되어 실행됨

### HCatalog
- Pig, MapReduce, Spark에서 Hive 메타스토어 테이블에 액세스할 수 있는 도구
- 테이블을 생겅하거나 기타 작업을 수행할 수 있는 REST 인터페이스 및 커맨드라인 클라이언트 제공

### 피그 Pig
- 복잡한 맵리듀스 프로그래밍을 대체할 피그 라틴(Pig Latin)이라는 자체 언어를 제공
- 맵리듀스 API를 매우 단순화한 형태
- SQL과 유사한 형태로 설계되었음
- 다만 기존 SQL 지식을 활용하기 어려움

### 클러스터 관리
### 얀 YARN
- 데이터 처리 작업을 실행하기 위한 클러스터 자원(CPU, 메모리, 디스크 등)과 스케쥴링을 위한 프레임워크
- 기존 하둡의 맵리듀스의 단점을 극복하기 위해 시작됨
- 맵리듀스, 하이브, 임팔라, 타조, 스파크 등 다양한 애플리케이션들은 얀에서 리소스를 할당받아서 작업을 실행하게 됨

### 메소스 Mesos
- 클라우드 인프라 및 컴퓨팅 엔진의 다양한 자원(CPU, 메모리, 디스크)을 통합적으로 관리할 수 있도록 만든 자원 관리 프로젝트
- 클러스터링 환경에서 동적으로 자원을 할당하고 격리해주는 메커니즘 제공 -> 분산 환경에서 작업 실행을 최적화할 수 있음
- 1만대 이상의 노드에도 대응 가능

### 분산 서버 관리
- 클러스터에서 여러가지 기술이 이용될 때 하나의 서버에서 모든 작업이 진행되면 이 서버가 SPOF가 됨
- 이로 인한 리스크를 줄이기 위해 분산 서버 관리 기술 이용

### 주키퍼 Zookeeper
- 분산 환경에서 서버 간의 상호 조정이 필요한 다양한 서비스를 제공하는 시스템
- 역할
  - 하나의 서버에만 서비스가 집중되지 않게 서비스를 알맞게 분산해 동시에 처리하게 해줌
  - 하나의 서버에서 처리한 결과를 다른 서버와도 동기화해서 데이터의 안정성 보장
  - 운영 서버에 문제가 발생해서 서비스를 제공할 수 없는 경우, 다른 대기 중인 서버를 운영 서버로 바꿔서 서비스가 중지 없이 제공되게 함
  - 분산 환경을 구성하는 서버의 환경설정을 통합적으로 관리

### 시각화
### 휴 Hue
- 하둡과 하둡에코시스템의 지원을 위한 웹 인터페이스를 제공하는 오픈 소스
- Hive 쿼릴르 실행하는 인터페이스 제공
- 잡의 스케줄링, 잡, HDFS 등 모니터링하기 위한 인터페이스도 제공

### 보안
### 레인저 Ranger
- 하둡 클러스터의 각 모듈에 대한 보안 정책을 관리할 수 있음
- HDFS의 ACL, Hive 데이터베이스의 접근권한 등의 보안 정책과 각 모듈에 대한 접근 기록(Audit)을 보관함

### 데이터 거버넌스
- 기업의 여기저기 산재한 데이터를 같은 저장소에 관리
- 비정형 데이터를 규칙에 맞게 표준화하는 전사 차원의 빅데이터 관리 체계

### 아틀라스 Atlas
- 데이터 거버넌스로 조직이 보안/컴플라이언스 요구사항을 준수할 수 있도록 지원
- 데이터 자원에 대한 태깅, 다운스크림 데이터셋에 대한 태그전파, 메타 데이터 접그넹 대한 보안 등 다양한 기능을 가지고 있음
- 메타데이터 변경 알림 기능을 제공
- Hive, HBase, Kafka의 데이터가 변경되는 것을 알리는 기능 제공

### 아문센 Amundsen
- 데이터 디스커버리 플랫폼
- 기업에 존재하는 데이터를 검색하고 추천하는 기능을 가지고 있음
- 테이블 상세 페이지 지원

### 플룸 Flume
- 대량의 로그 데이터를 여러 소스에서 수집하여 저장하기 위한 목적으로 개발
- 데이터 수집 프레임워크
- 특징
  - 여러개의 플룸 에이전트를 연결하여 확장 가능
  - 다양한 연결 모드를 지원하여 최종 목적지에 데이터를 전달할 때 까지 유연한 구성 가능
  - 전달 받은 데이터를 메모리, File, DB에 임시 저장하여 오류 발생 시 복구 가능 -> 신뢰성 
- 구조
  - OG: master가 agent를 관리, 데이터가 집중되면 master의 병목현상 발생
    - Agent와 Collector의 설정 값을 변경해줄 때, Master도 함꼐 변경해줘야 하는 불편함이 있음 -> NG 개발
  - NG: MAster와 collector의 개념이 없고 OG의 agent 노드 구성에 해당 