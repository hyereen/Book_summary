# ADP 필기 데이터 분석 전문가 올패키지

# 1~3과목
p.72 1980년대 기업내부 데이터베이스
- OLPT On-Line Transaction Processing: 호스트 컴퓨터가 데이터베이스를 액세스하고, 바로 처리결과를 돌려보내는 형태
- OLAP On-Line Analytical Processing: 다양한 비즈니스 관점에서 쉽고 빠르게 다차원적인 데이터에 접근하여 의사 결정에 활용할 수 있는 정보를 얻을 수 있게 해주는 기술

p.75 분야별 데이터베이스 
- 금융 부문
  - EAI Enterprise Application Integration: 기업 내 상호 연관된 모든 애플리케이션을 유기적으로 연동하여 필요한 정보를 중앙 집중적으로 통합, 관리, 사용할 수 있는 환경을 구현한 것
- 유통 부문
  - KMS Knowledge Management System: 지식관리 시스템, 기업의 환경이 물품을 주로 생산하던 산업사회에서 지적 재산의 중요성이 커지는 지식사회로 이동함에 따라 기업 경영을 지식이라는 관점에서 새롭게 조명하는 접근 방식
  - RFID Radio Frequency: 주파수를 이용해 ID를 식별하는 시스템으로 일명 전자태그로 불림

p.128 ETL 개요
- ETL 기능
  - Extraction 추출: 하나 또는 그 이상의 데이터 원천들로부터 데이터 획득
  - Trasnformation 변형: 데이터 클렌징, 형식 변환, 표준화, 통합 또는 다수 애플리케이션에 내장된 비즈니스 룰 적용 등
  - Load 적재: 변형 단계의 처리가 완료된 데이터를 특정 목표 시스템에 적재
- MPP Massivley Parallel Processing: 프로그램을 여러 부분으로 나누어 여러 프로세스가 각 부분을 동시에 수행시키는 것으로 대규모 병렬 처리를 의미

p.130 ODS 구성
- ODS Operational Data Store: 데이터에 대한 추가 작업을 위해 다양한 데이터 원천들로부터 데이터를 추출, 통합한 데이터베이스
- ODS 내 데이터는 향후 비즈니스 지원을 위해 타 정보 시스템으로 이관되거나 다양한 보고서 생성을 위해 데이터 웨어하우스로 이관됨
- ODS는 일반적으로 실시간 또는 실시간 근접 트랜잭션 데이터 혹은 가격 등의 원자성(개별성)을 지닌 하위 수준 데이터들을 저장하기 위해 설계됨
- ODS는 현재 혹은 비교적 최근의 데이터를 저장하기 위해 설계된다는 것을 기억해야 함
- ODS 구성 단계
  - 인터페이스 단계: 다양한 데이터 원천으로부터 데이터를 획득
  - 데이터 스테이징 단계: 작업 일정이 통제되는 프로세스들에 의해 데이터 원천들로부터 트랜잭션 데이터들이 추출되어 하나 또는 그 이상의 스테이징 테이블들에 저장
  - 데이터 프로파일링 단계: 범위, 도메인, 유일성 확보 등의 규칙을 기준으로 데이터 품질 점검
  - 데이터 클렌징 단계: 클렌징 ETL 프로세스들로 데이터 프로파일링 단계에서 식별된 오류 데이터들을 수정
  - 데이터 인티그레이션 단계: 수정 완료한 데이터를 ODS 내의 단일 통합 테이블에 적재
  - 익스포트 단계: 통합된 데이터에 대해 익스포트 규칙과 보안 규칙을 반영한 익스포트 ETL 기능을 수행해 익스포트 테이블 생성 후 다양한 DBMS 클라이언트 또는 데이터 마트 등에 적재

p.135 데이터 웨어하우스 테이블 모델링 기법
- 스타 스키마 = 조인 스키마
  - 데이터 웨어하우스 스키마 중 가장 단순
  - 단일 Fact 테이블을 중심으로 다수의 Dimension 테이블로 구성됨
  - 전통적인 관계형 데이터베이스를 통해 다차원의 데이터베이스 기능 구현 가능
  - 스타스키마의 Fact 테이블은 보통 제3정규형으로 모델링
  - Dimension 테이블은 보통 비정규화된 제2정규형으로 모델링하는 것이 일반적
  - 장점: 복잡도가 낮아 이해하기 쉽고 쿼리 작성이 용이함, 조인 테이블 개수가 적음
  - 단점: Dimension 테이블의 비정규화에 따른 데이터 중복으로 인해 테이블로 데이터를 적재할 때 상대적으로 많은 시간이 소요됨
- 스노우 플레이크 스키마
  - 스타스키마의 Dimension 테이블을 제3정규형으로 정규화한 형태
  - 장점: 데이터 중복이 제거돼 데이터 적재 시 시간이 단축됨
  - 단점: 스타 스키마에 비해 스키마 구조의 복잡성이 증가하므로 조인 테이블의 개수가 증가하고 쿼리 작성 난이도 상승

p.137 CDC
- CDC Change Data Capture
  - 데이터베이스 내 데이터에 대한 변경을 식별해 필요한 후속처리(데이터 전송/공유 등)를 자동화하는 기술 또는 설계 기법이자 구조
  - 실시간 또는 근접 실시간 데이터 통합을 기반으로 하는 데이터 웨어하우스 및 기타 데이터 저장소 구축에 폭 넓게 활용됨
  - 스토리지 하드웨어 계층에서부터 애플리케이션 계층에 이르기까지 다양한 계층에서 다양한 기술을 통해 구현될 수 있음
  - 단일 정보 시스템 내 다수의 CDC 메커니즘이 구현돼 동작될 수 있음
- 구현 기법
  - Time Stamp on Rows
    - 변경이 반드시 인지되어야 하는 테이블 내 마지막 변경 시점을 기록하는 타임스탬프 칼럼을 둠
    - 마지막 변경 타임스탬프 값보다 더 최근의 타임스탬프 값을 갖는 레코드를 변경된 것으로 식별하는 기법
  - Version Numbers on Rows
    - 변경이 반드시 인지되어야 하는 테이블 내 해당 레코드의 버전을 기록하는 칼럼을 둠
    - 기 식별된 레코드 버전보다 더 높은 버전을 보유한 레코드를 변경된 것으로 식별하는 기법
    - 레코드들의 최신 버전을 기록, 관리하는 참조 테이블을 함꼐 운영하는 것이 일반적
  - Status on Rows
    - 타임스탬프 및 버전 넘버 기겁에 대한 보완 용도로 활용
    - 데이터 변경 여부를 T/F의 Boolean 값으로 저장하는 칼럼의 상태 값을 기반으로 변경 여부를 판단하는 기법
    - 더 높은 버전 넘버 또는 더 최근 갱신 타임스탬프를 보유한 레코드에 대한 변경 여부 판단을 사람이 직접 결정할 수 있도록 유보하는 등의 업무 규칙 적용 가능
  - Time/Version/Status on Rows
    - 타임스탬프, 버전 넘버, 상태 값의 세 가지 특성을 모두 활용하는 기법
    - 정교한 쿼리 생성에 활용해 개발 유연성 제공
  - Triggers on Tables
    - 데이터베이스 트리거를 활용해 사전에 등록된 다수 대상 시스템에 변경 데이터를 배포하는 형태로 CDC를 구현하는 기법
    - 데이터에비스 트리거는 시스템 관리 복잡도 증가, 변경 관리의 어려움, 확장성 감소를 유발하는 등 전반적인 시스템 유지보수성을 저하시키는 특성이 있어 사용에 주의를 요함
  - Event Programming 
    - 데이터 변경 식별 기능을 애플리케이션에 구현
    - 애플리케이션 개발 부담과 복잡도 증가
    - 다양한 조건에 의한 CDC 메커니즘 구현 가능
  - Log Scanner on Database
    - DBMS에서 제공하는 트랜잭션 로그에 대한 스캐닝 및 변경 내역에 대한 해석을 통해 CDC 메커니즘을 구현하는 기법
    - DBMS 마다 트랜잭션 로그 관리 메커니즘이 상이해 다수의 이기종 데이터베이스를 활용하는 환경에서 적용 시 작업 규모가 증가될 수 있어 주의
    - 장점: 데이터베이스와 사용 애플리케이션에 대한 영향도 최소화, 변경 식별 지연시간 최소화, 트랜잭션 무결성에 대한 영향도 최소화, 데이터베이스 스키마 변경 불필요
- CDC 구현 방식
  - 푸시 방식: 데이터 원천에서 변경을 식별하고 대상 시스템에 변경 데이터를 적재해주는 방식
  - 풀 방식: 대상 시스템에서 데이터 원천을 정기적으로 살펴보고, 필요 시 데이터를 다운로하는 방식

p.139 EAI
- EAI Enterprise Application Integration
  - 비즈니스 프로세스를 중심으로 기업 내 각종 애플리케이션간의 상호 연동이 가능하도록 통합하는 솔루션
  - 기업 내 또는 기업 간 상호 이질적 정보 시스템들의 데이터를 연계함으로써 상호 융화 내지 동기화돼 동작하도록 하는 것
  - 산재 되어 있는 애플리케이션을 프로세스 및 메시지 차원에서 통합 및 관리
  - EAI를 통해 비즈니스 프로세스를 자동화하고 실시간으로 통합 연계
  - ETL은 배치 프로세스 중심, EAI는 실시간 혹은 근접 실시간 처리 중심
- 데이터 연계 방식
  - Point to Point
    - 기존 데이터 연계 방식
    - 기준 마스터 데이터의 통합과 표준화가 불가능
    - 복잡한 데이터 연계 경로 발생으로 인해 유지보수성 저하, 관리비용 상승
  - Hub and Spoke
    - EAI 데이터 연계 방식
    - 가운데 지점에 허브 역할을 하는 브로커를 둠
    - 연결 대상 노드들의 데이터 연계 요구를 중계해줌으로써 노드 간 연결 개수 및 구조를 단순화하는 방식
    - ETL/CDC는 운영 데이터와 분석을 위한 데이터베이스가 구분되지만, EAI는 다수 정보 시스템의 데이터를 중앙의 허브가 연계하고 통합하는 기법
    - 각 연결의 대상이 되는 노드들은 Spoke에 해당함
- EAI 구성요소
  - 어댑터 Adapter: 각 정보 시스템과 EAI허브(엔진)간의 연결성 확보
  - 버스 BUS: 어댑터를 매개로 연결된 각 정보시스템들 간의 데이터 연동 경로
  - 브로커 Broker: 데이터 연동 규칙을 통제
  - 트랜스포머 Transformer: 데이터 형식 변환을 담당
- EAI 구현 유형
  - Mediation(Intra-Communication)
    - EAI 엔진이 중개자로 동작, 특정 정보 시스템 내의 데이터 신규 생성 및 갱신 등 이벤트 발생을 식별하여 미리 약속된 정보 시스템에 해당 내용을 전달
    - Publish/Subscribe Model이라고 부름
  - Federation(Inter-Communication)
    - EAI 엔진이 외부 정보시스템으로부터 데이터 요청들을 일괄적으로 수령해 필요한 데이터 전달
    - Request/Reply Model이라고 부름
- EAI 활용 효과
  - 정보 시스템 개발 및 유지보수 비용 절감
  - 기업 정보 시스템의 지속적 발전 기반 확보
  - 관련 데이터 동기화 등을 위한 데이터 표준화 기반 제공
- EAI와 ESB 비교

| 구분 | EAI                                          | ESB                     |
|-----|----------------------------------------------|------------------------|
 |기능  | 미들웨어(Hub)를 이용하여 비즈니스 로직을 중심으로 머플리케이션을 통합, 연계 | 미들웨어(Bus)를 이용하여 서비스를 중심으로 시스템을 유기적으로 연계|
 | 통합관점 | 어플리케이션 | 프로세스 |
 | 로직연동 | 개별 어플리케이션에서 수행 | ESB에서 수행|
 | 아키텍처 | 단일 접점인 허브시스템을 이용한 중앙집중식 연결구조 | 버스 형태의 느슨하고 유연한 연결구조 |

p.164 분산 파일 시스템
- 분산 데이터 저장 기술은 분산 파일시스템, 클러스터, 데이터베이스, NoSQL로 구분
  
p.164 구글 파일 시스템 GFS Google File System
- 구글의 대규모 클러스터 서비스 플랫폼의 기반이 되는 시스템
- 일반적 파일 시스템에서의 클러스터 및 섹터와 유사하게 고정된 크기(64mb)의 청크(chunk)들로 나누고, 각 chunk에 대한 여러 개의 복제본과 chunk를 청크 서버에 분산, 저장
- 청크서버들은 데이터를 자동으로 복사하여 저장하고, 주기적으로 청크 서버의 상태를 마스터에게 전달
- GFS에서는 chunk의 기본 크기를 64mb로 지정하고, 트리 구조가 아닌 해시 테이블 구조 등을 사용함으로써 메모리상에서 보다 효율적인 메타데이터의 처리를 지원
- chunk는 마스터에 의해 생성/삭제될 수 있고 유일한 식별자에 의해 구별됨
- 구성요소
  - 클라이언트
    - 파일 읽기/쓰기 동작을 요청하는 애플리케이션
    - POSIX 인터페이스 지원 X
    - 여러 클라이언트에서 원자적인 데이터 추가 연산을 지원하기 위한 인터페이스를 지원
  - 마스터
    - 단일 마스터 구조로 파일 시스템의 Name Space, 파일과 chunk의 매핑정보, 각 chunk가 저장된 청크서버들의 위치 정보 등에 해당하는 모든 메타데이터를 메모리상에서 관리
    - 주기적으로 수집되는 청크서버의 하트비트 메시지를 이용하여 chunk들의 상태에 따라 chunk를 재복제하거나 재분산하는 것과 같은 회복 동작 수행
    - 하나의 청크서버를 primary로 지정하여 복제본의 갱신 연산을 일관되게 처리할 수 있도록 보장

p.169 러스터 Lustre
- 틀러스터 파일 시스템에서 개발한 객체 기반의 클러스터 파일 시스템
- 계층화된 모듈 구조로 TCP/IP, 인피니밴드, 미리넷과 같은 네트워크 지원
- 구성 요소
  - 클라이언트 파일 시스템: 리눅스에서 설치할 수 있는 파일 시스템, 메타데이터 서버와 객체 저장 서버들과 통신하면서 클라이언트 응용에 파일 시스템 인터페이스 제공
  - 메타데이터 서버: 파일 시스템의 이름 공간과 파일에 대한 메타데이터를 관리
  - 객체 저장 서버: 파일데이터를 저장하고, 클라이언트로부터 객체의 입출력 요청을 처리, 데이터는 세그먼트라는 작은 데이터 단위로 분할해서 복수의 디스크 장치에 분산시키는 스트라이핑 방식으로 분산, 저장
- 구동 방식
  - 유닉스 시맨틱을 제공하면서 파일 메타데이터에 대해서는 라이트백 캐시를 지원
  - 클라이언트에서 메타데이터 변경에 대한 갱신 레코드를 생성하고 나중에 메타데이터 서버에 전달
    - 라이트백 캐시 Write Back Cache: 기본적으로 데이터를 캐시에만 저장하고, 어쩔 수 없이 캐시영역에서 밀려나는 경우에 하위 저장소에서 저장하는 데이터 갱신 방식

p.170 데이터베이스 클러스터
- 하나의 데이터베이스를 여러 개의 서버 상에 구축하는 것을 의미
- 데이터를 통합할 때, 성능과 가용성의 향상을 위해 데이터베이스 차원의 파티셔닝 또는 클러스터링을 이용함
- 데이터베이스 파티셔닝 구현 효과: 병렬처리, 고가용성, 성능향상
- 데이터베이스 클러스터 구분
  - 데이터베이스 시스템 구성 형태에 따라 단일 서버 내 파티셔닝 / 다중 서버 사이 파티셔닝
  - 리소스 공유 관점에 따라 공유 디스크와 무공유 디스크로 구분
    - 무공유 디스크 Shared Nothing
      - 무공유 클러스터에서 각 데이터베이스 인스턴스는 자신이 관리하는 데이터 파일을 자신의 로컬 디스크에 저장하며, 이 파일들은 노드 간에 공유하지 않음
      - 각 인스턴스나 노드는 완전히 분리된 데이터의 서브 집합에 대한 소유권을 가지고 있음, 각 데이터는 소유권을 갖고 있는 인스턴스가 처리
      - Oracle RAC(Real Application Cluster)를 제외한 대부분의 데이터베이스 클러스터가 무공유 방식 채택
      - 장점: 노드 확장 제한 없음
      - 단점: 각 노드에 장애가 발생할 경우를 대비해 별도의 폴트톨러런스를 fault-tolerance(시스템에 고장이 발생하더라도 모든 기능 혹은 기븡의 일부를 기존과 같이 유지하는 기술)를 구성해야 함
    - 공유 디스크 Shared Disk
      - 공유 디스크 클러스터에서 모든 데이터베이스 인스턴스 노드들은 데이터 파일을 공유하고 각 인스턴스는 모든 데이터 접근할 수 있음
      - 데이터를 공유하려면 SAN(Storage Area Network)과 같은 네트워크가 반드시 있어야 함
      - 모든 노드가 데이터를 수정할 수 있기 때문에 노드 간의 동기화 작업 수행을 위한 별도의 커뮤니케이션 채널 필요
      - 장점: 높은 수준의 폴트 톨러런스를 제공하므로 클러스터를 구성하는 노드 중 하나의 노드만 살아 있어도 서비스 가능
      - 단점: 클러스터가 커지면 디스크 영역에서 병목현상 발생

p.184 분산 컴퓨팅 기술
- 맵리듀스 MapReduce
  - 구글에서 분산 병렬 컴퓨팅을 이용하여 대용량 데이터를 처리하기 위한 목적으로 제작한 소프트웨어 프레임워크
  - 분할 정복 방식으로 대용량 데이터를 병렬처리할 수 있는 프로그래밍 모델
    - Divide and Conquer: 해결하고자 하는 문제를 성질이 같은 여러 부분으로 나누어 해결한 뒤, 원래 문제의 해를 구하는 방식
  - 프로그래밍 모델: Map과 Reduce
    - Map: Key와 Value의 쌍으로 입력받음
    - Reduce: Map함수를 거친 Key와 Value쌍이 프레임워크에 의해 Reduce에 전송되고 Reduce함수를 통해 최종 Output으로 산출됨
  - 모델 적용 적합성
    - 적합: 분산 Grep이나 빈도 수 계산 등의 작업
    - 부적합: 정렬과 같은 작업

p.192 병렬 쿼리 시스템
- 직접 코딩하지 않고도 쉽고 빠르게 적용할 수 있도록 스크립트나 쿼리 인터페이스를 통해 병렬처리할 수 있는 시스템
- 구글 Sawzall: 맵리듀스를 추상화한 최초의 스크립트 형태 병렬 쿼리 언어

p.200 클라우드 컴퓨팅
- 동적으로 확장할 수 있는 가상화 자원들을 인터넷으로 서비스하는 기술을 의미
- AWS EMR: 하둡을 온디맨드로 이용할 수 있는 클라우드 서비스
- 서버 가상화
  - 인프라 기술들 중 가장 기반이 되는 기술
  - 정의: 물리적인 서버와 운영체제 사이에 적절한 계층을 추가해 서버를 사용하는 사용자에게 물리적인 자원은 숨기고 논리적인 자원만을 보여주는 기술
  - 특징: 하나의 서버에서 여러 개의 애플리케이션, 미들웨어, 운영체제들이 서로 영향을 미치지 않으면서 동시에 사용할 수 있도록 해줌

p.202 CPU 가상화
- 하이퍼바이저 Hypervisor
  - 의미: 호스트 컴퓨터에서 다수의 운영체제를 동시에 실행하도록 하기 위한 논리적인 플랫폼
  - 물리적 서버 위에 존재하는 가상화 레이어를 통해 운영체제를 수행하는 데 필요한 하드웨어 환경을 가상으로 만들어줌
  - 서버 가상화 기술의 핵심으로 x86 계열 서버 가상화에서는 소프트웨어 기반으로 하이퍼바이저를 구성
  - 이를 통해 사용자는 추가 하드웨어 구밉 없이 새로운 운영체제 설치, 애플리케이션의 테스팅 및 업그레이터를 동일한 물리적 서버에서 동시 수행 가능
  - 기능
    - 하드웨어 환경 에뮬레이션
    - 실행환경 격리
    - 시스템 자원 할당
    - 소프트웨어 스택 보존
  - 위치와 기능에 따른 분류
    - 베어메달 하이퍼바어지 Bare-metal
      - 하드웨어와 호스트 운영체제 사이에 위치
      - 다시 반 가상화 Para Virtualization과 완전 가상화 Full Virtualization으로 구분 -> Privileged 명령어를 어떻게 처리하느냐를 기준으로 분류한 것 
    - 호스트 기반 하이퍼 바이저 Hosted
       - 호스트 운영체제와 게스트 운영체제 사이에 위치

p.212 I/O 가상화
- 하나의 물리적인 장비에 여러 개의 가상머신이 실행되고 있는 상황에서 가장 문제되는 것은 I/O의 병목현상
- CPU 자원의 파텨서닝만으로는 가상화 기술을 제대로 활용할 수 없으며, I/O자원의 공유 및 파티셔닝이 필요함
- 하나의 물리적인 머신에서 운영되는 가상머신 간에도 통신이 이루어져야 하며, 이를 위해 가상 디스크 어댑터, 가상 이더넷 어댑터, 공유 이더넷 어댑터 등과 같은 기술들이 사용됨
  - 이더넷 Ethernet: LAN에 사용되는 네트워크 모델, 하나의 버스 네트워크에 1042 개의 노트를 연결할 수 있는 근거리 통신망 하드웨어, 프로토콜, 케이블 표준
- 가상 이더넷
  - 대표적인 I/O 가상화 기술, 가상화 기능 중에서 물리적으로 존재하지 않는 자원을 만들어내는 에뮬레이션 기능
  - 별도의 물리적 어댑터와 케이블을 사용하지 않고도 네트워크 이중화, 네트워크 안정적 단절 등의 효과
- 공유 이더넷 어댑터
  - 여러 개의 가상 머신이 물리적인 네트워크 카드를 공유할 수 있게 하며, 공유된 물리적 카드를 통해서 외부 네트워크와 통신 가능
  - 이 경우도 하나의 자원을 여러 가상머신이 공유하기 때문에 발생하는 병목현상은 피할 수 없음
- 가상 디스크 어댑터
  - 한 대의 서버가 여러 개의 가상머신을 구성할 경우 외장 디스크를 사용할 수 있게 해주는 파이버 채널 어댑터와 같은 I/O 어댑터의 부족 문제를 해결하기 위한 것
  - 가상화된 환경에서 가낭 디스크를 이용해 가상머신이 디스크 자원을 획득하는 방법 -> 내장 디스크, 외장디스크

p.279 데이터 거버넌스 체계 수립
- 데이터 거버넌스: 전사 차원의 모든 데이터에 대해 정책, 지침, 표준화, 운영 조직 및 책임 등의 표준화된 관리 체계를 수립하고 운영을 위한 프레임워크 및 저장소를 구축하는 것
- 구성요소: 원칙, 조직, 프로세스
- 체계: 데이터 표준화, 데이터 관리 체계, 데이터 저장소 관리, 표준화 활동

# 5과목

p.10 사용가능한 데이터 확인
- 데이터 명세화: 차원과 측정값
  - 모든 데이터는 기본적으로 하나 이상의 측정값 Measure과 하나 이상의 차원 Dimension을 갖음
  - 측정값을 분류할 수 있는 모든 것이 차원이 될 수 있음
  - 연속적인 데이터로 구성된 차원은 구간 형태로 재구성되기도 함
  - 동일한 데이터 항목이라도 차원이 될 수 있고 측정값도 될 수 있음
- 데이터 구성 원리1: 이벤트 기록으로서 접근
  - 원본 데이터는 명세화의 기본 대상, 특정 이벤트가 발생했을 때 생성됨 
  - 데이터가 어떤 원리로 생성, 구성되었는지 염두해야 함, 대상들 간의 관계는 시각화 도구를 활용해 찾아낼 수 있음
- 데이터 구성 원리2: 객체지향 관점에서의 접근
  - 데이터 구성과 생성 배경에 대해 고민함으로써 어떻게 시각화할지 찾을 수 있음
  - 데이터의 구조 자체를 설계, 생성하여 이를 토대로 통찰을 찾을 수 있음
  - 기본적으로 대상을 객체화하며, 모든 객체들은 행위와 고유 속성 값을 갖게 됨
  - 구조의 행위를 통해 구조 전체를 파악하는 것이 객체지향 관점

p.16 비정형 데이터에서의 관계 탐색
- 워들 Wordle: 주어진 텍스트 데이터에서 의미를 갖는 형태소 단위를 추출한 뒤 그것들의 빈도를 계싼해 빈도에 따라 색상이나 크기를 결정한 시각화 기법

p.21 지표 설정과 분석
- 지표: 어떤 현상의 강도를 평가하는 기준이 되는 숫자
- 기본 구조
  - 앞서 도출한 관계를 무언가 하나의 지표로 축약해 표현하면 다른 관계를 살펴보기 위한 기준으로 삼기가 훨씬 편해짐
  - 지표는 기존 값들을 어떤 함수식에 적용한 결과
- 주의점
  - 지표 단위
  - 지표가 통계 모델 만들 때 포함되면, 모델 설명력이 과대평가 될 수 있음
  - 요인분석: 지표가 지표를 만든 다른 요인들과 상당 부분 설명력이 겹치는지의 여부 확인

p.23 통찰에 대한 필요성
- 기존 문제 해결방식이나 설명 모델의 수정
- 새로운 문제 해결 방식 도입
- 새롭게 발견한 가능성에 대한 구체적인 탐색과 발전

p.26 지표의 운영
- 관계는 보통 여러 차원과 측정값 사이의 패턴을 말해주기 때문에 지표를 활용한다는 것은 여러가지 관계를 다 살펴보는 부담을 덜어줌
- 몇 가지의 지표만 집중해봐도 다양한 관계들을 통해 나타나는 전체적인 흐름을 알 수 있음
- 인사이트 프로세스에서 추출한 지표를 중심으로 운영할 경우, 문제점 -> 바로 환산된 값을 중심으로 보다보니 정작 어떤 변화요인이 발생해 지표 흐름에 영향을 미쳤는지 찾아내기가 어려워짐
- 지표를 운영할 때는 지표의 장단점을 이해하고 인사이트의 발전과 확장 효율성을 높일 수 있는 방향으로 지표를 끌고갈 필요가 있음