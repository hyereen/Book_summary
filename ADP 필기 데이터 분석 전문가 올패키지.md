# ADP 필기 데이터 분석 전문가 올패키지

# 1과목: 데이터 이해
p.72 1980년대 기업내부 데이터베이스
- OLPT On-Line Transaction Processing: 호스트 컴퓨터가 데이터베이스를 액세스하고, 바로 처리결과를 돌려보내는 형태
- OLAP On-Line Analytical Processing: 다양한 비즈니스 관점에서 쉽고 빠르게 다차원적인 데이터에 접근하여 의사 결정에 활용할 수 있는 정보를 얻을 수 있게 해주는 기술

p.75 분야별 데이터베이스 
- 금융 부문
  - EAI Enterprise Application Integration: 기업 내 상호 연관된 모든 애플리케이션을 유기적으로 연동하여 필요한 정보를 중앙 집중적으로 통합, 관리, 사용할 수 있는 환경을 구현한 것
- 유통 부문
  - KMS Knowledge Management System: 지식관리 시스템, 기업의 환경이 물품을 주로 생산하던 산업사회에서 지적 재산의 중요성이 커지는 지식사회로 이동함에 따라 기업 경영을 지식이라는 관점에서 새롭게 조명하는 접근 방식
  - RFID Radio Frequency: 주파수를 이용해 ID를 식별하는 시스템으로 일명 전자태그로 불림

p.128 ETL 개요
- ETL 기능
  - Extraction 추출: 하나 또는 그 이상의 데이터 원천들로부터 데이터 획득
  - Trasnformation 변형: 데이터 클렌징, 형식 변환, 표준화, 통합 또는 다수 애플리케이션에 내장된 비즈니스 룰 적용 등
  - Load 적재: 변형 단계의 처리가 완료된 데이터를 특정 목표 시스템에 적재
- MPP Massivley Parallel Processing: 프로그램을 여러 부분으로 나누어 여러 프로세스가 각 부분을 동시에 수행시키는 것으로 대규모 병렬 처리를 의미

p.130 ODS 구성
- ODS Operational Data Store: 데이터에 대한 추가 작업을 위해 다양한 데이터 원천들로부터 데이터를 추출, 통합한 데이터베이스
- ODS 내 데이터는 향후 비즈니스 지원을 위해 타 정보 시스템으로 이관되거나 다양한 보고서 생성을 위해 데이터 웨어하우스로 이관됨
- ODS는 일반적으로 실시간 또는 실시간 근접 트랜잭션 데이터 혹은 가격 등의 원자성(개별성)을 지닌 하위 수준 데이터들을 저장하기 위해 설계됨
- ODS는 현재 혹은 비교적 최근의 데이터를 저장하기 위해 설계된다는 것을 기억해야 함
- ODS 구성 단계
  - 인터페이스 단계: 다양한 데이터 원천으로부터 데이터를 획득
  - 데이터 스테이징 단계: 작업 일정이 통제되는 프로세스들에 의해 데이터 원천들로부터 트랜잭션 데이터들이 추출되어 하나 또는 그 이상의 스테이징 테이블들에 저장
  - 데이터 프로파일링 단계: 범위, 도메인, 유일성 확보 등의 규칙을 기준으로 데이터 품질 점검
  - 데이터 클렌징 단계: 클렌징 ETL 프로세스들로 데이터 프로파일링 단계에서 식별된 오류 데이터들을 수정
  - 데이터 인티그레이션 단계: 수정 완료한 데이터를 ODS 내의 단일 통합 테이블에 적재
  - 익스포트 단계: 통합된 데이터에 대해 익스포트 규칙과 보안 규칙을 반영한 익스포트 ETL 기능을 수행해 익스포트 테이블 생성 후 다양한 DBMS 클라이언트 또는 데이터 마트 등에 적재

p.135 데이터 웨어하우스 테이블 모델링 기법
- 스타 스키마 = 조인 스키마
  - 데이터 웨어하우스 스키마 중 가장 단순
  - 단일 Fact 테이블을 중심으로 다수의 Dimension 테이블로 구성됨
  - 전통적인 관계형 데이터베이스를 통해 다차원의 데이터베이스 기능 구현 가능
  - 스타스키마의 Fact 테이블은 보통 제3정규형으로 모델링
  - Dimension 테이블은 보통 비정규화된 제2정규형으로 모델링하는 것이 일반적
  - 장점: 복잡도가 낮아 이해하기 쉽고 쿼리 작성이 용이함, 조인 테이블 개수가 적음
  - 단점: Dimension 테이블의 비정규화에 따른 데이터 중복으로 인해 테이블로 데이터를 적재할 때 상대적으로 많은 시간이 소요됨
- 스노우 플레이크 스키마
  - 스타스키마의 Dimension 테이블을 제3정규형으로 정규화한 형태
  - 장점: 데이터 중복이 제거돼 데이터 적재 시 시간이 단축됨
  - 단점: 스타 스키마에 비해 스키마 구조의 복잡성이 증가하므로 조인 테이블의 개수가 증가하고 쿼리 작성 난이도 상승

p.137 CDC
- CDC Change Data Capture
  - 데이터베이스 내 데이터에 대한 변경을 식별해 필요한 후속처리(데이터 전송/공유 등)를 자동화하는 기술 또는 설계 기법이자 구조
  - 실시간 또는 근접 실시간 데이터 통합을 기반으로 하는 데이터 웨어하우스 및 기타 데이터 저장소 구축에 폭 넓게 활용됨
  - 스토리지 하드웨어 계층에서부터 애플리케이션 계층에 이르기까지 다양한 계층에서 다양한 기술을 통해 구현될 수 있음
  - 단일 정보 시스템 내 다수의 CDC 메커니즘이 구현돼 동작될 수 있음
- 구현 기법
  - Time Stamp on Rows
    - 변경이 반드시 인지되어야 하는 테이블 내 마지막 변경 시점을 기록하는 타임스탬프 칼럼을 둠
    - 마지막 변경 타임스탬프 값보다 더 최근의 타임스탬프 값을 갖는 레코드를 변경된 것으로 식별하는 기법
  - Version Numbers on Rows
    - 변경이 반드시 인지되어야 하는 테이블 내 해당 레코드의 버전을 기록하는 칼럼을 둠
    - 기 식별된 레코드 버전보다 더 높은 버전을 보유한 레코드를 변경된 것으로 식별하는 기법
    - 레코드들의 최신 버전을 기록, 관리하는 참조 테이블을 함꼐 운영하는 것이 일반적
  - Status on Rows
    - 타임스탬프 및 버전 넘버 기겁에 대한 보완 용도로 활용
    - 데이터 변경 여부를 T/F의 Boolean 값으로 저장하는 칼럼의 상태 값을 기반으로 변경 여부를 판단하는 기법
    - 더 높은 버전 넘버 또는 더 최근 갱신 타임스탬프를 보유한 레코드에 대한 변경 여부 판단을 사람이 직접 결정할 수 있도록 유보하는 등의 업무 규칙 적용 가능
  - Time/Version/Status on Rows
    - 타임스탬프, 버전 넘버, 상태 값의 세 가지 특성을 모두 활용하는 기법
    - 정교한 쿼리 생성에 활용해 개발 유연성 제공
  - Triggers on Tables
    - 데이터베이스 트리거를 활용해 사전에 등록된 다수 대상 시스템에 변경 데이터를 배포하는 형태로 CDC를 구현하는 기법
    - 데이터에비스 트리거는 시스템 관리 복잡도 증가, 변경 관리의 어려움, 확장성 감소를 유발하는 등 전반적인 시스템 유지보수성을 저하시키는 특성이 있어 사용에 주의를 요함
  - Event Programming 
    - 데이터 변경 식별 기능을 애플리케이션에 구현
    - 애플리케이션 개발 부담과 복잡도 증가
    - 다양한 조건에 의한 CDC 메커니즘 구현 가능
  - Log Scanner on Database
    - DBMS에서 제공하는 트랜잭션 로그에 대한 스캐닝 및 변경 내역에 대한 해석을 통해 CDC 메커니즘을 구현하는 기법
    - DBMS 마다 트랜잭션 로그 관리 메커니즘이 상이해 다수의 이기종 데이터베이스를 활용하는 환경에서 적용 시 작업 규모가 증가될 수 있어 주의
    - 장점: 데이터베이스와 사용 애플리케이션에 대한 영향도 최소화, 변경 식별 지연시간 최소화, 트랜잭션 무결성에 대한 영향도 최소화, 데이터베이스 스키마 변경 불필요
- CDC 구현 방식
  - 푸시 방식: 데이터 원천에서 변경을 식별하고 대상 시스템에 변경 데이터를 적재해주는 방식
  - 풀 방식: 대상 시스템에서 데이터 원천을 정기적으로 살펴보고, 필요 시 데이터를 다운로하는 방식

p.139 EAI
- EAI Enterprise Application Integration
  - 비즈니스 프로세스를 중심으로 기업 내 각종 애플리케이션간의 상호 연동이 가능하도록 통합하는 솔루션
  - 기업 내 또는 기업 간 상호 이질적 정보 시스템들의 데이터를 연계함으로써 상호 융화 내지 동기화돼 동작하도록 하는 것
  - 산재 되어 있는 애플리케이션을 프로세스 및 메시지 차원에서 통합 및 관리
  - EAI를 통해 비즈니스 프로세스를 자동화하고 실시간으로 통합 연계
  - ETL은 배치 프로세스 중심, EAI는 실시간 혹은 근접 실시간 처리 중심
- 데이터 연계 방식
  - Point to Point
    - 기존 데이터 연계 방식
    - 기준 마스터 데이터의 통합과 표준화가 불가능
    - 복잡한 데이터 연계 경로 발생으로 인해 유지보수성 저하, 관리비용 상승
  - Hub and Spoke
    - EAI 데이터 연계 방식
    - 가운데 지점에 허브 역할을 하는 브로커를 둠
    - 연결 대상 노드들의 데이터 연계 요구를 중계해줌으로써 노드 간 연결 개수 및 구조를 단순화하는 방식
    - ETL/CDC는 운영 데이터와 분석을 위한 데이터베이스가 구분되지만, EAI는 다수 정보 시스템의 데이터를 중앙의 허브가 연계하고 통합하는 기법
    - 각 연결의 대상이 되는 노드들은 Spoke에 해당함
- EAI 구성요소
  - 어댑터 Adapter: 각 정보 시스템과 EAI허브(엔진)간의 연결성 확보
  - 버스 BUS: 어댑터를 매개로 연결된 각 정보시스템들 간의 데이터 연동 경로
  - 브로커 Broker: 데이터 연동 규칙을 통제
  - 트랜스포머 Transformer: 데이터 형식 변환을 담당
- EAI 구현 유형
  - Mediation(Intra-Communication)
    - EAI 엔진이 중개자로 동작, 특정 정보 시스템 내의 데이터 신규 생성 및 갱신 등 이벤트 발생을 식별하여 미리 약속된 정보 시스템에 해당 내용을 전달
    - Publish/Subscribe Model이라고 부름
  - Federation(Inter-Communication)
    - EAI 엔진이 외부 정보시스템으로부터 데이터 요청들을 일괄적으로 수령해 필요한 데이터 전달
    - Request/Reply Model이라고 부름
- EAI 활용 효과
  - 정보 시스템 개발 및 유지보수 비용 절감
  - 기업 정보 시스템의 지속적 발전 기반 확보
  - 관련 데이터 동기화 등을 위한 데이터 표준화 기반 제공
- EAI와 ESB 비교

| 구분 | EAI                                          | ESB                     |
|-----|----------------------------------------------|------------------------|
 |기능  | 미들웨어(Hub)를 이용하여 비즈니스 로직을 중심으로 머플리케이션을 통합, 연계 | 미들웨어(Bus)를 이용하여 서비스를 중심으로 시스템을 유기적으로 연계|
 | 통합관점 | 어플리케이션 | 프로세스 |
 | 로직연동 | 개별 어플리케이션에서 수행 | ESB에서 수행|
 | 아키텍처 | 단일 접점인 허브시스템을 이용한 중앙집중식 연결구조 | 버스 형태의 느슨하고 유연한 연결구조 |

p.164 분산 파일 시스템
- 분산 데이터 저장 기술은 분산 파일시스템, 클러스터, 데이터베이스, NoSQL로 구분
  
p.164 구글 파일 시스템 GFS Google File System
- 구글의 대규모 클러스터 서비스 플랫폼의 기반이 되는 시스템
- 일반적 파일 시스템에서의 클러스터 및 섹터와 유사하게 고정된 크기(64mb)의 청크(chunk)들로 나누고, 각 chunk에 대한 여러 개의 복제본과 chunk를 청크 서버에 분산, 저장
- 청크서버들은 데이터를 자동으로 복사하여 저장하고, 주기적으로 청크 서버의 상태를 마스터에게 전달
- GFS에서는 chunk의 기본 크기를 64mb로 지정하고, 트리 구조가 아닌 해시 테이블 구조 등을 사용함으로써 메모리상에서 보다 효율적인 메타데이터의 처리를 지원
- chunk는 마스터에 의해 생성/삭제될 수 있고 유일한 식별자에 의해 구별됨
- 구성요소
  - 클라이언트
    - 파일 읽기/쓰기 동작을 요청하는 애플리케이션
    - POSIX 인터페이스 지원 X
    - 여러 클라이언트에서 원자적인 데이터 추가 연산을 지원하기 위한 인터페이스를 지원
  - 마스터
    - 단일 마스터 구조로 파일 시스템의 Name Space, 파일과 chunk의 매핑정보, 각 chunk가 저장된 청크서버들의 위치 정보 등에 해당하는 모든 메타데이터를 메모리상에서 관리
    - 주기적으로 수집되는 청크서버의 하트비트 메시지를 이용하여 chunk들의 상태에 따라 chunk를 재복제하거나 재분산하는 것과 같은 회복 동작 수행
    - 하나의 청크서버를 primary로 지정하여 복제본의 갱신 연산을 일관되게 처리할 수 있도록 보장