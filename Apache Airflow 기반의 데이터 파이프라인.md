# PART 1 기본편

## CHAPTER 1 Apache Airflow 살펴보기
### p.4 1.1 데이터 파이프라인 소개
- 방향성 비순환 그래프 Directed Acyclic Graph, DAG
  - 그래프는 화살표 방향성의 끝점을 포함하되 반복이나 순환을 허용하지 않음(비순환)
  - 비순환 속성은 태스크 간의 순환 실행을 방지하기 때문에 매우 중요함

#### p.9 1.1.4 워크플로 매니저를 이용한 파이프라인 실행
- 워크플로 매니저마다 워크플로 정의 방식의 차이가 있음
  - Oozie는 정적 파일(XML)을 사용하여 워크플로를 정의하기 때문에 읽기 쉽지만 유연하지 않음
  - Luigi와 Airflow는 코드로 워크플로 정의 가능 -> 좀 더 유연하지만 읽기 및 테스트는 어려울 수 있음(워크플로 구현하는 코딩 능력에 따라 잘라짐)
- 워크플로 관리자가 제공하는 기능 범위
  - Make나 Luigi는 워크플로 스케줄을 위한 기본 기능 제공 X -> 반복 스케줄로 워크플로를 실행하기 위해서는 Cron과 같은 추가 도구를 사용해야 함

### p.10 1.2 Airflow 소개
#### p.10 1.2.1 파이썬 코드로 유연한 파이프라인 정의
- 파이프라인이나 워크플로 태스크를 방향성 비순환 그래프(DAG)로 정의 가능
- 태스크는 노드로 정의하고 의존성은 태스크 노드 사이에 화살표로 정의함
- 파이썬 스크립트로 DAG 구조를 설명하고 구상함
- 일반적으로 DAG 파일은 주어진 DAG에 대한 태스크 집합과 태스크 간의 의존성을 기술하고, Airflow는 DAG 구조를 식별하기 위해 코드를 파싱함
- Airflow DAG를 파이썬 코드로 정의하여 많은 유연성 제공 가능

#### p.11 1.2.2 파이프라인 스케줄링 및 실행
- Airflow 주요 구성 요소
  - Airflow 스케줄러: DAG를 분석하고 현재 시점에서 DAG의 스케줄이 지난 경우 Airflowㅇ 워커에 DAG의 태스크를 예약
  - Airflow 워커: 예약된 태스크를 선택하고 실행함
  - Airflow 웹서버: 스케줄러에서 분석한 DAG를 시각화하고 DAG 실행과 결과를 확인할 수 있는 주요 인터페이스 제공

#### p.16 1.2.4 점진적 로딩 및 백필
- Airflow의 스케줄 기능 중 강력한 장점
  - DAG에 정의된 특정 시점에 트리거할 수 있음
  - 최종 시점과 예상되는 다음 스케줄 주기를 상세하게 알려주는 것 -> 각각의 주기로 나누고 각 주기별로 DAG 실행 가능
- Airflow의 특성은 데이터 파이프라인을 점진적으로 실행할 수 있도록 구성이 가능하기 때문에 효율적인 데이터 파이프라인 구축 가능
- 점진적인 파이프라인에서 각 DAG는 매번 전체 데이터 세트를 다시 처리할 필요 없이 해당 시간 슬롯에 대한 데이터만 처리 가능
- 대규모 데이터 세트를 처리해야 할 경우, 기존 결과에 대한 태스크 전체를 다시 수행하는 것을 방지하여 많은 시간, 비용 절감 가능
- 스케줄 주기가 백필 개념과 결합하여 더욱 강력하게 활용 가능
  - 이를 통해 새로 생성한 DAG를 과거 시점 및 기간에 대해 실행 가능
  - 과거 특정 기간에 대해 DAG를 실행해 새로운 데이터를 손쉽게 생성 (또는 백필)할 수 있음
  - 과거 실행 결과를 삭제한 다음, 태스크 코드를 변경한 후에 삭제된 과거 태스크를 쉽게 재실행할 수 있기 때문에 필요할 때 전체 데이터 세트를 간단하게 재구성해 처리 가능

### p.16 1.3 언제 Airflow를 사용해야 할까
#### p.17 1.3.1 Airflow를 선택하는 이유
- 파이썬 코드를 이용해 파이프라인 구현 -> 복잡한 커스텀 파이프라인 구현 가능
- 다양한 시스템과의 통합 가능
- 수많은 스케줄링 기법 -> 파이프라인 정기적 실행하고 점진적 증분 처리를 통해 전체 파이프라인을 재실행할 필요 없는 효율적인 파이프라인 구축 가능
- 백필 기능 -> 과거 데이터 손쉽게 재처리 할 수 있기 때문에 코드를 변경한 후 재생성이 필요한 데이터 재처리 가능
- Airflow 웹 인터페이스 -> 파이프라인 실행 결과 모니터링 가능, 오류 디버깅을 위한 뷰 제공
- 오픈 소스

#### p.17 1.3.2 Airflow가 적합하지 않은 경우
- Airflow는 반복적이거나 배치 태스크를 실행하는 기능에 초점이 맞춰져 있기 때문에, 스트리밍 워크플로 및 파이프라인 처리에는 적합하지 않을 수 이음
- 추가 및 삭제 태스크가 빈번한 동적 파이프라인의 경우 적합하지 않을 수 있음 -> Airflow는 동적 태스크를 구현할 수 있지만, 웹 UI는 DAG의 가장 최근 실행 버전에 대한 정의만 표현해줌. 따라서 Airflow는 실행되는 동안 구조가 변경되지 않은 파이프라인에 좀 더 적합함
- 파이썬 코드로 DAG를 작성하는 것은 파이프라인 규모가 커지면 굉장히 복잡해질 수 있음 -> 초기 사용 시점부터 엄격한 관리 필요


## CHAPTER 2 Airflow DAG의 구조
### p.23 첫 번째 Airflow DAG 작성
#### p.27 2.1.1 태스크와 오퍼레이터 차이점 
- 오퍼레이터
  - 단일 작업 수행 역할
  - BashOperator: 배시 스크립트를 실행하는 데 사용됨
  - PythonOperator: 파이썬 함수를 실행하는 데 사용됨
  - SimpleHTTPOperator: HTTP 엔드포인트 호출
- DAG
  - 오퍼레이터 집합에 대한 실행을 오케스트레이션(조정, 조율)하는 역할
  - 오퍼레이터의 시작과 정지, 오퍼레이터가 완료되면 다음 태스크의 시작, 그리고 오퍼레이터 간 의존성 보장됨
- 태스크
  - 작업의 올바른 실행을 보장하기 위한 오퍼레이터의 wrapper 또는 manager로 생각해볼 수 있음
  - 오퍼레이터의 상태를 관리하고 사용자에게 상태 변경(예: 시작/완료)를 표시하는 에어플로우의 내장 컴포넌트

### p.36 2.4 스케줄 간격으로 실행하기
- DAG를 일정 시간 간격으로 실행할 수 있도록 스케줄 설정 가능 -> schedule_interval 인수 설정
- @daily로 설정하면 하루에 한번 실행

#### p.45 Cron 기반의 스케줄 간격 설정하기
- cron(macOS 및 리눅스와 같은 유닉스 기반 OS에서 사용하는 시간 기반 작업 스케줄러)과 동일한 구문을 사용해 스케줄 간격 정의 가능
- cron job은 시간/날짜가 해당 필드의 값과 시스템 시간이 일치할 때 실행됨
  - 0 * * * * = 매 시간(정시에 실행)
  - 0 0 * * * = 매일(자정에 실행)
  - 0 0 * * 0 = 메주(일요일 자정에 실행)
- 콤마를 사용하여 값의 리스트를 정의하거나 대시를 사용하여 값의 범위를 정의하는 값의 집합을 지정할 수 있음
  - 0 0 * * MON,WED,FRI = 매주 월, 화, 금 자정에 실행
- cron 식은 기능이 좋지만 작업하기 쉽지 않으므로 적용 전 작성된 태스크에 대해 테스트하는 것이 필요

#### p.47 3.2.3 빈도 기반의 스케줄 간격 설정하기
- cron 식의 제약은 특정 빈도마다 스케줄을 정의할 수 있다는 것
- 이러한 제약은 cron 식의 특성에 있음 -> 작업의 실행 여부를 결정하기 위해 패턴과 일치하는 현재 시간을 지속적으로 확인하기 위한 정의
- Airflow은 이런 상대적인 시간 간격으로 스케줄 간격을 정의할 수 있도록 정의
- 빈도 기반 스케줄을 사용하려면 timedelta인스턴스를 사용하면 됨

#### p.49 3.3.2 실행 날짜를 사용하여 동적 시간 참조하기
- execution_date: DAG가 실행되는 날짜와 시간을 나타냄
  - DAG를 시작하는 시간의 특정 날짜가 아니라 스케줄 간격으로 실행되는 시작 시간을 나타내는 타임스탬프
  - 종종 날짜를 형식화된 문자열로 참조하여 사용됨 -> Airflow는 일반적인 날짜 형식에 대한 여러 유형의 축약 매개변수를 제공
- next_execution_dat: 스케줄 간격의 종료 시간 -> 태스크의 스케줄 간격 정의
- previous_execution_date: 과거 스케줄 정의
  - 현재 시간 간격의 데이터와 이전 간격의 데이터를 대조하여 분석을 수행할때 유용함

#### p.51 3.3.3 데이터 파티셔닝
- 새로운 fetch_events 태스크로 이벤트 데이터를 새롭게 스케줄한 간격에 맞춰 점진적으로 가져오지만, 각각의 새로운 태스크가 전일의 데이터를 덮어쓰게 됨
  - 문제 해결 방법: events.json 파일에 새 이벤트를 추가하는 것 -> 하나의 JSON 파일에 모든 데이터 작성 가능
    - 단점: 특정 날짜의 통계 계산을 하려고 해도 전체 데이터 세트를 로드하는 다운스트림 프로세스 작업이 필요, 장애 지점이 되어 파일이 손상되어 전체 데이터 세트가 손실될 위험을 가지게 됨
- 태스크의 출력을 해당 실행 날짜의 이름이 적힌 파일에 기록함으로써 데이터 세트를 일일 배치로 나누는 것

### p.53 3.4 Airflow 실행 날짜 이해
#### p.53 3.4.1 고정된 스케줄 간격으로 태스크 실행
- 시작 날짜, 스케줄 간격 및 종료 날짜로 DAG 실행 시점 제어 가능
- 실제로 DAG를 예약하기 위해 위 세 가지 매개변수를 사용해 시간을 스케줄 간격으로 나눔
- 간격 기반 접근 방식: 해당 간격의 시간 슬롯이 경과되자마자 해당 간격 동안 DAG가 실행됨
  - 이점: 작업이 실행되는 시간 간격을 정확히 알고 있으므로 증분 데이터 처리 유형을 처리하는데 적합
    - 이는 작업이 실행되는 현재 시점의 시간만 아는 cron과 같은 시점 기반 스케줄링 시스템과 극명한 대조를 이룸

### p.56 3.5 과거 데이터 간격을 메꾸기 위해 백필 사용하기
- Airflow를 사용하면 임의의 시작 날짜로부터 스케줄 간격을 정의할 수 있으므로 과거의 시작 날짜부터 과거 간격을 정의할 수 있음
- 백필: 과거 데이터 세트를 로드하거나 분석하기 위해 DAG의 과거 시점을 지정해 실행하는 것

#### p.56 3.5.1 과거 시점의 작업 실행하기
- 기본적으로 Airflow는 아직 실행되지 않은 과거 스케줄 간격을 예약하고 실행함
- 따라서 과거 시작 날짜를 지정하고 해당 DAG를 활성화하면 현재 시간 이전에 과거 시작 이후의 모든 스케줄 간격이 생성됨
- 이 동작은 DAG의 catchup 매개변수에 의해 제어됨
- catchup = false: 과거 모든 스케줄 간격으로 태스크를 실행하는 대신 가장 최근 스케줄 간격에 대해서만 실행함
- 백필은 코드를 변경한 후 다시 처리하는 데 사용할 수도 있음

### p.57 3.6 태스크 디자인을 위한 모범 사례
- 원자성
  - Airflow에서 원자성 트랜잭션은 모두 발생하거나 전혀 발생하지 않는, 나눌 수 없고 돌이킬 수 없는 일련의 데이터베이스와 같은 작업으로 간주됨
  - 마찬가지로 Airflow의 태스크는 성공적으로 수행하여 적절한 결과를 생성하거나 시스템 상태에 영향을 미치지 않고 실패하도록 정의함
  - 모든 작업을 개별 태스크로 분리하면 모든 태스크를 원자성을 유지할 수 있다고 생각할 수 있지만 반드시 그런건 아님
  - 대부분의 Airflow 오퍼레이터는 이미 원자성을 유지하도록 설계되어, 오퍼레이터가 내부적으로 인증과 같이 밀접하게 연결된 작업을 수행할 수 있는 옵션이 있음
- 멱등성
  - 동일한 입력으로 동일한 태스크를 여러 번 호출해도 결과에 효력이 없어야 함
  - 입력 변경 없이 태스크를 다시 실행해도 전체 결과가 변경되지 않아야 함
  - 멱등성이 보장되는 태스크는 실행 횟수에 관계 없이 동일한 결과를 생성함
  - 멱등성은 일관성과 장애 처리를 보장함

### p.86 요약
- 오퍼레이터의 일부 인수는 템플릿화할 수 있음
- 템플릿 작업은 런타임에 실행됨
- PythonOperator 템플릿은 다른 오퍼레이터와 다르게 작동함
- 변수는 호출 가능하도록 구성해 전달함
- 템플릿 인수의 결과는 airflow tasks render로 확인할 수 있음
- 오퍼레이터는 훅을 통해 다른 시스템과 통신할 수 있음
- 오퍼레이터는 무엇을 해야하는지 기술하고, 훅은 작업 방법을 결정함


### p.88 5.1 기본 의존성 유형
- 의존성 패턴
  - 선형 체인 유형: 연속적으로 실행되는 작업
    - 이전 태스크의 결과가 다음 태스크의 입력 값으로 사용되기 때문에 다음 태스크로 이동하기 전에 각 태스크를 완료해야 함
    - 오른쪽 비트 시프트 연산자(>>)를 사용하여 태스크 간에 의존성을 만들어 두 태스크 간에 관계를 나타낼 수 있음
    - 태스크 의존성을 명시적으로 지정하면 얻는 이점은 여러 태스크에서 순서가 명확하게 정의된다는 것 -> 이를 통해 Airflow는 의존성이 충족된 경우에만 다음 태스크를 스케줄할 수 있음
    - 모든 오류는 Airflow에 의해 다운스트림 태스크로 전달되어 실행을 지연시킴
  - 팬아웃/팬인 유형: 하나의 태스크가 여러 다운스트림 태스크에 연결되거나 그 반대의 동작을 수행하는 유형
    - 팬인 구조: 하나의 태스크가 여러 업스트림 태스크에 영향을 받는 구조는 단일 다운스트림 태스크가 여러 업스트림 태스크에 의존성을 가짐

### p.92 5.2 브랜치하기
#### 5.2.1 태스크 내에서 브랜치하기
- 수집 태스크를 다시 작성하여 실행 날짜를 통해 개별 코드로 분리
- 초기 데이터 수집/정제 작업을 수행하면 데이터 소스와 무관하게 일관된 형식으로 판매 데이터 처리 가능
- 장점: DAG 자체의 구조를 수정하지 않고도 DAG에서 약간의 유연성을 허용할 수 있다는 것
- 단점: 이 접근 방식은 분기가 가능한 유사한 태스크로 구성된 경우에만 작동, 특정 DAG 실행중에 Ariflow에서 어떤 코드 분기를 사용하고 있는지 확인하기 어려움

#### 5.2.2 DAG 내부에서 브랜치하기
- 두 개의 개별 태스크 세트를 개발하고 DAG가 이전 또는 새로운 ERP 시스템에서 데이터 수집 작업을 실행을 선택할 수 있도록 하는 것
- 두 가지 태스크 새트 구축 방법: 적절한 오퍼레이터를 사용하여 각 태스크를 별도 생성하고 각 태스크들 연결하기
- DAG에 서로 다른 브랜치를 결합하는 더미 태스크를 추가하여 브랜치 조건을 명확하게 해야 함

### p.99 5.3 조건부 태스크
- 특정 조건에 따라 DAG특정 태스크를 건너뛸 수 있는 방법이 있음
- 
#### 5.3.1 태스크 내에서 조건
- 가장 최근 실행된 DAG에 대해서만 모델을 배포하도록 DAG를 변경하여 문제 해결 가능
- 이렇게 하면 모델의 한 버전, 즉 가장 최근 데이터 세트에 대해 학습된 모델 중 특정 버전만 배포 가능
- 수행 방법: PythonOperator를 이용하여 배포를 구현하고 배포 함수 내에서 DAG의 실행 날짜를 명시적으로 확인하는 것
- 
#### 5.3.2 조건부 태스크 만들기
- 배포 태스크 자체를 조건부화하는 것 -> 미리 정의된 조건에 따라서만 실행되도록
- Airflow에서는 해당 조건을 테스트하고 조건이 실패할 경우 모든 다운스트림 작업을 건너뛰는 태스크를 DAG에 추가하여 태스크를 조건부화할 수 있음

### 5.4 트리거 규칙에 대한 추가 정보
- 트리거 규칙을 이해하려면 먼저 Airflow가 DAG 실행 내에서 작업을 실행하는 방법을 알아야 함
- 근본적으로 Airflow는 DAG를 실행할 때 각 태스크를 지속적으로 확인하여 실행 여부를 확인함
- 태스크 실행이 가능하다고 판단되면 그 즉시 스케줄러에 의해 선택된 후 실행을 예약함
- 결론적으로 에어플로우에 사용 가능한 실행 슬롯이 있다면 즉시 태스크가 실행됨
- 그렇다면 에어플로우는 태스크 실행 시기를 어떻게 결정할까 ? -> 트리거 규칙 필요

#### 5.4.1 트리거 규칙이란?
- 태스크 의존성 기능과 같이 에어플로우가 태스크가 실행 준비가 되어 있는지 여부를 결정하기 위한 필수적인 조건
- 에어플로우의 기본 트리거 규칙은 all_success이며, 태스크를 실행하려면 모든 의존적인 태스크가 모두 성공적으로 완료되어야 함을 의미

#### 5.4.2 실패의 영향
- 태스크 중 하나가 오류를 발생시키면 더이상 진행할 수 없음
- 업스트림 태스크 결과가 다운스트림 태스크에도 영향을 미치는 동작 유형을 전파(propagation)
- 이 경우 업스트림 실패가 다운스트림 태스크로 전파되기 때문

#### 5.4.3 기타 트리거 규칙
- all_done
  - 결과에 관계없이 의존성 실행이 완료되는 즉시 실행된느 태스크를 정의할 수 있음
- one_failed 또는 one_success와 같은 즉시 규칙
  - 트리거 하기 전에 모든 업스트림 태스크가 완료될때까지 기다리지 않고
  - 하나의 업스트림 태스크의 성공/실패 확인 조건만 필요로 함
  - 태스크의 조기 실패를 알리거나 태스크 그룹 중 하나의 태스크가 성공적으로 완료되는 즉시 대응할 수 있음

### 5.5 태스크간 데이터 공유
- Airflow의 XCom을 사용하여 태스크 간의 작은 데이터를 공유할 수 있음
- XCome은 기본적으로 태스크 간의 메시지를 교환하여 특정 상태를 공유할 수 있게 함

#### 5.5.1 XCome을 사용하여 데이터 공유하기
- xcom_push
  - 값을 게시할 수 있음
- xcome_pull
  - 다른 태스크에서 XCom 값을 확인할 수 있음
  - 현재 DAG 실행을 통해 게시된 값만 가져옴

#### 5.5.2 XCom 사용 시 고려사항
- 풀링 태스크는 필요한 값을 사용하기 위해 태스크 간에 묵시적인 의존성이 필요함
  - 명시적 의존성 태스크와 달리 DAG에 직접적으로 표시되지 않으며 태스크 스테줄 시에 고려되지 않음
  - XCom에 의해 의존성 있는 작업이 올바른 순서로 실행할 수 있도록 해야 함 -> Airflow는 이를 고려하지 않음
  - 이러한 숨겨진 의존성은 서로 다른 DAG에서 실행 날짜 사이에 XCom 값을 공유할 때 더 복잡해지기 때문에 권장하지 않음